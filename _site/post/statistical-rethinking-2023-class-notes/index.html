<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Zajichek">
<meta name="dcterms.date" content="2023-01-01">

<title>Statistical Rethinking 2023 Class Notes – Zajichek Stats</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-9MW3W3RQD9"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-9MW3W3RQD9', { 'anonymize_ip': true});
</script>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Statistical Rethinking 2023 Class Notes – Zajichek Stats">
<meta property="og:description" content="Statistician/data scientist in Central Wisconsin.">
<meta property="og:image" content="https://www.zajichekstats.com/post/statistical-rethinking-2023-class-notes/feature.png">
<meta property="og:site_name" content="Zajichek Stats">
<meta property="og:image:height" content="1142">
<meta property="og:image:width" content="936">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../presentations.html"> 
<span class="menu-text">Projects &amp; Presentations</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.centralstatz.com/"> 
<span class="menu-text">Consultancy</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://dashboard.mailerlite.com/forms/1517199/154300987644839168/share"> 
<span class="menu-text">Subscribe</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:alex@centralstatz.com"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/alexzajichek"> <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/zajichek"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.youtube.com/@centralstatz"> <i class="bi bi-youtube" role="img" aria-label="YouTube">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Statistical Rethinking 2023 Class Notes</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Bayesian Statistics</div>
    <div class="quarto-category">Causal Inference</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Alex Zajichek </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This document is intended to be a repository for my (raw, unedited) notes, interpretations, examples, and summaries from the <a href="https://github.com/rmcelreath/stat_rethinking_2023">Statistical Rethinking 2023</a> course (which Richard McElreath has graciously made available for free (!) covering <a href="https://xcelab.net/rm/statistical-rethinking/">his book</a>). I’m not actually enrolled in the course, but just casually following the lectures and material. I have a strong interest in learning and incorporating Bayesian analysis and causal principles into my work, and this seemed like a great opportunity to build a foundation for that.</p>
<section id="table-of-contents" class="level1">
<h1>Table of Contents</h1>
<ol type="1">
<li><a href="#lecture1">Science Before Statistics</a></li>
<li><a href="#lecture2">Garden of Forking Data</a></li>
<li><a href="#lecture3">Geocentric Models</a></li>
<li><a href="#lecture4">Categories and Curves</a></li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load some packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
</div>
</section>
<section id="lecture1" class="level1">
<h1>1. Science Before Statistics</h1>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1</td>
<td>1</td>
<td>1/6/2023</td>
<td>1/3/2023</td>
</tr>
</tbody>
</table>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This course focus is on scientific modeling via causal inference, which is focused on identifying causes in <em>observational</em> data. Causal Inference requires us to consider the mechanism of a phenomenon, and think about not only which variables cause other variables, but in what order–subject matter expertise is of utmost importance, and we don’t really depend on the data at hand until the very end of our inference process. Causal modeling must become the foundation to do analysis by–we can’t just do simple statistics in one project and then think about causal modeling in another–samples are from populations and there are causes associated with why we observed the sample we did, even if we’re answering very basic questions. Also, <em>Bayesian</em> modeling as a means to performing causal inference is not due to philosophical reasons (e.g., frequentist vs.&nbsp;Bayesian), it’s more so because a Bayesian framework provides the most natural tools to employ the specified causal model (i.e., if the frequentist model made sense for answering the causal question, we’d use it). The generative aspect of Bayesian modeling is one aspect in particular that makes it very inviting to represent the causal model in a statistical framework, and apply distributions. Finally, coding is not just a means to employ the math, but rather needs to be treated as part of the product, therefore employing software engineering principles, having documentation, making things reproducible. These things need to be employed if you really want to advance knowledge with confidence.</p>
</section>
<section id="notes" class="level2">
<h2 class="anchored" data-anchor-id="notes">Notes</h2>
<p><strong>Overview</strong></p>
<ul>
<li>Most interested in Causal Inference, focusing on the <em>science</em> before the <em>statistics</em></li>
<li>We must be able to talk about causes to obtain scientific knowledge, why else would we do it?</li>
<li>Causes can’t be extracted from data; must come from knowledge, assumptions</li>
</ul>
<p><strong>What is Causal Inference?</strong></p>
<ul>
<li>It is more than associations; associations are bi-directional, and correlation is only a basic measure of association;</li>
<li>It is all about intervention, directionality, and the <em>prediction</em> of the consequence of changing one variable on another (asking <em>what-if?</em>)</li>
</ul>
<p><strong>Causal Imputation</strong></p>
<ul>
<li>This is about being able to construct <em>counterfactual</em> outcomes</li>
<li>Asking the question, <em>what if I had done something else?</em></li>
<li>We only observe a single outcome, but we want to know what would have happened had a certain intervention not taken place</li>
</ul>
<p><strong>Directed Acyclic Graph (DAG)</strong></p>
<ul>
<li>Nothing more than an abstraction about which variables cause which other variables</li>
<li>Shows the direction at which variables cause each other, but doesn’t specify <em>how</em> (i.e., effect shapes, etc.)</li>
<li>We can use this to know which things to control for, answer hypothetical interventions, under the assumption that the model is true</li>
<li>It provides a tool to answer very specific questions (queries); not necessarily all questions lead to the same statistical model, but the appropriate statistical model can be derived from the causal model depending on the question</li>
<li><em>Intuition Pumps</em>: Gets the researcher to think about mechanism; great way to problem solve with SME’s without looking at the data (which is how it should be)</li>
</ul>
<p><strong>Golems (statistical models)</strong></p>
<ul>
<li>Metaphor for what a statistical model is; it’s a very useful machine that will do what it’s asked very well, but has no wisdom or forethought</li>
<li>Does not know the intent of the task</li>
<li>Statistical models are just objective tools, but we need causal models to know how and when certain models are actually appropriate</li>
</ul>
<p><strong>Statistical Models</strong></p>
<ul>
<li>Having a flowchart of tests is not useful, except maybe in the <em>experimental</em> setting (remember we’re talking observational data)</li>
<li>Statistical models/tests don’t make a clear relationship between the research and the data; it’s just math</li>
</ul>
<p><strong>Hypotheses &amp; Models</strong></p>
<ul>
<li>We need <em>generative</em> causal models that are guided by the DAG’s</li>
<li>We need <em>estimands</em> that are statistical models justified by the generative models (how do we quantify what we’re after?)</li>
<li>Introduce real data at the end–this is the easy part</li>
</ul>
<p><strong>Justifying Controls</strong></p>
<ul>
<li>Cannot just control for everything in your dataset like is done so much in current research (e.g., colliders have undesired effect)</li>
<li>Need the causal model (DAG) to be able to deduce what should be controlled for based on the specific question that is asked</li>
<li><em>Adjustment Set:</em> The variables determined appropriate to control for for a particular query</li>
</ul>
<p><strong>Why Bayesian?</strong></p>
<ul>
<li>Bayesian happens to be the easiest approach for generative models; it’s not because we’re stuck in a philosophical debate</li>
<li>Easiest way to take the scientific structure of the assumed model and generate it, since it naturally has <em>direction</em> (i.e., priors)</li>
<li>In most cases, Bayes can be appropriate (sometimes not–cut cake with chainsaw)
<ul>
<li>Measurement error, missing data, latent variables, regularization</li>
</ul></li>
<li>It is <em>practical</em>, not <em>philosophical</em></li>
</ul>
<p><strong>Owls</strong></p>
<ul>
<li>Classic joke: Step 1 = Draw two circles, Step 2 = draw remaining owl
<ul>
<li>Programming and technical things tend to be taught this way, but we want to avoid this and document all the intermediate steps</li>
</ul></li>
<li>We need to have an explicit workflow with clear steps</li>
<li>We need to treat coding/scripting seriously, not just a means to something (apply software engineering principles, documentation, quality control)</li>
<li>Understand what you are doing, document your work and reduce error, have a respectable scientific workflow, be professional and organized to maintain <em>reproducible</em> scientific knowledge, otherwise it’s all bullshit</li>
<li>Workflow
<ol type="1">
<li>Theoretical Estimand (what are we trying to do?)</li>
<li>Scientific (Causal) Model (DAG + Generative)</li>
<li>Use 1 &amp; 2 to build appropriate statistical model</li>
<li>Simulate from 2 to validate that 3 yields 1</li>
<li>Analyze the actual data</li>
</ol></li>
</ul>
</section>
</section>
<section id="lecture2" class="level1">
<h1>2. Garden of Forking Data</h1>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>2, 3</td>
<td>1/6/2023</td>
<td>1/6/2023</td>
</tr>
</tbody>
</table>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">Summary</h2>
<p>This scientific modeling framework provides an <em>objective</em> process to incorporate <em>subjective</em> (expert, scientfic) knowledge into the modeling process, enabling us to incorporate all of the uncertainty associated with those processes, predicated on the assumption of the causal model. Further, one of the key takeaways was that <em>samples do not need to be representative of the population for us to provide good estimates</em>. This is profound because generally we are taught the opposite, but because of the process, we can explicitly account for how we know/assume the data was generated, and use that information to create a good estimate of the quantity we are interested in. This is much more <em>practical</em> than the assumptions that are made in a typical frequentist analysis–which tend to be blindly made which ironically makes them more wrong than the “subjective” information in the generative approach. We can then use sampling of our posterior distribution(s) to answer questions about what might happen if we do another experiment, etc. (e.g., what if we take 10 more samples?). Instead of relying on asymptotics for the sampling distribution of a statistic (frequentist), we can just take samples from the posterior for any complex quantity of interest and get the uncertainty surrounding that. This is especially important once we are dealing with analytically intractable posteriors that don’t have closed form solutions. Instead of needing expert-level calculus knowledge for such problem, we just have to follow the same workflow as in this basic problem. After years of frequentist modeling, that is always full of limitations and disatisfaction in the results, this approach will lead to much more rewarding scientific discovery and confidence in the conclusions of research.</p>
<section id="a-check-for-understanding" class="level3">
<h3 class="anchored" data-anchor-id="a-check-for-understanding">A check for understanding</h3>
<p>Let’s go through and reproduce some of the content/concepts from slides but using our own explanation, implementation and interpretation along the way.</p>
<section id="what-is-the-objective" class="level4">
<h4 class="anchored" data-anchor-id="what-is-the-objective">1. What is the objective?</h4>
<p>The main question asked in the demonstration was <em>what proportion of the globe is water?</em>. Thus, the quantity we are interested in is a single quantity: the <em>true</em> proportion of of the globe that is water.</p>
</section>
<section id="what-is-the-sampling-strategy" class="level4">
<h4 class="anchored" data-anchor-id="what-is-the-sampling-strategy">2. What is the sampling strategy?</h4>
<p>We want to collect data to try to answer the question of interest. This will be done by spinning the globe and dropping a pin at a random location to indicate if it is either land or water. Some initial assumptions are</p>
<ul>
<li>All points on the globe are equally-likely to be selected</li>
<li>Any given point on the globe is either land or water (only two possibilities)</li>
<li>There is no measurement error associated with indicating if the selected point was land or water</li>
</ul>
</section>
<section id="what-is-the-generative-model" class="level4">
<h4 class="anchored" data-anchor-id="what-is-the-generative-model">3. What is the generative model?</h4>
<p>We want to consider the different variables at play here as it relates to any observed sample we get as a result of the sampling strategy. First and foremost, the primary <em>unknown</em> parameter is:</p>
<p><span class="math display">\[p=\text{proportion of water on the globe}\]</span></p>
<p>The other two at play (under this simplistic model) are:</p>
<p><span class="math display">\[N=\text{Number of globe spins} \hskip.5in W=\text{Number of spins resulting in water}\]</span> <em>Note that the number of spins resulting in land is just <span class="math inline">\(N-W\)</span></em></p>
<p>With the variables defined, the next step is determine how these variables relate to each other. We’ll use the following DAG:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
  A(p) --&gt; C(W)
  B(N) --&gt; C
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This assumes that the number of water spins observed in our sample is determined by:</p>
<ol type="1">
<li>The true proportion of water on the globe</li>
<li>The total number of spins of the globe made (samples)</li>
</ol>
</section>
<section id="what-is-the-statistical-modelestimation-procedure" class="level4">
<h4 class="anchored" data-anchor-id="what-is-the-statistical-modelestimation-procedure">4. What is the statistical model/estimation procedure?</h4>
<p>Let’s suppose we execute the sampling procedure which yields the following response vector:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>observed_sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 1 = water; 0 = land</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">sum</span>(observed_sample) <span class="co"># Number of water samples</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">length</span>(observed_sample) <span class="co"># Number of spins</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>W; N</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9</code></pre>
</div>
</div>
<p>We just need to <em>count</em> all of the ways that this sample could have arose across all of the different possibilities of <span class="math inline">\(p\)</span>, and then estimate <span class="math inline">\(p\)</span> as that of where the sample was most likely to have occurred.</p>
<section id="basic-incorrect-solution-with-finite-possibilities" class="level5">
<h5 class="anchored" data-anchor-id="basic-incorrect-solution-with-finite-possibilities">Basic (incorrect) solution with finite possibilities</h5>
<p>We know that there are infinitely many possibilities for <span class="math inline">\(p\)</span>. Let’s first go through this assuming the globe is that of a 4-sided die, such that each side is land or water, implying the only possibilities are <span class="math inline">\(p \in (0,.25,.50,.75,1)\)</span>. For each possible value of <span class="math inline">\(p\)</span>, what is number of ways we could have observed our sequence of data? (thinking of the generative process, starting with <span class="math inline">\(N\)</span> and <span class="math inline">\(p\)</span>).</p>
<p>First of all, we can set our <em>possible</em> set of parameter values, and the number of “sides” of the globe this implies (i.e., we’re saying that there are only 4 sides and each one is either Water or Land, so we have a limited number of <span class="math inline">\(p\)</span> values that could occur).</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set possible values for p</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">75</span>, <span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of sides of globe</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>sides <span class="ot">&lt;-</span> <span class="fu">length</span>(p) <span class="sc">-</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>For each of the 5 possible values of <span class="math inline">\(p\)</span>, how many combinations are there that produce our observed sequence of data?</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of ways to observe sample for each p (this is the count of the possible sequences of indicators)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> (sides<span class="sc">*</span>p)<span class="sc">^</span>W <span class="sc">*</span> (sides<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N<span class="sc">-</span>W)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>ways</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1]   0  27 512 729   0</code></pre>
</div>
</div>
<p>Now, of those possibilities, which was the most likely to occur?</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior probability</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>posterior_prob <span class="ot">&lt;-</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, posterior_prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        p ways posterior_prob
[1,] 0.00    0     0.00000000
[2,] 0.25   27     0.02129338
[3,] 0.50  512     0.40378549
[4,] 0.75  729     0.57492114
[5,] 1.00    0     0.00000000</code></pre>
</div>
</div>
<p>It looks like <span class="math inline">\(p=0.75\)</span> was the most likely value of those that are possible.</p>
<p>What is key to note about the posterior probabilities is that they are relative to the total across all values of <span class="math inline">\(p\)</span>. We simply found all of the raw counts associated with each <span class="math inline">\(p\)</span> and then normalized them by the total to get the posterior probability. But this process was <em>exactly</em> the same thing as finding the <em>likelihood</em> of the data:</p>
<p><span class="math display">\[Likelihood = \prod_{i=1}^NP(X=x|p)\]</span></p>
<p>where <span class="math inline">\(X\)</span> is the binary indicator from a single globe spin.</p>
<p>If we just look at all the <em>possible</em> sequences of indicators that could have occurred:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Total possible sequences of indicators (each one could be a 1 or a 0)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>total_possible_sequences <span class="ot">&lt;-</span> sides<span class="sc">^</span>N</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>total_possible_sequences</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 262144</code></pre>
</div>
</div>
<p>And then divide our original combination counts by that, we’ll get <em>exactly</em> the likelihood of the data:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide the total number of combinations we could have saw our sample, by the total number of possibilities</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> ways <span class="sc">/</span> total_possible_sequences</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>likelihood</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0000000000 0.0001029968 0.0019531250 0.0027809143 0.0000000000</code></pre>
</div>
</div>
<p>However, as stated above, this will <em>not</em> change the resulting posterior distribution because the number we divided by was just a normalizing constant:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>likelihood <span class="sc">/</span> <span class="fu">sum</span>(likelihood)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00000000 0.02129338 0.40378549 0.57492114 0.00000000</code></pre>
</div>
</div>
<p>So, we could also think of this problem in a different light (although it’s the SAME) and get the same result:</p>
<ol type="1">
<li>We could think of each observed value as an (unfair) coin flip (according to the value of <span class="math inline">\(p\)</span>) and calculate the likelihood of the sequence of flips (which is actually what we already did, but this is more of the “traditional” way to think about it):</li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood of sequence of observed sample</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>likelihood2 <span class="ot">&lt;-</span> p<span class="sc">^</span>W <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N<span class="sc">-</span>W)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>likelihood</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0000000000 0.0001029968 0.0019531250 0.0027809143 0.0000000000</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute posterior</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>likelihood2 <span class="sc">/</span> <span class="fu">sum</span>(likelihood2) <span class="co"># Same as before</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00000000 0.02129338 0.40378549 0.57492114 0.00000000</code></pre>
</div>
</div>
<ol start="2" type="1">
<li>We could also think of this as finding the likelihood of observing the <em>total</em> number of water spins since each flip is <em>independent</em>. This is also the same as before, except we’re accounting for all of the combinations to observe the total number of water flips, not just the particular sequence:</li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make the normalizing constant</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>normalizing_constant <span class="ot">&lt;-</span> <span class="fu">factorial</span>(N) <span class="sc">/</span> (<span class="fu">factorial</span>(W)<span class="sc">*</span><span class="fu">factorial</span>(N<span class="sc">-</span>W))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiply the likelihood by the normalizing constant by the likelihood to get the true probability of the observed sample for each value of p</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>probability <span class="ot">&lt;-</span> normalizing_constant <span class="sc">*</span> likelihood</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>probability</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000000000 0.008651733 0.164062500 0.233596802 0.000000000</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the posterior</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>probability <span class="sc">/</span> <span class="fu">sum</span>(probability)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.00000000 0.02129338 0.40378549 0.57492114 0.00000000</code></pre>
</div>
</div>
<p>Note that the normalizing constant had no effect on the posterior, but it did calculate the correct probabilities of the observed sample. In fact, this was just a Binomial distribution:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># What is the probability of observing W water values in a sample of N globe spins for each p?</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> W, <span class="at">size =</span> N, <span class="at">prob =</span> p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000000000 0.008651733 0.164062500 0.233596802 0.000000000</code></pre>
</div>
</div>
<p>That is, the probability distribution for the number of water samples is:</p>
<p><span class="math display">\[W|p \sim Binomial(N, p)\]</span> <span class="math display">\[
\begin{equation}
\begin{split}
P(W|p)
&amp;= \binom{N}{W}p^W(1-p)^{N-W} \\
&amp;= \frac{N!}{W!(N-W)!}p^W(1-p)^{(N-W)} \\
\end{split}
\end{equation}
\]</span></p>
<p>So what is going on here? We are after the distribution of probability weights associated with each possible value of <span class="math inline">\(p\)</span> (which is what the posterior distribution is). In mathematical notation, we’re just applying Bayes’ formula:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
P(p|sample)
&amp; = \frac{P(p)P(sample|p)}{P(sample)} \\
&amp; = \frac{P(p)P(W|p)}{P(W)} \\
&amp; = \frac{P(p)P(W|p)}{P(W \cap p = 0) + ... + P(W \cap p = 1)} \\
&amp; = \frac{P(p)P(W|p)}{P(p=0)P(W|p=0) + ... + P(p=1)P(W|p=1)} \\
\end{split}
\end{equation}
\]</span> Each value of <span class="math inline">\(p\)</span> is equally-likely to occur (<em>uniform prior</em>), so we can factor out that term:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
\text{(from previous)}
&amp; = \frac{P(W|p)}{P(W|p=0) + ... + P(W|p=1)} \\
(binomials) &amp;= \frac{\binom{N}{W}p^W(1-p)^{(N-W)}}{\binom{N}{W}0^W(1-0)^{(N-W)} + ... + \binom{N}{W}1^W(1-1)^{(N-W)}} \\
&amp; = \frac{p^W(1-p)^{(N-W)}}{0^W(1-0)^{(N-W)} + ... + 1^W(1-1)^{(N-W)}} \\
&amp; = \frac{p^W(1-p)^{(N-W)}}{\text{Normalizing constant}} \\
\end{split}
\end{equation}
\]</span> As you can see, the combination term also factors out, and the basic structure we’re left with is the <em>likelihood</em> piece that was found in <em>all three (3)</em> variations above: <span class="math inline">\(p^W(1-p)^{(N-W)}\)</span>. So when computing the posterior probability, they are relative to only terms dependent on the parameter of interest, so doesn’t matter if we use the counts, base likelihood, or the probability distribution–they are all the SAME. The counting process and the “forking data” approach is simply a means to breakdown the process of what’s happening behind the scenes in the math, so instead of just saying “do this integral” or “compute this product of the likelihood”, you’re picking apart each step of that process to gain intuition about what is happening. I’d imagine this is exactly the point of the Owl reference in the prior lecture.</p>
</section>
<section id="full-solution-p-is-a-continuous-value" class="level5">
<h5 class="anchored" data-anchor-id="full-solution-p-is-a-continuous-value">Full solution: <em>p</em> is a continuous value</h5>
<p>As mentioned before, the actual proportion of water on the globe can be any number between zero and one (<span class="math inline">\(p \in [0,1]\)</span>), meaning that there are “infinite” sides to the globe. The derivation at the end of the previous section illustrates that the posterior distribution for <span class="math inline">\(p\)</span> not restricted to any particular set of values. If we pick up where we left off:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
P(p|data)
&amp; = \frac{p^W(1-p)^{(N-W)}}{\text{Normalizing constant}} \\
\end{split}
\end{equation}
\]</span> All we would need to do for the continuous version of <span class="math inline">\(p\)</span> to make the posterior a formal probability distribution is to find the normalizing constant such that the integral over all possible values of <span class="math inline">\(p\)</span> equals 1. Formally, with respect to <span class="math inline">\(p\)</span>,</p>
<p><span class="math display">\[\int_0^1 \frac{p^W(1-p)^{N-W}}{Constant} = 1\]</span> This will ensure that the probabilities across all possible values of <span class="math inline">\(p\)</span> sums to one. However, it doesn’t actually matter that we find that constant necessarily, because the posterior probability is just <em>relative</em> to the range of values of <span class="math inline">\(p\)</span>. So all that really matters is:</p>
<p><span class="math display">\[P(p|data) \propto p^W(1-p)^{N-W}\]</span> We can then plug in our data and graph the resulting distribution to make inferences about <span class="math inline">\(p\)</span>.</p>
<p><span class="math display">\[P(p|data) \propto p^6(1-p)^3\]</span></p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>), <span class="co"># Approximate the range of p values</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> p<span class="sc">^</span>W<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N<span class="sc">-</span>W) <span class="co"># Compute the posterior</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>After using our sample of 9, the probability weight for <span class="math inline">\(p\)</span> tends to focus near 0.70. Note that the scale of the y-axis was removed to emphasize that it doesn’t really matter what it is. We would just need to be able to calculate the area under the curve to be able to assign real probabilities to questions like <em>“what is the probability that the proportion of water is less than 0.5?”</em>.</p>
<p><em>Note: In some cases, if we used used a different priors on <span class="math inline">\(p\)</span> (e.g., Beta), the posterior will turn out to be an identifiable distribution which we know the normalizing constant.</em></p>
</section>
<section id="updating-the-posterior" class="level5">
<h5 class="anchored" data-anchor-id="updating-the-posterior">Updating the posterior</h5>
<p>So when we talk “Bayesian updates” or updating the posterior distribution, what does this mean? Since the point of it is to be able to update a model with new information, my gut used to tell me that we were somehow adding our current knowledge about the parameter into the new <em>prior</em> distribution, and then updating the new posterior with an updated prior and only using new data in the likelihood. While in a way this might be the right way to think about it (i.e., if I have a posterior right now, isn’t that the most current knowledge about the parameter, so if I want to collect more data, wouldn’t I want to use knowledge up to this point as the prior instead of reverting back to the original prior and just adding more data to the collective sample?), in these examples we were doing something different: we’re just seeing how the posterior changes as more data is added to the sample (i.e., observed sequence of data points).</p>
<p>Let’s start with just focusing on the basic example (i.e., 4 sided-globe) for now. We just need to loop through the observed sample, and calculate the posterior probabilities for each value of <span class="math inline">\(p\)</span> as a new observation comes in:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the prior probability (uniform over the possibly choices)</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">length</span>(p), <span class="fu">length</span>(p))</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the current posterior as the prior (before any data collected)</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>last_posterior <span class="ot">&lt;-</span> prior</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make result set</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in the observed sample </span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1. Get the sub-sample</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>  sub_sample <span class="ot">&lt;-</span> observed_sample[<span class="dv">1</span><span class="sc">:</span>i]</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 2. Compute metrics (the number of water samples, and the total number of spins)</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>  W_temp <span class="ot">&lt;-</span> <span class="fu">sum</span>(sub_sample)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>  N_temp <span class="ot">&lt;-</span> <span class="fu">length</span>(sub_sample)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. Compute the likelihood for each p</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>  temp_likelihood <span class="ot">&lt;-</span> p<span class="sc">^</span>W_temp <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p)<span class="sc">^</span>(N_temp <span class="sc">-</span> W_temp)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4. Posterior</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>  temp_posterior <span class="ot">&lt;-</span> temp_likelihood <span class="sc">/</span> <span class="fu">sum</span>(temp_likelihood)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 5. Add to results</span></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">%&gt;%</span></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> i,</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>        <span class="at">sequence =</span> <span class="fu">paste</span>(sub_sample, <span class="at">collapse =</span> <span class="st">","</span>),</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>        p,</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        <span class="at">likelihood =</span> temp_likelihood,</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>        <span class="at">current =</span> temp_posterior,</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>        <span class="at">last =</span> last_posterior</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the new last posterior</span></span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>  last_posterior <span class="ot">&lt;-</span> temp_posterior</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Send down the rows</span></span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(last, current)</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">factor</span>(p),</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> value,</span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>      <span class="at">fill =</span> name</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">75</span>,</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>    <span class="at">width =</span> .<span class="dv">25</span>,</span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span></span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(</span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">"Spin: "</span>, <span class="fu">factor</span>(sample), <span class="st">" </span><span class="sc">\n</span><span class="st">Sample: "</span>, sequence)</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">colour =</span> <span class="st">"gray"</span>)</span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"p"</span>) <span class="sc">+</span></span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Posterior Probability"</span>) <span class="sc">+</span></span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Posterior"</span></span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"darkgray"</span>)</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a>  ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The blue bars show the posterior probability for each possible value of <span class="math inline">\(p\)</span> <em>after</em> the newest observation was made, and the gray bars show it <em>before</em> the newest observation was made. This illustrates the incremental impact of adding more data to the sample on the resulting posterior distribution.</p>
<p>We can apply this same process to the <em>continuous</em> (correct) possible set of values for <span class="math inline">\(p\)</span> (in fact, we’ll create the curves by performing the exact same procedure to a larger, discrete set of values but make the display appear continuous):</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate the set of inifinite p-values by a large set of discrete ones</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>p_continuous <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the prior probability (uniform over the possibly choices)</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">length</span>(p_continuous), <span class="fu">length</span>(p_continuous))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the current posterior as the prior (before any data collected)</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>last_posterior <span class="ot">&lt;-</span> prior</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Make result set</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in the observed sample </span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1. Get the sub-sample</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>  sub_sample <span class="ot">&lt;-</span> observed_sample[<span class="dv">1</span><span class="sc">:</span>i]</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 2. Compute metrics (the number of water samples, and the total number of spins)</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>  W_temp <span class="ot">&lt;-</span> <span class="fu">sum</span>(sub_sample)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>  N_temp <span class="ot">&lt;-</span> <span class="fu">length</span>(sub_sample)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. Compute the likelihood for each p</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>  temp_likelihood <span class="ot">&lt;-</span> p_continuous<span class="sc">^</span>W_temp <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p_continuous)<span class="sc">^</span>(N_temp <span class="sc">-</span> W_temp)</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4. Posterior</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>  temp_posterior <span class="ot">&lt;-</span> temp_likelihood <span class="sc">/</span> <span class="fu">sum</span>(temp_likelihood)</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 5. Add to results</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">%&gt;%</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> i,</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>        <span class="at">sequence =</span> <span class="fu">paste</span>(sub_sample, <span class="at">collapse =</span> <span class="st">","</span>),</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>        p_continuous,</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>        <span class="at">likelihood =</span> temp_likelihood,</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>        <span class="at">current =</span> temp_posterior,</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">last =</span> last_posterior</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the new last posterior</span></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a>  last_posterior <span class="ot">&lt;-</span> temp_posterior</span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Send down the rows</span></span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(last, current)</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(</span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p_continuous,</span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> value,</span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>      <span class="at">fill =</span> name</span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">65</span>,</span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">"Spin: "</span>, <span class="fu">factor</span>(sample), <span class="st">" </span><span class="sc">\n</span><span class="st">Sample: "</span>, sequence)</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">colour =</span> <span class="st">"gray"</span>),</span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"p"</span>) <span class="sc">+</span></span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Posterior Probability"</span>) <span class="sc">+</span></span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Posterior"</span></span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"darkgray"</span>)</span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a>  ) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Again, these curves are actually approximated here. In practice, we would need to calculate the area underneath the curve to get exact answers about probabilities. <em>Note: We could parameterize the Beta distribution to get the normalizing constant for calculating the actual posterior probabilities that fits this distribution.</em></p>
</section>
</section>
</section>
</section>
<section id="homework" class="level2">
<h2 class="anchored" data-anchor-id="homework">Homework</h2>
<ol type="1">
<li>Suppose the globe tossing data had turned out to be 4 water and 11 land. Construct the posterior distribution.</li>
</ol>
<p>We’ll cheat a little bit and use the approach of using a large, discrete list of possible values for <span class="math inline">\(p\)</span>, and plot it as if it is continuous (we could also just use the Beta distribution). With that, all we need to do is change the values of <span class="math inline">\(W\)</span> and <span class="math inline">\(N\)</span> and use the same code as above.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>W_new <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>N_new <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>), <span class="co"># Approximate the range of p values</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> p<span class="sc">^</span>W_new<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N_new<span class="sc">-</span>W_new) <span class="co"># Compute the posterior</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p,</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li>Using the posterior distribution from (1), compute the posterior predictive distribution for the next 5 tosses of the same globe.</li>
</ol>
<p>Okay here I’ll finally acknowledge that the posterior can be written as a <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta</a> distribution, which gives us the normalizing constant needed to make it a real probability distribution (i.e., the area sums to 1). It has the following <em>probability density function (PDF)</em>:</p>
<p><span class="math display">\[f(x|\alpha, \beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}\]</span> where <span class="math inline">\(x \in [0,1]\)</span>, <span class="math inline">\(\alpha, \beta &gt; 0\)</span>, and <span class="math inline">\(\Gamma(n) = (n-1)!\)</span>. If we make the following reparameterizations from our set of variables:</p>
<p><span class="math display">\[p=x\]</span> <span class="math display">\[W = \alpha - 1\]</span> <span class="math display">\[N-W = \beta - 1\]</span> we get:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
f(p|W,N)
&amp; = \frac{\Gamma(W+1+N-W+1)}{\Gamma(W+1)\Gamma(N-W+1)}p^W(1-p)^{N-W} \\
&amp; = \frac{\Gamma(N+2)}{\Gamma(W+1)\Gamma(N-W+1)}p^W(1-p)^{N-W} \\
&amp; = \frac{(N+1)!}{W!(N-W)!}p^W(1-p)^{N-W} \\
\end{split}
\end{equation}
\]</span></p>
<p><em>Note that since <span class="math inline">\(p\)</span> is continuous, this function represents the probability density at any particular value of <span class="math inline">\(p\)</span>. To get any positive probability, we must integrate this function over a range of <span class="math inline">\(p\)</span> values. Hence the <span class="math inline">\(f\)</span> notation.</em></p>
<p>Let’s quickly plug in <span class="math inline">\(W=4\)</span> and <span class="math inline">\(N=15\)</span> to confirm (at least visually) that this function produces the same posterior we made to answer the last question. We’ll do this by evaluating the density of the derived Beta distribution at range of possible <span class="math inline">\(p\)</span> values. <em>Note we’ll have to use the parameterizations for the Beta distribution that are built into <code>R</code></em>.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reparameterize</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> W_new <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> N_new <span class="sc">-</span> W_new <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a data frame</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>), <span class="co"># Approximate the range of p values (same as before)</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> <span class="fu">dbeta</span>(p, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta) <span class="co"># Compute the actual posterior density</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p,</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>From inspection, it appears that they are essentially the same curves. <em>Note that this time I kept the y-axis labels because this is the density for the actual probability distribution</em>.</p>
<p>So back to the question: how do we find the posterior predictive distribution for the next 5 globe spins? Well, if the globe is spun 5 more times, then we can get water on 0, 1, 2, 3, 4, or all 5 spins. Our quest is to figure out the likelihood of each of those possible outcomes based on what we currently know about <span class="math inline">\(p\)</span> (i.e., the posterior distribution). To do this, we’ll use our posterior distribution to run a simulation of the experiment using the following steps:</p>
<ol type="i">
<li>Select a random value of <span class="math inline">\(p\)</span> from the posterior</li>
<li>Draw a random <span class="math inline">\(binomial\)</span> realization where <span class="math inline">\(N=5\)</span></li>
<li>Repeat steps i-ii 10000 times</li>
<li>Graph the results</li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set some parameters</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>n_experiment <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="co"># Number of new spins we're going to conduct</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># Number of simulations</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Draw random values of p from the posterior</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>p_rand <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="at">n =</span> s, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta) <span class="co"># Same parameters as before</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. For each p, run a binomial experiment (represents samples of W)</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>w_rand <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> s, <span class="at">size =</span> n_experiment, <span class="at">prob =</span> p_rand)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a data frame</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">w =</span> w_rand</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># For each w</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(w) <span class="sc">%&gt;%</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the total</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">count =</span> <span class="fu">n</span>()</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add proportion</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">proportion =</span> count <span class="sc">/</span> <span class="fu">sum</span>(count)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">factor</span>(w)</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> proportion</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> proportion,</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>      <span class="at">label =</span> <span class="fu">paste0</span>(<span class="fu">round</span>(proportion<span class="sc">*</span><span class="dv">100</span>,<span class="dv">1</span>), <span class="st">"%"</span>)</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">vjust =</span> <span class="sc">-</span>.<span class="dv">1</span></span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> scales<span class="sc">::</span>percent</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"W"</span>) <span class="sc">+</span></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability"</span>) <span class="sc">+</span></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">paste0</span>(<span class="st">"Posterior Predictive Distribution for "</span>, n_experiment, <span class="st">" more spins."</span>)</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Another way to think about what we’re doing here is:</p>
<ol type="i">
<li>Find the collection of <em>density</em> values for all <span class="math inline">\(p\)</span> in the posterior distribution</li>
<li>Find the probability distribution of the possible outcomes from a Binomial distribution where <span class="math inline">\(N=5\)</span> for all possible values of <span class="math inline">\(p\)</span> (i.e., independent of our posterior)</li>
<li>Take the average probability value for each possible outcome in (ii) over all values of <span class="math inline">\(p\)</span>, <em>weighted</em> by the posterior density in (i)</li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a set of p representive of its domain</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>p_alt <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">001</span>) <span class="co"># Supposed to represent continuous p</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Posterior density values for each p</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>posterior_alt <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(p_alt, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Probability distribution for each outcome for each p</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>possible_outcomes <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span>n_experiment</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>likelihood_alt <span class="ot">&lt;-</span> </span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>  possible_outcomes <span class="sc">%&gt;%</span> </span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_df</span>(</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">binomial_probability =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> .x, <span class="at">size =</span> n_experiment, <span class="at">prob =</span> p_alt),</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">p =</span> p_alt,</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>        <span class="at">outcome =</span> .x</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Get the posterior predictive distribution</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>posterior_predictive_distribution <span class="ot">&lt;-</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>  likelihood_alt <span class="sc">%&gt;%</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Join to attach the posterior density weight to each value of p</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inner_join</span>(</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> </span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>        <span class="at">p =</span> p_alt,</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>        <span class="at">posterior_density =</span> posterior_alt</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">by =</span> <span class="st">"p"</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># For each possible outcome</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(outcome) <span class="sc">%&gt;%</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the weighted-average probability</span></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">posterior_probability =</span> <span class="fu">sum</span>(binomial_probability <span class="sc">*</span> posterior_density) <span class="sc">/</span> <span class="fu">sum</span>(posterior_density)</span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Make a plot</span></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>posterior_predictive_distribution <span class="sc">%&gt;%</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">factor</span>(outcome)</span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(</span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior_probability</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior_probability,</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>      <span class="at">label =</span> <span class="fu">paste0</span>(<span class="fu">round</span>(posterior_probability<span class="sc">*</span><span class="dv">100</span>,<span class="dv">1</span>), <span class="st">"%"</span>)</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>    <span class="at">vjust =</span> <span class="sc">-</span>.<span class="dv">1</span></span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> scales<span class="sc">::</span>percent</span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"W"</span>) <span class="sc">+</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability"</span>) <span class="sc">+</span></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">paste0</span>(<span class="st">"Posterior Predictive Distribution for "</span>, n_experiment, <span class="st">" more spins."</span>)</span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The distributions from the two approaches are merely identical (slight differences due to simulation variability and inexact integration).</p>
<ol start="3" type="1">
<li>Use the posterior predictive distribution from (2) to calculate the probability of 3 or more water samples in the next 5 tosses.</li>
</ol>
<p>Using the posterior predictive distribution above, we can look at the percent of simulations that resulted in 3 or more water samples:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(w_rand <span class="sc">&gt;=</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1771</code></pre>
</div>
</div>
<p>So there is a 0.177 probability of 3 or more water samples in the next 5 tosses. However, this point estimate is not totally sufficient because we haven’t reported any uncertainty associated with it. Since we know that <span class="math inline">\(W|p \sim Binomial(n,p)\)</span>, the <span class="math inline">\(P(W&gt;=3|p,N)\)</span> is already determined. In this case, we can just calculate it for each random value of <span class="math inline">\(p\)</span> sampled from the posterior:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the binomial probability</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>prob_binom <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="at">q =</span> <span class="dv">2</span>, <span class="at">size =</span> n_experiment, <span class="at">prob =</span> p_rand)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a plot</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> prob_binom</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"P(W&gt;=3|N=5)"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>This one has been stumping me a bit, and I’m not totally confident this is the correct result. Another way I was thinking about it was similar the alternative in (2), namely that we are finding the <span class="math inline">\(P(W&gt;=3|N=5)\)</span> for each value of <span class="math inline">\(p\)</span>, and then weighting that by the posterior density of <span class="math inline">\(p\)</span>. However, it seems like we should be sampling from the predictive distribution in (2) somehow, but if we do that it seems like the precision of our estimates would then just be determined by the number of simulations we run, not the data, which also doesn’t make sense.</p>
</section>
<section id="notes-1" class="level2">
<h2 class="anchored" data-anchor-id="notes-1">Notes</h2>
<p><strong>Goal: Estimate the percent of the globe that is covered in water</strong></p>
<ul>
<li>Think of spinning the globe and stopping on a point and repeating many times</li>
<li>How do we use that collection of points to come up with an estimate? That’s the goal of today’s lecture</li>
<li>First thought is just indicate each time whether land or water appear as the point; however, how does the shape of the globe impact the likelihood that I will come up with land or water on a “random” toss? Has to do with sampling strategy</li>
</ul>
<ol type="1">
<li>Define a generative model</li>
</ol>
<ul>
<li>Think conceptually about scientifically how the sample was produced (how do variables influence one another)</li>
<li>Variables: Things we <em>want</em> to observe/estimate or things we actually do observe</li>
</ul>
<p><span class="math display">\[\bf{p} = \text{proportion of water}\hskip.5inW=\text{water observations}\]</span> <span class="math display">\[N = \text{number of tosses}\hskip.5inL=\text{land observations}\]</span></p>
<ol start="2" type="1">
<li>Define a specific estimand</li>
</ol>
<p>Were interested in the true proportion of water <strong>p</strong></p>
<ol start="3" type="1">
<li>Design a statistical way to produce estimate</li>
</ol>
<ul>
<li>How are these related to each other?
<ul>
<li>N influences W and L (the more tosses leads to change on other variables)</li>
<li>p also influences W and L (i.e., the true proportion dictates the number of water observations and land observations)</li>
<li>The DAG shows relationships, but not what the relationships <em>are</em>. We can say <span class="math inline">\(W,L=f(p,N)\)</span>; what is <span class="math inline">\(f\)</span>?</li>
</ul></li>
<li>Assume a model (e.g., <span class="math inline">\(p\)</span> = .25, then count likely the sample was under that model, do that for all possible models)</li>
</ul>
<ol start="4" type="1">
<li>Test (3) using (1)</li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>sim_globe <span class="ot">&lt;-</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(<span class="at">p =</span> .<span class="dv">7</span>, <span class="at">N =</span> <span class="dv">9</span>) {</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="st">"W"</span>,<span class="st">"L"</span>), <span class="co"># Possible observations</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">size =</span> N, <span class="co"># Number of tosses</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">prob =</span> <span class="fu">c</span>(p, <span class="dv">1</span><span class="sc">-</span>p), <span class="co"># The probability of each possible observation</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_globe</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "W" "W" "W" "W" "W" "W" "W" "W" "W"</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">replicate</span>(<span class="fu">sim_globe</span>(<span class="at">p =</span>.<span class="dv">5</span>, <span class="at">N=</span><span class="dv">9</span>), <span class="at">n=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,] "W"  "L"  "W"  "W"  "L"  "W"  "L"  "W"  "L"  "W"  
 [2,] "L"  "L"  "L"  "W"  "L"  "L"  "W"  "L"  "L"  "W"  
 [3,] "L"  "L"  "W"  "W"  "W"  "W"  "W"  "W"  "W"  "W"  
 [4,] "W"  "W"  "W"  "L"  "W"  "L"  "L"  "W"  "W"  "W"  
 [5,] "W"  "L"  "W"  "W"  "L"  "W"  "W"  "W"  "W"  "L"  
 [6,] "W"  "W"  "L"  "W"  "L"  "W"  "L"  "L"  "W"  "W"  
 [7,] "L"  "L"  "W"  "W"  "W"  "W"  "L"  "L"  "L"  "W"  
 [8,] "W"  "L"  "L"  "W"  "L"  "W"  "W"  "W"  "W"  "W"  
 [9,] "W"  "L"  "W"  "L"  "L"  "W"  "L"  "W"  "W"  "L"  </code></pre>
</div>
</div>
<ul>
<li>Test the intent of the code first</li>
<li>If our procedure doesn’t work when <em>we know</em> the answer, it certainly won’t when we <em>don’t</em> know the answer</li>
</ul>
<p>Infinite sample:</p>
<p><span class="math display">\[p^W(1-p)^L\]</span> Posterior probability:</p>
<p><span class="math display">\[p = \frac{(W+L+1)!}{W!L!}p^W(1-p)^L\]</span></p>
<ul>
<li>This is a <em>Beta</em> distribution, and the likelihood was a <em>Binomial</em>.</li>
<li>The minimum sample size for Bayesian analysis is 1.</li>
<li>The shape of the posterior distribution embodies the sample size</li>
<li>No point estimate, we work with the entire posterior distribution</li>
<li>The distribution <em>is</em> the estimate; always use the entire distribution, never a single point</li>
<li>The fact that an arbitrary interval contains an arbitrary value is not meaningful</li>
</ul>
<ol start="5" type="1">
<li>Analyze sample, summarize</li>
</ol>
<ul>
<li>Implications depend on entire posterior</li>
<li>Average over the uncertainty of the posterior</li>
<li>What can we do with the posterior distribution?
<ul>
<li>We can take samples from it, and then do calculations with the samples</li>
</ul></li>
<li>Posterior Prediction
<ul>
<li>Given what we’ve learned, what would happen if we took more samples?</li>
<li>Sampling distribution (predictive distribution) of draws represents the likelihood of each outcome in a new experiment for a particular value</li>
<li>The <em>posterior predictive</em> distribution then represents the entire distribution of the statistic of interest, and contains all the uncertainty around that estimate (analogous to the sampling distribution of a statistic (e.g., mean) in the frequentist paradigm, except this is completely model-driven by the posterior instead of based on asymptotics in the frequentist approach)</li>
<li>Sampling turns calculus into a data summary problem; this is important when models get complex and numerically intractable to compute by hand</li>
</ul></li>
<li>This generative, Bayesian framework is the optimal approach for causal estimation <em>if your model is correct</em>.</li>
<li>It honestly carries out the assumptions we put into it, using logical implications</li>
<li>Quantitative framework/asset that activates our qualitative knowledge as scientists, subject matter experts, etc. Let’s the subjective and objective work together. Subjectivity is expertise.</li>
</ul>
<p><strong>Misclassification</strong></p>
<ul>
<li><p>Use circles around variable in DAG to represent unobserved vs.&nbsp;observed variables</p></li>
<li><p>Imagine the true number of water samples (W) are unobserved (e.g., measurement error, data error, etc.)</p></li>
<li><p>We observe a <em>contaminated</em> W (called W*) that is the <em>misclassified</em> sample</p></li>
<li><p>W* is caused by the <em>measurement process</em> M. We can get get back to the correct posterior distribution for p if we use M through W*.</p></li>
<li><p>The posterior is honest about the uncertaintly induced by the misclassification process</p></li>
<li><p>When there is measurement error, model it instead of ignoring it (same for missing data, compliance, inclusion)</p></li>
<li><p><em>Key point: Samples do not need to be representative of population to provide good estimates, since we can correct them through our causal diagram (modeling the source, sampling process, etc.)</em></p></li>
<li><p>This concept may also arise if, for example, the globe was not spun equally likely for every point to be selected.</p></li>
</ul>
</section>
</section>
<section id="lecture3" class="level1">
<h1>3. Geocentric Models</h1>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td>3</td>
<td>4</td>
<td>1/13/2023</td>
<td>1/10/2023</td>
</tr>
</tbody>
</table>
<section id="summary-2" class="level2">
<h2 class="anchored" data-anchor-id="summary-2">Summary</h2>
<p>We don’t actually need data to construct a model. Our prior distributions, which account for our baseline knowledge about what reasonable values for unknown parameters may be, can produce estimates on their own. A bare minimum strategy is to choose these such that before seeing data, the output of our model produces scientifically reasonable results–there is no reason to allow our model to produce results that we know cannot happen. Then, our data can be introduced to help guide the parameters to an area of focus. In this sense (thinking of the example of points bumping around in parameter space), the data we collect is really just a tool for our model–the model is the central focus, the data just helps the model go to where it needs to go. Also, the idea that there are no correct priors and that priors are just (normalized) posteriors from previous data, make the idea of Bayesian updating very intuitive. It will be interesting to see in coming lectures how we can extend this linear model framework to more “real life” problems with observational data that have potentially tens or hundreds or thousands of potential drivers, and strategies for accounting for the most important ones. Obviously these basic examples are great to build a foundation, but it seems like a huge (sometimes impossible) hurdle to have the time and resources to be able to fully vet out expert-driven causal diagrams and generative models that fully account for all the things, especially in fast-paced environments when everyone is just so busy and there are so many projects to attend to. I’d imagine this is one of the reasons why frequentist analysis persists so much (at least in medical research), because it’s the way it’s been done and therefore you can get more things done faster, even though in an ideal state a Bayesian approach <em>is</em> the right way to go. Definitely something I’ve thought about time and time again–how can we balance the rigor and detail needed to construct the appropriate models to achieve better inference while still being efficient with peoples’ time? Part of it probably has to do with proving to stakeholders that the inference gained from the “quicker” way is less informative (or just plain wrong) compared to the more involved approach.</p>
</section>
<section id="notes-2" class="level2">
<h2 class="anchored" data-anchor-id="notes-2">Notes</h2>
<ul>
<li>Statistical models can attain arbitrarily accurate predictions without having any explanation or accurate structure (i.e., the model is just plain wrong, but happens to produce accurate predictions at the right time)
<ul>
<li>Example of this is a previous explanation of orbit pattern of Mars: assuming Earth at the center (geocentric), Mars orbits around Earth but also it’s own local orbit (epi-cycles). Using this model, they got very accurate predictions, but this mechanism is completely wrong.</li>
<li>Orbits are actually elliptical and around the sun, not Earth</li>
<li>Even though the first one predicts accurately, because the structure/mechanism is wrong, it doesn’t extend or generalize to other things. However, the correct mechanism is able to explain orbit patterns of all planets in the solar system.</li>
</ul></li>
<li>Linear regression is a large class of statistical golems
<ul>
<li><strong>Geogentric</strong>: describes associations, makes good predictions; mechanistically always wrong (but useful), very good approximation; meaning doesn’t depend on the model, depends on an external causal model. Nothing wrong with it unless you actually believe it is the true mechanism.</li>
<li><strong>Gaussian</strong>: Abstracts away from detail of general error model; mechanistically silent. General argument about symmetry of error.</li>
</ul></li>
</ul>
<p><strong>Gaussian</strong></p>
<ul>
<li>Example: Flip coin, each person take a step to left or right depending on heads/tails, measure distance from center; makes a normal distribution. Why?
<ul>
<li>There are more ways for a sequence of coin tosses to get you close to the middle than there are to get you to the left or right</li>
<li>Many natural processes attract to this behavior because it is adding together small differences</li>
</ul></li>
<li>Two arguments:
<ul>
<li>Generative: summed fluctuations tend towards normal. Ex. growth–added fluctuations over time, same age weight tends to be gaussian</li>
<li>Inferential: estimating mean/variance. Best to use since least informative (maximum entropy)</li>
</ul></li>
<li>Variable does not need to be normally distributed for normal model to be useful. Machine for estimating mean/variance. Contains the least assumptions. (central limit theorem)</li>
</ul>
<p><strong>Skills/Goals for Lecture</strong></p>
<ol type="1">
<li>Learn a standardized language for representing models (generative and statistical)</li>
<li>Calculate posteriors with multiple unknown parameters</li>
<li>How to construct and understand linear models; how to construct posterior predictions from them</li>
</ol>
<p><strong>Reminder of the owl</strong></p>
<ol type="1">
<li>State a clear question; descriptive, causal, anything; but needs to be clear</li>
<li>Sketch causal assumptions using DAGs; good way for non-theorists to realize they have a lot of subject knowledge and can get it on paper</li>
<li>Define a generative model; generates synthetic observations</li>
<li>Use generative model to build estimator; causal/generative assumptions embedded</li>
<li>Test, analyze</li>
<li>Profit: we realize our model was useful, or terrible; either way we gain something</li>
</ol>
<p><strong>Describing models</strong></p>
<ol type="1">
<li>Lists variables</li>
<li>Define each variable as a deterministic or distributional function of other variables</li>
</ol>
<p><strong>Exercise</strong></p>
<ol type="1">
<li>Goal: Describe the association between adult weight and height</li>
<li>Height causes weight H–&gt;W&lt;–(U) (unobserved influences on body weight)</li>
<li>Generative/scientific model: <span class="math inline">\(W=f(H,U)\)</span>, <span class="math inline">\(W=\beta H + U\)</span></li>
</ol>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>sim_weight <span class="ot">&lt;-</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(H,b,sd) {</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    U <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(H),<span class="dv">0</span>,sd)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    W<span class="ot">&lt;-</span>b<span class="sc">*</span>H <span class="sc">+</span> U</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(W)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate height</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>H <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">200</span>,<span class="dv">130</span>,<span class="dv">170</span>)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">sim_weight</span>(H, <span class="at">b=</span>.<span class="dv">5</span>, <span class="at">sd=</span> <span class="dv">5</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(W<span class="sc">~</span>H,<span class="at">col=</span><span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><span class="math display">\[W_i=\beta H_i + U_i\]</span> <span class="math display">\[U_i \sim Normal(0,\sigma)\]</span> <span class="math display">\[H_i \sim Uniform(130, 170)\]</span> 4. Statistical model (estimator)</p>
<ul>
<li>We want to estimate how the average weight changes with height.</li>
</ul>
<p><span class="math display">\[E(W_i|H_i)=\alpha + \beta H_i\]</span></p>
<ul>
<li>Posterior distribution</li>
</ul>
<p><span class="math display">\[P(\alpha, \beta, \sigma|H_i,W_i) = \frac{P(W_i|H_i,\alpha,\beta,\sigma)P(\alpha,\beta,\sigma)}{Z}\]</span></p>
<ul>
<li>Gives the posterior probability of a specific regression line
<ul>
<li>Likelihood: Number of ways we could produce <span class="math inline">\(W_i\)</span>, given a line</li>
<li>Prior: The previous posterior distribution; normalized number of ways previous data could have been produced.</li>
</ul></li>
</ul>
<p><span class="math display">\[W_i \sim Normal(\mu_i, \sigma)\]</span> <span class="math display">\[\mu_i = \alpha + \beta H_i\]</span></p>
<ul>
<li><p>Generally more useful to look at the lines (parameter implications together), instead of individual parameters</p></li>
<li><p>Quadratic approximation</p>
<ul>
<li>Approximate the posterior distribution using a multivariate Gaussian distribution</li>
<li>Use the <code>quap</code> function in the <code>rethinking</code> package</li>
</ul></li>
</ul>
<p><strong>Prior Predictive Distribution</strong></p>
<ul>
<li>Should express scientific knowledge, but <em>softly</em></li>
<li>We can make the model make predictions without using data</li>
<li>Not make ranges that represent the data, but rather just those that make sense based on current knowledge</li>
<li>Account for basic reasonable constraints: In general, patients with more weight have more height, and the weight is less than the height, so <span class="math inline">\(\beta\)</span> is probably between <span class="math inline">\([0,1]\)</span>.</li>
<li>Use these to define some lines based on the assumptions</li>
</ul>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">runif</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">130</span>,<span class="dv">170</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">90</span>),<span class="at">xlab=</span><span class="st">"height(cm)"</span>,<span class="at">ylab=</span><span class="st">"Weight(kg)"</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>) <span class="fu">abline</span>(<span class="at">a=</span>a[j],<span class="at">b=</span>b[j],<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Some of these are probably not plausible (e.g., high height with low weight). Slopes look good but not intercept</li>
<li>We can adjust as needed to create what makes sense</li>
<li>There are no correct priors; only scientifically justifiable priors</li>
</ul>
<ol start="5" type="1">
<li>Validate Model</li>
</ol>
<ul>
<li>Bare minimum to test statistical model</li>
<li>Not because you wrote it, more so to make sure your model works</li>
</ul>
<ol start="6" type="1">
<li>Analyze data</li>
</ol>
<ul>
<li>Plug in your data set into your process</li>
<li>Parameters are not independent, can’t interpret as such</li>
<li>Push out posterior predictions</li>
</ul>
</section>
</section>
<section id="lecture4" class="level1">
<h1>4. Categories and Curves</h1>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td>4</td>
<td>4</td>
<td>1/13/2023</td>
<td>1/11/2023</td>
</tr>
</tbody>
</table>
<section id="summary-3" class="level2">
<h2 class="anchored" data-anchor-id="summary-3">Summary</h2>
<p>The idea of <em>total</em> vs.&nbsp;<em>direct</em> effects is about specifying the statistical model that will allow you to observe the complete effect (i.e., including differences that could be explained by something else in the model) compared to parsing out differences explained by the variable after adjusting for effects explained through other variables. In the lecture example, the total causal effect of sex on weight was determined by using a (Bayesian) intercept-only model, which showed considerable difference is mean weights between male/female. However, when assessing the direct causal effect, a parameter was added to fit separate slopes for male/female in order to block out the effect of sex on weight that is observed through other causes (in this case, height), such that the resulting estimator looked at mean differences in weight <em>at each height</em>–the posterior distribution for this difference yielded little to no direct effect, indicating that most of the difference in weight between male/females is due to height differences. Another interesting aspect of this lecture was how to think about which way an arrow should go when drawing the causal diagram. You should think of the interventions we are willing to consider, and which make logical sense. For example, we drew <span class="math inline">\(H \rightarrow W\)</span> because, given a height, it makes sense to employ interventions (such as weight loss program, exercise, etc.) that could presumably impact the resulting weight, but it doesn’t make a lot of sense to think of trying to change someone’s height given their weight. Also, declaring something as a <em>cause</em> of something, generally you first want to think about whether an intervention can be employed, but if not can still make sense if it is a proxy for something else (e.g., age encapsulates time, among many other things that presumably do cause height). We can use flexible curves to fit things (e.g., splines), but we want to make sure we vet out any erroneous areas where estimates don’t make sense, and add necessary restrictions to alleviate. So far, these lectures have given great optimism and excitement for how to approach modeling. I want to be confident in the models I produce, and I think the generative framework is the right approach to be able to believe in the results you are producing. I see so much published research from observational data that declare something statistically significant for a given research hypothesis and say “we adjusted for all these confounders”. Even if I feel fine about the math/statistical procedure, I’m always skeptical about the conclusions that are drawn from it, and quite frankly, don’t feel like it means much at all for really making a decision–there are just too many limitations about all sorts of things. The generative approach gives the tools and rigor to be much more confident in the results, and if we can be more demanding of that rigor, time and energy, it should yield more benefit in the long run. I’d rather spend more time getting to a confident conclusion than just pumping out results.</p>
<section id="a-check-for-understanding-1" class="level3">
<h3 class="anchored" data-anchor-id="a-check-for-understanding-1">A check for understanding</h3>
<p>During (and after) the lecture, it took me a while to gain intuition about what was happening in the generative simulation for the model:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
  A(Sex) --&gt; C(Weight)
  A --&gt; B(Height)
  B --&gt; C
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The code was written in the following way:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># S = 1 female, S = 2 male</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>sim_HW <span class="ot">&lt;-</span> <span class="cf">function</span>(S,b,a) {</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> <span class="fu">length</span>(S)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  H <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(S<span class="sc">==</span><span class="dv">1</span>,<span class="dv">150</span>,<span class="dv">160</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>  W <span class="ot">&lt;-</span> a[S] <span class="sc">+</span> b[S]<span class="sc">*</span>H <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(S,H,W)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">100</span>,<span class="dv">1</span>,.<span class="dv">5</span>) <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">sim_HW</span>(S, <span class="at">b=</span><span class="fu">c</span>(.<span class="dv">5</span>,.<span class="dv">6</span>), <span class="at">a=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  S        H        W
1 1 151.2666 79.57199
2 2 159.8573 99.75957
3 1 149.7856 76.55384
4 2 166.8430 95.06392
5 2 158.8711 94.72542
6 1 157.5824 77.38920</code></pre>
</div>
</div>
<p>First, the indexing used here <code>b[S]</code> was odd because <code>b</code> is a vector of length 2, and <code>S</code> is a vector of length 100. But all it is doing is making a vector of length 100 by looking up the index of <code>b</code> at each spot (since <code>S</code> is either 1 or 2). I didn’t know you could index like that in <code>R</code> but I guess you learn something everyday. Anyway, that was not the real thing that confused me.</p>
<p>In the lecture, he states that the <code>a</code> term represents the <em>direct</em> effect of sex on weight, and the <code>b</code> term represents the <em>indirect</em> effect (i.e., proportionality/slope for each sex). It’s clear that there are separate lines created for each sex, and you can see the form of an intercept and slope for each one. In my mind, I’m thinking this has to be similar to an interaction in the model, but it wasn’t intuitive to me how this really played out and/or there was something different going on here. After some thought on a notepad, it is exactly what I was thinking–just a linear model with an interaction term between sex and height, though it is reparameterized a little to create the <em>symmetry</em> of effects as discussed in the lecture. Anyway, here is how it translates:</p>
<p>Currently, we have that the sex indicators are as follows:</p>
<p><span class="math display">\[S = 1 (female), 2(male)\]</span> Then, the effect of height on weight for each sex is as follows:</p>
<p><span class="math display">\[b=(b_{S_1},b_{S_2}) = (0.5, 0.6)\]</span> Finally, the intercept within each line is:</p>
<p><span class="math display">\[a=(a_{S_1},a_{S_2})=(0,0)\]</span> This leads to:</p>
<p><span class="math display">\[W_{S_1} = a_{S_1} + b_{S_1}H + \epsilon_i = .5H+\epsilon_i\]</span> <span class="math display">\[W_{S_2} = a_{S_2} + b_{S_1}H + \epsilon_i = .6H + \epsilon_i\]</span> We could think of this as a single model equation with four (4) regression coefficients looking like the following:</p>
<p><span class="math display">\[W = \beta_1 S_1 + \beta_2 S_2 + \beta_3 H \times S_1 + \beta_4 H \times S_2 + \epsilon_i\]</span> where</p>
<p><span class="math display">\[S_1 = 1 \text{ if female; 0 otherwise}\]</span> <span class="math display">\[S_2 = 1 \text{ if male; 0 otherwise}\]</span> There is no intercept term in the model. Instead, there are <em>symmetric</em> parameterizations for males and females, instead of making the effects relative to one another (which, as mentioned in the lecture, makes it more intuitive to make priors for). The design matrix for this model would then look something like:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tribble</span>(</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>S1, <span class="sc">~</span>S2, <span class="sc">~</span>H_S1, <span class="sc">~</span>H_S2, <span class="sc">~</span>W,</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">150</span>, <span class="dv">0</span>, <span class="dv">80</span>,</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">160</span>, <span class="dv">90</span>,</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">140</span>, <span class="dv">70</span>,</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">165</span>, <span class="dv">0</span>, <span class="dv">75</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 5
     S1    S2  H_S1  H_S2     W
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1     1     0   150     0    80
2     0     1     0   160    90
3     0     1     0   140    70
4     1     0   165     0    75</code></pre>
</div>
</div>
<p>Basically, every time <code>S1</code> is <code>1</code> (female), then <code>S2</code> is <code>0</code> (male), as well as the corresponding value for <code>H</code>.</p>
<p><em>I may have to rethink what I just wrote a bit as the the <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> columns are actually completely redundant, so not sure if this is right yet</em></p>
<p>So how would we parameterize this in a more classical regression model? If we just rewrite a few things. Let:</p>
<p><span class="math display">\[S=(0(female), 1(male))\]</span> Then we assume the model is:</p>
<p><span class="math display">\[W = \beta_0+\beta_1 S+\beta_2 H+\beta_3 S\times H + \epsilon_i\]</span> If we translate parameter values from the example,</p>
<p><span class="math display">\[\beta_0 = 0 \hskip.1in \beta_1 = 0\]</span> <span class="math display">\[\beta_2 = .5 \hskip.1in \beta_3 = .6-.5 = .1\]</span> We then get:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
W_{S=0(female)}
&amp;= \beta_0 + \beta_1(0) + \beta_2H+\beta_3 0 \times H + \epsilon_i \\
&amp;= 0 + 0(0) + .5H + .1(0 \times H) + \epsilon_i \\
&amp;= 0.5H + \epsilon_i
\end{split}
\end{equation}
\]</span></p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
W_{S=1(male)}
&amp;= \beta_0 + \beta_1(1) + \beta_2H+\beta_3 1 \times H + \epsilon_i \\
&amp;= 0 + 0(1) + .5H + .1(1 \times H) + \epsilon_i \\
&amp;= 0.5H + 0.1H + \epsilon_i \\
&amp;= 0.6H + \epsilon_i
\end{split}
\end{equation}
\]</span></p>
<p>This makes it much more clear why the <em>direct</em> effect is zero, since the main effect of sex is zero in this model. We only see an effect from sex through the interaction with height, which is what is known as the <em>indirect</em> effect.</p>
</section>
</section>
<section id="homework-1" class="level2">
<h2 class="anchored" data-anchor-id="homework-1">Homework</h2>
<ol type="1">
<li>From the <code>Howell1</code> dataset, consider only the people younger than 13 years old. Estimate the causal association between age and weight. Assume age influences weight through two paths. First, age influences height, and height influences weight. Second, age directly influences weight through age-related changes in muscle growth and body proportions. Draw the DAG that represents these causal relationships. And then write a generative simulation that takes age as an input and simulates height and weight, obeying the relationships in the DAG.</li>
</ol>
<p>First, we’ll import the dataset directly from the package’s <a href="https://github.com/rmcelreath/rethinking">Github repository</a>. We will filter to those &lt; 13 years old, and convert height to inches, and weight to lbs:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>howell1 <span class="ot">&lt;-</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">read_delim</span>(</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv"</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">delim =</span> <span class="st">";"</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep those younger than 13</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&lt;</span> <span class="dv">13</span>) <span class="sc">%&gt;%</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert the units (more intuitive for me)</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">height =</span> height <span class="sc">/</span> <span class="fl">2.54</span>,</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> weight <span class="sc">*</span> <span class="fl">2.205</span></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 544 Columns: 4
── Column specification ────────────────────────────────────────────────────────
Delimiter: ";"
dbl (4): height, weight, age, male

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>howell1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 146 × 4
   height weight   age  male
    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1   48     43.3  12       1
 2   41.5   30.8   8       0
 3   34     23.1   6.5     0
 4   43     35.3   7       0
 5   45     39.4  11       1
 6   48     45.0   8       1
 7   50.8   51.5  12       0
 8   38.5   29.3   5       0
 9   43.5   34.0   9       0
10   38.5   28.1   5       0
# ℹ 136 more rows</code></pre>
</div>
</div>
<p>Next, we can write the causal diagram as described:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
  A(Age) --&gt; C(Weight)
  A --&gt; B(Height)
  B --&gt; C
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>If we let</p>
<p><span class="math display">\[A=Age \hskip.1in H=Height \hskip.1in W=Weight\]</span></p>
<p>Then, we assume that:</p>
<p><span class="math display">\[H = f_H(A) \hskip.2in W = f_W(A,H)\]</span> Finally, we can write the generative simulation to produce synthetic data governed by the DAG:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulating synthetic children</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>sim_children <span class="ot">&lt;-</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(N) {</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Generate uniform ages</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    A <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, <span class="dv">0</span>, <span class="dv">13</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Generate heights as a linear combination of age</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>    H <span class="ot">&lt;-</span> <span class="dv">22</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>A <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Generate weights as a linear combination of age and height</span></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    W <span class="ot">&lt;-</span> .<span class="dv">8</span><span class="sc">*</span>H <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> .<span class="dv">5</span>)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make a data frame</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(A, H, W)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We first generate ages uniformly from 0 to 13, so</p>
<p><span class="math display">\[A \sim Uniform(0,13)\]</span></p>
<p>Then, we generate heights from a normal distribution with means that are linearly related to the age.</p>
<p><span class="math display">\[H \sim Normal(\mu =22 + 2 \times A, \sigma = 3)\]</span> Notice the intercept term to ensure a positive height for children who are 0 years old. <em>Note: A distribution like the Gamma may be better here to ensure we don’t get negative heights. For younger ages, I would assume that the distribution of heights has a little right-skew. In any case, we’ll move forward with the Normal distribution here for simplicity sake.</em></p>
<p>Then we generate the weights as a linear function of the observed age and heights.</p>
<p><span class="math display">\[W \sim Normal(\mu=.8H, \sigma = .5)\]</span> We make the assumption that there is a linear relationship between weight with age and height, and that for any age, the increase in mean weight per inch increase in height is the same. In fact, the effect for age is 0 since it is observed through height.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate some children</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>simmed_children <span class="ot">&lt;-</span> <span class="fu">sim_children</span>(<span class="dv">200</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(simmed_children)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/unnamed-chunk-30-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li><p>Use a linear regression to estimate the <strong>total</strong> causal effect of each year of growth on weight.</p></li>
<li><p>Now suppose the causal association between age and weight might be different between boys and girls. Use a single linear regression, with a categorical variable for sex, to estimate the total causal effect of age on weight separately for boys and girls. How do boys and girls differ? Provide one or more posterior contrasts as a summary.</p></li>
</ol>
</section>
<section id="notes-3" class="level2">
<h2 class="anchored" data-anchor-id="notes-3">Notes</h2>
<ul>
<li>The linear regression can approximate anything, so we need to design it with the causal model in mind</li>
<li>Generative models + multiple estimands, we’ll have multiple estimands</li>
<li>Need post-processing of posterior distribution to gain inference of joint distributino</li>
<li>We require categories, splines, etc. to build causal estimators</li>
<li>Need to <em>stratify</em> by category to get at the estimands we want (separate lines)</li>
</ul>
<p><strong>Example</strong></p>
<ul>
<li>Extend example above to include patient sex, age</li>
<li>Need to determine how height, weight, sex are causally related (add to DAG), and statistically related</li>
<li>To determine which way the arrows go, think about the interventions you’re willing to consider</li>
<li>Don’t have to draw them, but the implied unobserved causes of each variable are implied
<ul>
<li>These are ignorable <em>unless shared</em> across variables</li>
<li>Ex. temperature is a cause of sex and weight in some species</li>
</ul></li>
<li>What is the causal effect of S on W?
<ul>
<li>Accounts for direct and indirect effect</li>
<li>We can also ask what is the direct causal effect of S on W?</li>
<li>These questions require different models</li>
</ul></li>
<li>Generally want to assign the same prior for parameters for each category level (below)
<ul>
<li>Using indexing is advantageous because you have symmetry such that all parameters can get the same prior, they are all interpreted the same within their levels</li>
<li>Using indicators makes parameters relative to other levels, which causes you have to put priors on other parameters because it is an adjustment parameter (one is an average, one is an adjustment to an average)</li>
</ul></li>
</ul>
<p><span class="math display">\[W_i \sim Normal(\mu_i, \sigma) \hskip.1in \mu_i=\alpha_{S[i]}\]</span> <span class="math display">\[\alpha = [\alpha_1, \alpha_2] \hskip.1in \alpha_j \sim Normal(60,10)\]</span> <strong>Total Causal Effect</strong></p>
<ul>
<li>Simulate one data set of all males, another of all females, look at the average difference in weight
<ul>
<li>This is the actual causal effect</li>
<li>Then you can generate a random data set, run the modeling process, and then ensure that the model provides the expected estimate</li>
</ul></li>
<li>Look at the posterior distribution of the mean difference, and randomly draw samples from the individual posteriors and compute the differences to answer questions like “what is the probability that a randomly selected male will be heavier than a randomly selected female?”</li>
<li>This was basically just an intercept-only model for sex, and the effect due to height would be captured in that difference</li>
</ul>
<p><strong>Direct Effect</strong></p>
<ul>
<li>How do we partial out the indirect effect of Height (block it)?
<ul>
<li>Stratify by height to block the association between S and W that is transmitted through H</li>
</ul></li>
<li>Difference in intercept, the indirect is slope differences</li>
<li>Here, the model allows for separate slopes by sex, so we can tease out the impact of height
<ul>
<li>Center the height to make the interpretation of the intercept be the average</li>
<li>Makes priors more intuitive, and computation easier</li>
</ul></li>
</ul>
<p><span class="math display">\[W_i \sim Normal(\mu_i, \sigma) \hskip.1in \mu_i=\alpha_{S[i]} + \beta_{S[i]}(H_i-\bar{H})\]</span> <span class="math display">\[\alpha=[\alpha_1,\alpha_2] \hskip.1in \beta=[\beta_1,\beta_2]\]</span></p>
<ul>
<li>In this case, nearly all the total effect of sex on weight is explained through height (the direct effect (posterior of the difference between weights at each height) is nearly 0 at all heights)</li>
</ul>
<p><strong>Curve Fitting</strong></p>
<ul>
<li>We use linear models to do this; i.e., it’s not mechanistic, but we use it wisely</li>
<li>Strategies
<ul>
<li>Polynomials: Don’t do it; no local smoothing, only global; learn to much from data in regions that lie far away
<ul>
<li>It’s not worth having a model that looks OK for most of the data that we know is completely erroneous (e.g., parabola at some point shows babies get heavier as their height decreases, which we know is wrong); even though this is a small portation of observations, it’s still knowingly wrong, so why use it?</li>
</ul></li>
<li>Splines &amp; GAMs: Not as bad as polynomials; add total many locally trained terms</li>
</ul></li>
</ul>
<p><strong>Splines</strong></p>
<ul>
<li>Flexible curve that will find trends</li>
<li>B-splines are linear models containing additive terms with synthetic variables
<ul>
<li>Think of it as a collection of individual curves (basis functions), but the weight of each basis function is non-zero at only particular areas of x, and spline is the sum of the curves at a particular point</li>
</ul></li>
</ul>
<p><span class="math display">\[\mu_i = \alpha + w_1B_{i,1} + w_2B_{i,2} + ...\]</span></p>
<ul>
<li>Ideal model for age/height would be to account for what we know about human biology: infant, toddler, adolescent, adult. In the first 3, we expect only upward growth, so we should constrain.</li>
</ul>
<p><strong>Full Luxury Bayes</strong></p>
<ul>
<li>Equivalent approach is to use one model for entire causal sample</li>
<li>Then run simulations from overall system to get answers to specific queries</li>
</ul>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.zajichekstats\.com\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb53" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Statistical Rethinking 2023 Class Notes"</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Alex Zajichek"</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "1/1/2023"</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "feature.png"</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Bayesian Statistics</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Causal Inference</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>This document is intended to be a repository for my (raw, unedited) notes, interpretations, examples, and summaries from the <span class="co">[</span><span class="ot">Statistical Rethinking 2023</span><span class="co">](https://github.com/rmcelreath/stat_rethinking_2023)</span> course (which Richard McElreath has graciously made available for free (!) covering <span class="co">[</span><span class="ot">his book</span><span class="co">](https://xcelab.net/rm/statistical-rethinking/)</span>). I'm not actually enrolled in the course, but just casually following the lectures and material. I have a strong interest in learning and incorporating Bayesian analysis and causal principles into my work, and this seemed like a great opportunity to build a foundation for that.</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a><span class="fu"># Table of Contents</span></span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="co">[</span><span class="ot">Science Before Statistics</span><span class="co">](#lecture1)</span></span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="co">[</span><span class="ot">Garden of Forking Data</span><span class="co">](#lecture2)</span></span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="co">[</span><span class="ot">Geocentric Models</span><span class="co">](#lecture3)</span></span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span><span class="co">[</span><span class="ot">Categories and Curves</span><span class="co">](#lecture4)</span></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup}</span></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a><span class="in"># Load some packages</span></span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a><span class="in">library(tidyverse)</span></span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a><span class="fu"># 1. Science Before Statistics {#lecture1}</span></span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>Week #    Lecture #   Chapter(s)    Week End    Notes Taken</span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>------    ---------   ----------    --------    -----------</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a>1         1           1             1/6/2023    1/3/2023</span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a>This course focus is on scientific modeling via causal inference, which is focused on identifying causes in *observational* data. Causal Inference requires us to consider the mechanism of a phenomenon, and think about not only which variables cause other variables, but in what order--subject matter expertise is of utmost importance, and we don't really depend on the data at hand until the very end of our inference process. Causal modeling must become the foundation to do analysis by--we can't just do simple statistics in one project and then think about causal modeling in another--samples are from populations and there are causes associated with why we observed the sample we did, even if we're answering very basic questions. Also, *Bayesian* modeling as a means to performing causal inference is not due to philosophical reasons (e.g., frequentist vs. Bayesian), it's more so because a Bayesian framework provides the most natural tools to employ the specified causal model (i.e., if the frequentist model made sense for answering the causal question, we'd use it). The generative aspect of Bayesian modeling is one aspect in particular that makes it very inviting to represent the causal model in a statistical framework, and apply distributions. Finally, coding is not just a means to employ the math, but rather needs to be treated as part of the product, therefore employing software engineering principles, having documentation, making things reproducible. These things need to be employed if you really want to advance knowledge with confidence.</span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Notes</span></span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-42"><a href="#cb53-42" aria-hidden="true" tabindex="-1"></a>**Overview**</span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-44"><a href="#cb53-44" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Most interested in Causal Inference, focusing on the *science* before the *statistics*</span>
<span id="cb53-45"><a href="#cb53-45" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We must be able to talk about causes to obtain scientific knowledge, why else would we do it?</span>
<span id="cb53-46"><a href="#cb53-46" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Causes can't be extracted from data; must come from knowledge, assumptions</span>
<span id="cb53-47"><a href="#cb53-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-48"><a href="#cb53-48" aria-hidden="true" tabindex="-1"></a>**What is Causal Inference?**</span>
<span id="cb53-49"><a href="#cb53-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-50"><a href="#cb53-50" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It is more than associations; associations are bi-directional, and correlation is only a basic measure of association;</span>
<span id="cb53-51"><a href="#cb53-51" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It is all about intervention, directionality, and the *prediction* of the consequence of changing one variable on another (asking *what-if?*)</span>
<span id="cb53-52"><a href="#cb53-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-53"><a href="#cb53-53" aria-hidden="true" tabindex="-1"></a>**Causal Imputation**</span>
<span id="cb53-54"><a href="#cb53-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-55"><a href="#cb53-55" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>This is about being able to construct *counterfactual* outcomes</span>
<span id="cb53-56"><a href="#cb53-56" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Asking the question, *what if I had done something else?*</span>
<span id="cb53-57"><a href="#cb53-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We only observe a single outcome, but we want to know what would have happened had a certain intervention not taken place</span>
<span id="cb53-58"><a href="#cb53-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-59"><a href="#cb53-59" aria-hidden="true" tabindex="-1"></a>**Directed Acyclic Graph (DAG)**</span>
<span id="cb53-60"><a href="#cb53-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-61"><a href="#cb53-61" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Nothing more than an abstraction about which variables cause which other variables</span>
<span id="cb53-62"><a href="#cb53-62" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Shows the direction at which variables cause each other, but doesn't specify *how* (i.e., effect shapes, etc.)</span>
<span id="cb53-63"><a href="#cb53-63" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We can use this to know which things to control for, answer hypothetical interventions, under the assumption that the model is true</span>
<span id="cb53-64"><a href="#cb53-64" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It provides a tool to answer very specific questions (queries); not necessarily all questions lead to the same statistical model, but the appropriate statistical model can be derived from the causal model depending on the question</span>
<span id="cb53-65"><a href="#cb53-65" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Intuition Pumps*: Gets the researcher to think about mechanism; great way to problem solve with SME's without looking at the data (which is how it should be)</span>
<span id="cb53-66"><a href="#cb53-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-67"><a href="#cb53-67" aria-hidden="true" tabindex="-1"></a>**Golems (statistical models)**</span>
<span id="cb53-68"><a href="#cb53-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-69"><a href="#cb53-69" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Metaphor for what a statistical model is; it's a very useful machine that will do what it's asked very well, but has no wisdom or forethought</span>
<span id="cb53-70"><a href="#cb53-70" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Does not know the intent of the task</span>
<span id="cb53-71"><a href="#cb53-71" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistical models are just objective tools, but we need causal models to know how and when certain models are actually appropriate</span>
<span id="cb53-72"><a href="#cb53-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-73"><a href="#cb53-73" aria-hidden="true" tabindex="-1"></a>**Statistical Models**</span>
<span id="cb53-74"><a href="#cb53-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-75"><a href="#cb53-75" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Having a flowchart of tests is not useful, except maybe in the *experimental* setting (remember we're talking observational data)</span>
<span id="cb53-76"><a href="#cb53-76" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Statistical models/tests don't make a clear relationship between the research and the data; it's just math</span>
<span id="cb53-77"><a href="#cb53-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-78"><a href="#cb53-78" aria-hidden="true" tabindex="-1"></a>**Hypotheses &amp; Models**</span>
<span id="cb53-79"><a href="#cb53-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-80"><a href="#cb53-80" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We need *generative* causal models that are guided by the DAG's</span>
<span id="cb53-81"><a href="#cb53-81" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We need *estimands* that are statistical models justified by the generative models (how do we quantify what we're after?)</span>
<span id="cb53-82"><a href="#cb53-82" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Introduce real data at the end--this is the easy part</span>
<span id="cb53-83"><a href="#cb53-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-84"><a href="#cb53-84" aria-hidden="true" tabindex="-1"></a>**Justifying Controls**</span>
<span id="cb53-85"><a href="#cb53-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-86"><a href="#cb53-86" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Cannot just control for everything in your dataset like is done so much in current research (e.g., colliders have undesired effect)</span>
<span id="cb53-87"><a href="#cb53-87" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Need the causal model (DAG) to be able to deduce what should be controlled for based on the specific question that is asked</span>
<span id="cb53-88"><a href="#cb53-88" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>*Adjustment Set:* The variables determined appropriate to control for for a particular query</span>
<span id="cb53-89"><a href="#cb53-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-90"><a href="#cb53-90" aria-hidden="true" tabindex="-1"></a>**Why Bayesian?**</span>
<span id="cb53-91"><a href="#cb53-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-92"><a href="#cb53-92" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Bayesian happens to be the easiest approach for generative models; it's not because we're stuck in a philosophical debate</span>
<span id="cb53-93"><a href="#cb53-93" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Easiest way to take the scientific structure of the assumed model and generate it, since it naturally has *direction* (i.e., priors)</span>
<span id="cb53-94"><a href="#cb53-94" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In most cases, Bayes can be appropriate (sometimes not--cut cake with chainsaw)</span>
<span id="cb53-95"><a href="#cb53-95" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Measurement error, missing data, latent variables, regularization</span>
<span id="cb53-96"><a href="#cb53-96" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>It is *practical*, not *philosophical*</span>
<span id="cb53-97"><a href="#cb53-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-98"><a href="#cb53-98" aria-hidden="true" tabindex="-1"></a>**Owls**</span>
<span id="cb53-99"><a href="#cb53-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-100"><a href="#cb53-100" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Classic joke: Step 1 = Draw two circles, Step 2 = draw remaining owl</span>
<span id="cb53-101"><a href="#cb53-101" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Programming and technical things tend to be taught this way, but we want to avoid this and document all the intermediate steps</span>
<span id="cb53-102"><a href="#cb53-102" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We need to have an explicit workflow with clear steps</span>
<span id="cb53-103"><a href="#cb53-103" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We need to treat coding/scripting seriously, not just a means to something (apply software engineering principles, documentation, quality control)</span>
<span id="cb53-104"><a href="#cb53-104" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Understand what you are doing, document your work and reduce error, have a respectable scientific workflow, be professional and organized to maintain *reproducible* scientific knowledge, otherwise it's all bullshit</span>
<span id="cb53-105"><a href="#cb53-105" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Workflow</span>
<span id="cb53-106"><a href="#cb53-106" aria-hidden="true" tabindex="-1"></a><span class="ss">    1.  </span>Theoretical Estimand (what are we trying to do?)</span>
<span id="cb53-107"><a href="#cb53-107" aria-hidden="true" tabindex="-1"></a><span class="ss">    2.  </span>Scientific (Causal) Model (DAG + Generative)</span>
<span id="cb53-108"><a href="#cb53-108" aria-hidden="true" tabindex="-1"></a><span class="ss">    3.  </span>Use 1 &amp; 2 to build appropriate statistical model</span>
<span id="cb53-109"><a href="#cb53-109" aria-hidden="true" tabindex="-1"></a><span class="ss">    4.  </span>Simulate from 2 to validate that 3 yields 1</span>
<span id="cb53-110"><a href="#cb53-110" aria-hidden="true" tabindex="-1"></a><span class="ss">    5.  </span>Analyze the actual data</span>
<span id="cb53-111"><a href="#cb53-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-112"><a href="#cb53-112" aria-hidden="true" tabindex="-1"></a><span class="fu"># 2. Garden of Forking Data {#lecture2}</span></span>
<span id="cb53-113"><a href="#cb53-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-114"><a href="#cb53-114" aria-hidden="true" tabindex="-1"></a>Week #    Lecture #   Chapter(s)    Week End    Notes Taken</span>
<span id="cb53-115"><a href="#cb53-115" aria-hidden="true" tabindex="-1"></a>------    ---------   ----------    --------    -----------</span>
<span id="cb53-116"><a href="#cb53-116" aria-hidden="true" tabindex="-1"></a>1         2           2, 3          1/6/2023    1/6/2023</span>
<span id="cb53-117"><a href="#cb53-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-118"><a href="#cb53-118" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb53-119"><a href="#cb53-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-120"><a href="#cb53-120" aria-hidden="true" tabindex="-1"></a>This scientific modeling framework provides an _objective_ process to incorporate _subjective_ (expert, scientfic) knowledge into the modeling process, enabling us to incorporate all of the uncertainty associated with those processes, predicated on the assumption of the causal model. Further, one of the key takeaways was that _samples do not need to be representative of the population for us to provide good estimates_. This is profound because generally we are taught the opposite, but because of the process, we can explicitly account for how we know/assume the data was generated, and use that information to create a good estimate of the quantity we are interested in. This is much more _practical_ than the assumptions that are made in a typical frequentist analysis--which tend to be blindly made which ironically makes them more wrong than the "subjective" information in the generative approach. We can then use sampling of our posterior distribution(s) to answer questions about what might happen if we do another experiment, etc. (e.g., what if we take 10 more samples?). Instead of relying on asymptotics for the sampling distribution of a statistic (frequentist), we can just take samples from the posterior for any complex quantity of interest and get the uncertainty surrounding that. This is especially important once we are dealing with analytically intractable posteriors that don't have closed form solutions. Instead of needing expert-level calculus knowledge for such problem, we just have to follow the same workflow as in this basic problem. After years of frequentist modeling, that is always full of limitations and disatisfaction in the results, this approach will lead to much more rewarding scientific discovery and confidence in the conclusions of research.</span>
<span id="cb53-121"><a href="#cb53-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-122"><a href="#cb53-122" aria-hidden="true" tabindex="-1"></a><span class="fu">### A check for understanding</span></span>
<span id="cb53-123"><a href="#cb53-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-124"><a href="#cb53-124" aria-hidden="true" tabindex="-1"></a>Let's go through and reproduce some of the content/concepts from slides but using our own explanation, implementation and interpretation along the way. </span>
<span id="cb53-125"><a href="#cb53-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-126"><a href="#cb53-126" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1. What is the objective?</span></span>
<span id="cb53-127"><a href="#cb53-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-128"><a href="#cb53-128" aria-hidden="true" tabindex="-1"></a>The main question asked in the demonstration was _what proportion of the globe is water?_. Thus, the quantity we are interested in is a single quantity: the _true_ proportion of of the globe that is water. </span>
<span id="cb53-129"><a href="#cb53-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-130"><a href="#cb53-130" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2. What is the sampling strategy?</span></span>
<span id="cb53-131"><a href="#cb53-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-132"><a href="#cb53-132" aria-hidden="true" tabindex="-1"></a>We want to collect data to try to answer the question of interest. This will be done by spinning the globe and dropping a pin at a random location to indicate if it is either land or water. Some initial assumptions are</span>
<span id="cb53-133"><a href="#cb53-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-134"><a href="#cb53-134" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>All points on the globe are equally-likely to be selected</span>
<span id="cb53-135"><a href="#cb53-135" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Any given point on the globe is either land or water (only two possibilities)</span>
<span id="cb53-136"><a href="#cb53-136" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There is no measurement error associated with indicating if the selected point was land or water</span>
<span id="cb53-137"><a href="#cb53-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-138"><a href="#cb53-138" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3. What is the generative model?</span></span>
<span id="cb53-139"><a href="#cb53-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-140"><a href="#cb53-140" aria-hidden="true" tabindex="-1"></a>We want to consider the different variables at play here as it relates to any observed sample we get as a result of the sampling strategy. First and foremost, the primary _unknown_ parameter is:</span>
<span id="cb53-141"><a href="#cb53-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-142"><a href="#cb53-142" aria-hidden="true" tabindex="-1"></a>$$p=\text{proportion of water on the globe}$$</span>
<span id="cb53-143"><a href="#cb53-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-144"><a href="#cb53-144" aria-hidden="true" tabindex="-1"></a>The other two at play (under this simplistic model) are:</span>
<span id="cb53-145"><a href="#cb53-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-146"><a href="#cb53-146" aria-hidden="true" tabindex="-1"></a>$$N=\text{Number of globe spins} \hskip.5in W=\text{Number of spins resulting in water}$$</span>
<span id="cb53-147"><a href="#cb53-147" aria-hidden="true" tabindex="-1"></a>_Note that the number of spins resulting in land is just $N-W$_</span>
<span id="cb53-148"><a href="#cb53-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-149"><a href="#cb53-149" aria-hidden="true" tabindex="-1"></a>With the variables defined, the next step is determine how these variables relate to each other. We'll use the following DAG:</span>
<span id="cb53-150"><a href="#cb53-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-153"><a href="#cb53-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb53-154"><a href="#cb53-154" aria-hidden="true" tabindex="-1"></a><span class="in">flowchart LR</span></span>
<span id="cb53-155"><a href="#cb53-155" aria-hidden="true" tabindex="-1"></a><span class="in">  A(p) --&gt; C(W)</span></span>
<span id="cb53-156"><a href="#cb53-156" aria-hidden="true" tabindex="-1"></a><span class="in">  B(N) --&gt; C</span></span>
<span id="cb53-157"><a href="#cb53-157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-158"><a href="#cb53-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-159"><a href="#cb53-159" aria-hidden="true" tabindex="-1"></a>This assumes that the number of water spins observed in our sample is determined by:</span>
<span id="cb53-160"><a href="#cb53-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-161"><a href="#cb53-161" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The true proportion of water on the globe</span>
<span id="cb53-162"><a href="#cb53-162" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The total number of spins of the globe made (samples)</span>
<span id="cb53-163"><a href="#cb53-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-164"><a href="#cb53-164" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4. What is the statistical model/estimation procedure?</span></span>
<span id="cb53-165"><a href="#cb53-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-166"><a href="#cb53-166" aria-hidden="true" tabindex="-1"></a>Let's suppose we execute the sampling procedure which yields the following response vector:</span>
<span id="cb53-167"><a href="#cb53-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-170"><a href="#cb53-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-171"><a href="#cb53-171" aria-hidden="true" tabindex="-1"></a>observed_sample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># 1 = water; 0 = land</span></span>
<span id="cb53-172"><a href="#cb53-172" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">sum</span>(observed_sample) <span class="co"># Number of water samples</span></span>
<span id="cb53-173"><a href="#cb53-173" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">length</span>(observed_sample) <span class="co"># Number of spins</span></span>
<span id="cb53-174"><a href="#cb53-174" aria-hidden="true" tabindex="-1"></a>W; N</span>
<span id="cb53-175"><a href="#cb53-175" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-176"><a href="#cb53-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-177"><a href="#cb53-177" aria-hidden="true" tabindex="-1"></a>We just need to _count_ all of the ways that this sample could have arose across all of the different possibilities of $p$, and then estimate $p$ as that of where the sample was most likely to have occurred.</span>
<span id="cb53-178"><a href="#cb53-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-179"><a href="#cb53-179" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Basic (incorrect) solution with finite possibilities</span></span>
<span id="cb53-180"><a href="#cb53-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-181"><a href="#cb53-181" aria-hidden="true" tabindex="-1"></a>We know that there are infinitely many possibilities for $p$. Let's first go through this assuming the globe is that of a 4-sided die, such that each side is land or water, implying the only possibilities are $p \in (0,.25,.50,.75,1)$. For each possible value of $p$, what is number of ways we could have observed our sequence of data? (thinking of the generative process, starting with $N$ and $p$).</span>
<span id="cb53-182"><a href="#cb53-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-183"><a href="#cb53-183" aria-hidden="true" tabindex="-1"></a>First of all, we can set our _possible_ set of parameter values, and the number of "sides" of the globe this implies (i.e., we're saying that there are only 4 sides and each one is either Water or Land, so we have a limited number of $p$ values that could occur).</span>
<span id="cb53-186"><a href="#cb53-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-187"><a href="#cb53-187" aria-hidden="true" tabindex="-1"></a><span class="co"># Set possible values for p</span></span>
<span id="cb53-188"><a href="#cb53-188" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, .<span class="dv">25</span>, .<span class="dv">5</span>, .<span class="dv">75</span>, <span class="dv">1</span>)</span>
<span id="cb53-189"><a href="#cb53-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-190"><a href="#cb53-190" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of sides of globe</span></span>
<span id="cb53-191"><a href="#cb53-191" aria-hidden="true" tabindex="-1"></a>sides <span class="ot">&lt;-</span> <span class="fu">length</span>(p) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb53-192"><a href="#cb53-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-193"><a href="#cb53-193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-194"><a href="#cb53-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-195"><a href="#cb53-195" aria-hidden="true" tabindex="-1"></a>For each of the <span class="in">`r length(p)`</span> possible values of $p$, how many combinations are there that produce our observed sequence of data?</span>
<span id="cb53-196"><a href="#cb53-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-199"><a href="#cb53-199" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-200"><a href="#cb53-200" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of ways to observe sample for each p (this is the count of the possible sequences of indicators)</span></span>
<span id="cb53-201"><a href="#cb53-201" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> (sides<span class="sc">*</span>p)<span class="sc">^</span>W <span class="sc">*</span> (sides<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p))<span class="sc">^</span>(N<span class="sc">-</span>W)</span>
<span id="cb53-202"><a href="#cb53-202" aria-hidden="true" tabindex="-1"></a>ways</span>
<span id="cb53-203"><a href="#cb53-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-204"><a href="#cb53-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-205"><a href="#cb53-205" aria-hidden="true" tabindex="-1"></a>Now, of those possibilities, which was the most likely to occur?</span>
<span id="cb53-206"><a href="#cb53-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-209"><a href="#cb53-209" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-210"><a href="#cb53-210" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior probability</span></span>
<span id="cb53-211"><a href="#cb53-211" aria-hidden="true" tabindex="-1"></a>posterior_prob <span class="ot">&lt;-</span> ways <span class="sc">/</span> <span class="fu">sum</span>(ways)</span>
<span id="cb53-212"><a href="#cb53-212" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(p, ways, posterior_prob)</span>
<span id="cb53-213"><a href="#cb53-213" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-214"><a href="#cb53-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-215"><a href="#cb53-215" aria-hidden="true" tabindex="-1"></a>It looks like $p=0.75$ was the most likely value of those that are possible.</span>
<span id="cb53-216"><a href="#cb53-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-217"><a href="#cb53-217" aria-hidden="true" tabindex="-1"></a>What is key to note about the posterior probabilities is that they are relative to the total across all values of $p$. We simply found all of the raw counts associated with each $p$ and then normalized them by the total to get the posterior probability. But this process was _exactly_ the same thing as finding the _likelihood_ of the data:</span>
<span id="cb53-218"><a href="#cb53-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-219"><a href="#cb53-219" aria-hidden="true" tabindex="-1"></a>$$Likelihood = \prod_{i=1}^NP(X=x|p)$$</span>
<span id="cb53-220"><a href="#cb53-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-221"><a href="#cb53-221" aria-hidden="true" tabindex="-1"></a>where $X$ is the binary indicator from a single globe spin. </span>
<span id="cb53-222"><a href="#cb53-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-223"><a href="#cb53-223" aria-hidden="true" tabindex="-1"></a>If we just look at all the _possible_ sequences of indicators that could have occurred:</span>
<span id="cb53-224"><a href="#cb53-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-227"><a href="#cb53-227" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-228"><a href="#cb53-228" aria-hidden="true" tabindex="-1"></a><span class="co"># Total possible sequences of indicators (each one could be a 1 or a 0)</span></span>
<span id="cb53-229"><a href="#cb53-229" aria-hidden="true" tabindex="-1"></a>total_possible_sequences <span class="ot">&lt;-</span> sides<span class="sc">^</span>N</span>
<span id="cb53-230"><a href="#cb53-230" aria-hidden="true" tabindex="-1"></a>total_possible_sequences</span>
<span id="cb53-231"><a href="#cb53-231" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-232"><a href="#cb53-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-233"><a href="#cb53-233" aria-hidden="true" tabindex="-1"></a>And then divide our original combination counts by that, we'll get _exactly_ the likelihood of the data:</span>
<span id="cb53-234"><a href="#cb53-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-237"><a href="#cb53-237" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-238"><a href="#cb53-238" aria-hidden="true" tabindex="-1"></a><span class="co"># Divide the total number of combinations we could have saw our sample, by the total number of possibilities</span></span>
<span id="cb53-239"><a href="#cb53-239" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> ways <span class="sc">/</span> total_possible_sequences</span>
<span id="cb53-240"><a href="#cb53-240" aria-hidden="true" tabindex="-1"></a>likelihood</span>
<span id="cb53-241"><a href="#cb53-241" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-242"><a href="#cb53-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-243"><a href="#cb53-243" aria-hidden="true" tabindex="-1"></a>However, as stated above, this will _not_ change the resulting posterior distribution because the number we divided by was just a normalizing constant:</span>
<span id="cb53-244"><a href="#cb53-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-247"><a href="#cb53-247" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-248"><a href="#cb53-248" aria-hidden="true" tabindex="-1"></a>likelihood <span class="sc">/</span> <span class="fu">sum</span>(likelihood)</span>
<span id="cb53-249"><a href="#cb53-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-250"><a href="#cb53-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-251"><a href="#cb53-251" aria-hidden="true" tabindex="-1"></a>So, we could also think of this problem in a different light (although it's the SAME) and get the same result:</span>
<span id="cb53-252"><a href="#cb53-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-253"><a href="#cb53-253" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>We could think of each observed value as an (unfair) coin flip (according to the value of $p$) and calculate the likelihood of the sequence of flips (which is actually what we already did, but this is more of the "traditional" way to think about it):</span>
<span id="cb53-254"><a href="#cb53-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-257"><a href="#cb53-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-258"><a href="#cb53-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood of sequence of observed sample</span></span>
<span id="cb53-259"><a href="#cb53-259" aria-hidden="true" tabindex="-1"></a>likelihood2 <span class="ot">&lt;-</span> p<span class="sc">^</span>W <span class="sc">*</span> (<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N<span class="sc">-</span>W)</span>
<span id="cb53-260"><a href="#cb53-260" aria-hidden="true" tabindex="-1"></a>likelihood</span>
<span id="cb53-261"><a href="#cb53-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-262"><a href="#cb53-262" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute posterior</span></span>
<span id="cb53-263"><a href="#cb53-263" aria-hidden="true" tabindex="-1"></a>likelihood2 <span class="sc">/</span> <span class="fu">sum</span>(likelihood2) <span class="co"># Same as before</span></span>
<span id="cb53-264"><a href="#cb53-264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-265"><a href="#cb53-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-266"><a href="#cb53-266" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>We could also think of this as finding the likelihood of observing the _total_ number of water spins since each flip is _independent_. This is also the same as before, except we're accounting for all of the combinations to observe the total number of water flips, not just the particular sequence:</span>
<span id="cb53-267"><a href="#cb53-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-270"><a href="#cb53-270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-271"><a href="#cb53-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Make the normalizing constant</span></span>
<span id="cb53-272"><a href="#cb53-272" aria-hidden="true" tabindex="-1"></a>normalizing_constant <span class="ot">&lt;-</span> <span class="fu">factorial</span>(N) <span class="sc">/</span> (<span class="fu">factorial</span>(W)<span class="sc">*</span><span class="fu">factorial</span>(N<span class="sc">-</span>W))</span>
<span id="cb53-273"><a href="#cb53-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-274"><a href="#cb53-274" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiply the likelihood by the normalizing constant by the likelihood to get the true probability of the observed sample for each value of p</span></span>
<span id="cb53-275"><a href="#cb53-275" aria-hidden="true" tabindex="-1"></a>probability <span class="ot">&lt;-</span> normalizing_constant <span class="sc">*</span> likelihood</span>
<span id="cb53-276"><a href="#cb53-276" aria-hidden="true" tabindex="-1"></a>probability</span>
<span id="cb53-277"><a href="#cb53-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-278"><a href="#cb53-278" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the posterior</span></span>
<span id="cb53-279"><a href="#cb53-279" aria-hidden="true" tabindex="-1"></a>probability <span class="sc">/</span> <span class="fu">sum</span>(probability)</span>
<span id="cb53-280"><a href="#cb53-280" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-281"><a href="#cb53-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-282"><a href="#cb53-282" aria-hidden="true" tabindex="-1"></a>Note that the normalizing constant had no effect on the posterior, but it did calculate the correct probabilities of the observed sample. In fact, this was just a Binomial distribution:</span>
<span id="cb53-283"><a href="#cb53-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-286"><a href="#cb53-286" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-287"><a href="#cb53-287" aria-hidden="true" tabindex="-1"></a><span class="co"># What is the probability of observing W water values in a sample of N globe spins for each p?</span></span>
<span id="cb53-288"><a href="#cb53-288" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> W, <span class="at">size =</span> N, <span class="at">prob =</span> p)</span>
<span id="cb53-289"><a href="#cb53-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-290"><a href="#cb53-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-291"><a href="#cb53-291" aria-hidden="true" tabindex="-1"></a>That is, the probability distribution for the number of water samples is:</span>
<span id="cb53-292"><a href="#cb53-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-293"><a href="#cb53-293" aria-hidden="true" tabindex="-1"></a>$$W|p \sim Binomial(N, p)$$</span>
<span id="cb53-294"><a href="#cb53-294" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-295"><a href="#cb53-295" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-296"><a href="#cb53-296" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-297"><a href="#cb53-297" aria-hidden="true" tabindex="-1"></a>P(W|p) </span>
<span id="cb53-298"><a href="#cb53-298" aria-hidden="true" tabindex="-1"></a>&amp;= \binom{N}{W}p^W(1-p)^{N-W} <span class="sc">\\</span></span>
<span id="cb53-299"><a href="#cb53-299" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{N!}{W!(N-W)!}p^W(1-p)^{(N-W)} <span class="sc">\\</span></span>
<span id="cb53-300"><a href="#cb53-300" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-301"><a href="#cb53-301" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-302"><a href="#cb53-302" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-303"><a href="#cb53-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-304"><a href="#cb53-304" aria-hidden="true" tabindex="-1"></a>So what is going on here? We are after the distribution of probability weights associated with each possible value of $p$ (which is what the posterior distribution is). In mathematical notation, we're just applying Bayes' formula:</span>
<span id="cb53-305"><a href="#cb53-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-306"><a href="#cb53-306" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-307"><a href="#cb53-307" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-308"><a href="#cb53-308" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-309"><a href="#cb53-309" aria-hidden="true" tabindex="-1"></a>P(p|sample) </span>
<span id="cb53-310"><a href="#cb53-310" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{P(p)P(sample|p)}{P(sample)} <span class="sc">\\</span></span>
<span id="cb53-311"><a href="#cb53-311" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{P(p)P(W|p)}{P(W)} <span class="sc">\\</span></span>
<span id="cb53-312"><a href="#cb53-312" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{P(p)P(W|p)}{P(W \cap p = 0) + ... + P(W \cap p = 1)} <span class="sc">\\</span></span>
<span id="cb53-313"><a href="#cb53-313" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{P(p)P(W|p)}{P(p=0)P(W|p=0) + ... + P(p=1)P(W|p=1)} <span class="sc">\\</span></span>
<span id="cb53-314"><a href="#cb53-314" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-315"><a href="#cb53-315" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-316"><a href="#cb53-316" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-317"><a href="#cb53-317" aria-hidden="true" tabindex="-1"></a>Each value of $p$ is equally-likely to occur (_uniform prior_), so we can factor out that term:</span>
<span id="cb53-318"><a href="#cb53-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-319"><a href="#cb53-319" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-320"><a href="#cb53-320" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-321"><a href="#cb53-321" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-322"><a href="#cb53-322" aria-hidden="true" tabindex="-1"></a>\text{(from previous)}</span>
<span id="cb53-323"><a href="#cb53-323" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{P(W|p)}{P(W|p=0) + ... + P(W|p=1)} <span class="sc">\\</span></span>
<span id="cb53-324"><a href="#cb53-324" aria-hidden="true" tabindex="-1"></a>(binomials) &amp;= \frac{\binom{N}{W}p^W(1-p)^{(N-W)}}{\binom{N}{W}0^W(1-0)^{(N-W)} + ... + \binom{N}{W}1^W(1-1)^{(N-W)}} <span class="sc">\\</span></span>
<span id="cb53-325"><a href="#cb53-325" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{p^W(1-p)^{(N-W)}}{0^W(1-0)^{(N-W)} + ... + 1^W(1-1)^{(N-W)}} <span class="sc">\\</span></span>
<span id="cb53-326"><a href="#cb53-326" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{p^W(1-p)^{(N-W)}}{\text{Normalizing constant}} <span class="sc">\\</span></span>
<span id="cb53-327"><a href="#cb53-327" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-328"><a href="#cb53-328" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-329"><a href="#cb53-329" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-330"><a href="#cb53-330" aria-hidden="true" tabindex="-1"></a>As you can see, the combination term also factors out, and the basic structure we're left with is the _likelihood_ piece that was found in _all three (3)_ variations above: $p^W(1-p)^{(N-W)}$. So when computing the posterior probability, they are relative to only terms dependent on the parameter of interest, so doesn't matter if we use the counts, base likelihood, or the probability distribution--they are all the SAME. The counting process and the "forking data" approach is simply a means to breakdown the process of what's happening behind the scenes in the math, so instead of just saying "do this integral" or "compute this product of the likelihood", you're picking apart each step of that process to gain intuition about what is happening. I'd imagine this is exactly the point of the Owl reference in the prior lecture.</span>
<span id="cb53-331"><a href="#cb53-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-332"><a href="#cb53-332" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Full solution: _p_ is a continuous value</span></span>
<span id="cb53-333"><a href="#cb53-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-334"><a href="#cb53-334" aria-hidden="true" tabindex="-1"></a>As mentioned before, the actual proportion of water on the globe can be any number between zero and one ($p \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$), meaning that there are "infinite" sides to the globe. The derivation at the end of the previous section illustrates that the posterior distribution for $p$ not restricted to any particular set of values. If we pick up where we left off:</span>
<span id="cb53-335"><a href="#cb53-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-336"><a href="#cb53-336" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-337"><a href="#cb53-337" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-338"><a href="#cb53-338" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-339"><a href="#cb53-339" aria-hidden="true" tabindex="-1"></a>P(p|data)</span>
<span id="cb53-340"><a href="#cb53-340" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{p^W(1-p)^{(N-W)}}{\text{Normalizing constant}} <span class="sc">\\</span></span>
<span id="cb53-341"><a href="#cb53-341" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-342"><a href="#cb53-342" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-343"><a href="#cb53-343" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-344"><a href="#cb53-344" aria-hidden="true" tabindex="-1"></a>All we would need to do for the continuous version of $p$ to make the posterior a formal probability distribution is to find the normalizing constant such that the integral over all possible values of $p$ equals 1. Formally, with respect to $p$,</span>
<span id="cb53-345"><a href="#cb53-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-346"><a href="#cb53-346" aria-hidden="true" tabindex="-1"></a>$$\int_0^1 \frac{p^W(1-p)^{N-W}}{Constant} = 1$$</span>
<span id="cb53-347"><a href="#cb53-347" aria-hidden="true" tabindex="-1"></a>This will ensure that the probabilities across all possible values of $p$ sums to one. However, it doesn't actually matter that we find that constant necessarily, because the posterior probability is just _relative_ to the range of values of $p$. So all that really matters is:</span>
<span id="cb53-348"><a href="#cb53-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-349"><a href="#cb53-349" aria-hidden="true" tabindex="-1"></a>$$P(p|data) \propto p^W(1-p)^{N-W}$$</span>
<span id="cb53-350"><a href="#cb53-350" aria-hidden="true" tabindex="-1"></a>We can then plug in our data and graph the resulting distribution to make inferences about $p$. </span>
<span id="cb53-351"><a href="#cb53-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-352"><a href="#cb53-352" aria-hidden="true" tabindex="-1"></a>$$P(p|data) \propto p^6(1-p)^3$$</span>
<span id="cb53-355"><a href="#cb53-355" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-356"><a href="#cb53-356" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb53-357"><a href="#cb53-357" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>), <span class="co"># Approximate the range of p values</span></span>
<span id="cb53-358"><a href="#cb53-358" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> p<span class="sc">^</span>W<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N<span class="sc">-</span>W) <span class="co"># Compute the posterior</span></span>
<span id="cb53-359"><a href="#cb53-359" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb53-360"><a href="#cb53-360" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-361"><a href="#cb53-361" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb53-362"><a href="#cb53-362" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb53-363"><a href="#cb53-363" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb53-364"><a href="#cb53-364" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-365"><a href="#cb53-365" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p,</span>
<span id="cb53-366"><a href="#cb53-366" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior</span>
<span id="cb53-367"><a href="#cb53-367" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-368"><a href="#cb53-368" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-369"><a href="#cb53-369" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb53-370"><a href="#cb53-370" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb53-371"><a href="#cb53-371" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb53-372"><a href="#cb53-372" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-373"><a href="#cb53-373" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-374"><a href="#cb53-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-375"><a href="#cb53-375" aria-hidden="true" tabindex="-1"></a>After using our sample of <span class="in">`r N`</span>, the probability weight for $p$ tends to focus near 0.70. Note that the scale of the y-axis was removed to emphasize that it doesn't really matter what it is. We would just need to be able to calculate the area under the curve to be able to assign real probabilities to questions like _"what is the probability that the proportion of water is less than 0.5?"_.</span>
<span id="cb53-376"><a href="#cb53-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-377"><a href="#cb53-377" aria-hidden="true" tabindex="-1"></a>_Note: In some cases, if we used used a different priors on $p$ (e.g., Beta), the posterior will turn out to be an identifiable distribution which we know the normalizing constant._</span>
<span id="cb53-378"><a href="#cb53-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-379"><a href="#cb53-379" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Updating the posterior</span></span>
<span id="cb53-380"><a href="#cb53-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-381"><a href="#cb53-381" aria-hidden="true" tabindex="-1"></a>So when we talk "Bayesian updates" or updating the posterior distribution, what does this mean? Since the point of it is to be able to update a model with new information, my gut used to tell me that we were somehow adding our current knowledge about the parameter into the new _prior_ distribution, and then updating the new posterior with an updated prior and only using new data in the likelihood. While in a way this might be the right way to think about it (i.e., if I have a posterior right now, isn't that the most current knowledge about the parameter, so if I want to collect more data, wouldn't I want to use knowledge up to this point as the prior instead of reverting back to the original prior and just adding more data to the collective sample?), in these examples we were doing something different: we're just seeing how the posterior changes as more data is added to the sample (i.e., observed sequence of data points).</span>
<span id="cb53-382"><a href="#cb53-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-383"><a href="#cb53-383" aria-hidden="true" tabindex="-1"></a>Let's start with just focusing on the basic example (i.e., 4 sided-globe) for now. We just need to loop through the observed sample, and calculate the posterior probabilities for each value of $p$ as a new observation comes in:</span>
<span id="cb53-384"><a href="#cb53-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-387"><a href="#cb53-387" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-388"><a href="#cb53-388" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the prior probability (uniform over the possibly choices)</span></span>
<span id="cb53-389"><a href="#cb53-389" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">length</span>(p), <span class="fu">length</span>(p))</span>
<span id="cb53-390"><a href="#cb53-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-391"><a href="#cb53-391" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the current posterior as the prior (before any data collected)</span></span>
<span id="cb53-392"><a href="#cb53-392" aria-hidden="true" tabindex="-1"></a>last_posterior <span class="ot">&lt;-</span> prior</span>
<span id="cb53-393"><a href="#cb53-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-394"><a href="#cb53-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Make result set</span></span>
<span id="cb53-395"><a href="#cb53-395" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb53-396"><a href="#cb53-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-397"><a href="#cb53-397" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in the observed sample </span></span>
<span id="cb53-398"><a href="#cb53-398" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb53-399"><a href="#cb53-399" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-400"><a href="#cb53-400" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1. Get the sub-sample</span></span>
<span id="cb53-401"><a href="#cb53-401" aria-hidden="true" tabindex="-1"></a>  sub_sample <span class="ot">&lt;-</span> observed_sample[<span class="dv">1</span><span class="sc">:</span>i]</span>
<span id="cb53-402"><a href="#cb53-402" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-403"><a href="#cb53-403" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 2. Compute metrics (the number of water samples, and the total number of spins)</span></span>
<span id="cb53-404"><a href="#cb53-404" aria-hidden="true" tabindex="-1"></a>  W_temp <span class="ot">&lt;-</span> <span class="fu">sum</span>(sub_sample)</span>
<span id="cb53-405"><a href="#cb53-405" aria-hidden="true" tabindex="-1"></a>  N_temp <span class="ot">&lt;-</span> <span class="fu">length</span>(sub_sample)</span>
<span id="cb53-406"><a href="#cb53-406" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-407"><a href="#cb53-407" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. Compute the likelihood for each p</span></span>
<span id="cb53-408"><a href="#cb53-408" aria-hidden="true" tabindex="-1"></a>  temp_likelihood <span class="ot">&lt;-</span> p<span class="sc">^</span>W_temp <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p)<span class="sc">^</span>(N_temp <span class="sc">-</span> W_temp)</span>
<span id="cb53-409"><a href="#cb53-409" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-410"><a href="#cb53-410" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4. Posterior</span></span>
<span id="cb53-411"><a href="#cb53-411" aria-hidden="true" tabindex="-1"></a>  temp_posterior <span class="ot">&lt;-</span> temp_likelihood <span class="sc">/</span> <span class="fu">sum</span>(temp_likelihood)</span>
<span id="cb53-412"><a href="#cb53-412" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-413"><a href="#cb53-413" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 5. Add to results</span></span>
<span id="cb53-414"><a href="#cb53-414" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb53-415"><a href="#cb53-415" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">%&gt;%</span></span>
<span id="cb53-416"><a href="#cb53-416" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(</span>
<span id="cb53-417"><a href="#cb53-417" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb53-418"><a href="#cb53-418" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> i,</span>
<span id="cb53-419"><a href="#cb53-419" aria-hidden="true" tabindex="-1"></a>        <span class="at">sequence =</span> <span class="fu">paste</span>(sub_sample, <span class="at">collapse =</span> <span class="st">","</span>),</span>
<span id="cb53-420"><a href="#cb53-420" aria-hidden="true" tabindex="-1"></a>        p,</span>
<span id="cb53-421"><a href="#cb53-421" aria-hidden="true" tabindex="-1"></a>        <span class="at">likelihood =</span> temp_likelihood,</span>
<span id="cb53-422"><a href="#cb53-422" aria-hidden="true" tabindex="-1"></a>        <span class="at">current =</span> temp_posterior,</span>
<span id="cb53-423"><a href="#cb53-423" aria-hidden="true" tabindex="-1"></a>        <span class="at">last =</span> last_posterior</span>
<span id="cb53-424"><a href="#cb53-424" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb53-425"><a href="#cb53-425" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-426"><a href="#cb53-426" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-427"><a href="#cb53-427" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the new last posterior</span></span>
<span id="cb53-428"><a href="#cb53-428" aria-hidden="true" tabindex="-1"></a>  last_posterior <span class="ot">&lt;-</span> temp_posterior</span>
<span id="cb53-429"><a href="#cb53-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-430"><a href="#cb53-430" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-431"><a href="#cb53-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-432"><a href="#cb53-432" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb53-433"><a href="#cb53-433" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-434"><a href="#cb53-434" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Send down the rows</span></span>
<span id="cb53-435"><a href="#cb53-435" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb53-436"><a href="#cb53-436" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(last, current)</span>
<span id="cb53-437"><a href="#cb53-437" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb53-438"><a href="#cb53-438" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-439"><a href="#cb53-439" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb53-440"><a href="#cb53-440" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb53-441"><a href="#cb53-441" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(</span>
<span id="cb53-442"><a href="#cb53-442" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-443"><a href="#cb53-443" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">factor</span>(p),</span>
<span id="cb53-444"><a href="#cb53-444" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> value,</span>
<span id="cb53-445"><a href="#cb53-445" aria-hidden="true" tabindex="-1"></a>      <span class="at">fill =</span> name</span>
<span id="cb53-446"><a href="#cb53-446" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb53-447"><a href="#cb53-447" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb53-448"><a href="#cb53-448" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">75</span>,</span>
<span id="cb53-449"><a href="#cb53-449" aria-hidden="true" tabindex="-1"></a>    <span class="at">width =</span> .<span class="dv">25</span>,</span>
<span id="cb53-450"><a href="#cb53-450" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span></span>
<span id="cb53-451"><a href="#cb53-451" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-452"><a href="#cb53-452" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(</span>
<span id="cb53-453"><a href="#cb53-453" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">"Spin: "</span>, <span class="fu">factor</span>(sample), <span class="st">" </span><span class="sc">\n</span><span class="st">Sample: "</span>, sequence)</span>
<span id="cb53-454"><a href="#cb53-454" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-455"><a href="#cb53-455" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb53-456"><a href="#cb53-456" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb53-457"><a href="#cb53-457" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb53-458"><a href="#cb53-458" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">colour =</span> <span class="st">"gray"</span>)</span>
<span id="cb53-459"><a href="#cb53-459" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-460"><a href="#cb53-460" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"p"</span>) <span class="sc">+</span></span>
<span id="cb53-461"><a href="#cb53-461" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Posterior Probability"</span>) <span class="sc">+</span></span>
<span id="cb53-462"><a href="#cb53-462" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb53-463"><a href="#cb53-463" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Posterior"</span></span>
<span id="cb53-464"><a href="#cb53-464" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-465"><a href="#cb53-465" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb53-466"><a href="#cb53-466" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"darkgray"</span>)</span>
<span id="cb53-467"><a href="#cb53-467" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb53-468"><a href="#cb53-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-469"><a href="#cb53-469" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-470"><a href="#cb53-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-471"><a href="#cb53-471" aria-hidden="true" tabindex="-1"></a>The blue bars show the posterior probability for each possible value of $p$ _after_ the newest observation was made, and the gray bars show it _before_ the newest observation was made. This illustrates the incremental impact of adding more data to the sample on the resulting posterior distribution.</span>
<span id="cb53-472"><a href="#cb53-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-473"><a href="#cb53-473" aria-hidden="true" tabindex="-1"></a>We can apply this same process to the _continuous_ (correct) possible set of values for $p$ (in fact, we'll create the curves by performing the exact same procedure to a larger, discrete set of values but make the display appear continuous):</span>
<span id="cb53-474"><a href="#cb53-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-477"><a href="#cb53-477" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-478"><a href="#cb53-478" aria-hidden="true" tabindex="-1"></a><span class="co"># Approximate the set of inifinite p-values by a large set of discrete ones</span></span>
<span id="cb53-479"><a href="#cb53-479" aria-hidden="true" tabindex="-1"></a>p_continuous <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>)</span>
<span id="cb53-480"><a href="#cb53-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-481"><a href="#cb53-481" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the prior probability (uniform over the possibly choices)</span></span>
<span id="cb53-482"><a href="#cb53-482" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="fu">length</span>(p_continuous), <span class="fu">length</span>(p_continuous))</span>
<span id="cb53-483"><a href="#cb53-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-484"><a href="#cb53-484" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the current posterior as the prior (before any data collected)</span></span>
<span id="cb53-485"><a href="#cb53-485" aria-hidden="true" tabindex="-1"></a>last_posterior <span class="ot">&lt;-</span> prior</span>
<span id="cb53-486"><a href="#cb53-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-487"><a href="#cb53-487" aria-hidden="true" tabindex="-1"></a><span class="co"># Make result set</span></span>
<span id="cb53-488"><a href="#cb53-488" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">tibble</span>()</span>
<span id="cb53-489"><a href="#cb53-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-490"><a href="#cb53-490" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in the observed sample </span></span>
<span id="cb53-491"><a href="#cb53-491" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb53-492"><a href="#cb53-492" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-493"><a href="#cb53-493" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 1. Get the sub-sample</span></span>
<span id="cb53-494"><a href="#cb53-494" aria-hidden="true" tabindex="-1"></a>  sub_sample <span class="ot">&lt;-</span> observed_sample[<span class="dv">1</span><span class="sc">:</span>i]</span>
<span id="cb53-495"><a href="#cb53-495" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-496"><a href="#cb53-496" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 2. Compute metrics (the number of water samples, and the total number of spins)</span></span>
<span id="cb53-497"><a href="#cb53-497" aria-hidden="true" tabindex="-1"></a>  W_temp <span class="ot">&lt;-</span> <span class="fu">sum</span>(sub_sample)</span>
<span id="cb53-498"><a href="#cb53-498" aria-hidden="true" tabindex="-1"></a>  N_temp <span class="ot">&lt;-</span> <span class="fu">length</span>(sub_sample)</span>
<span id="cb53-499"><a href="#cb53-499" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-500"><a href="#cb53-500" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 3. Compute the likelihood for each p</span></span>
<span id="cb53-501"><a href="#cb53-501" aria-hidden="true" tabindex="-1"></a>  temp_likelihood <span class="ot">&lt;-</span> p_continuous<span class="sc">^</span>W_temp <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p_continuous)<span class="sc">^</span>(N_temp <span class="sc">-</span> W_temp)</span>
<span id="cb53-502"><a href="#cb53-502" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-503"><a href="#cb53-503" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 4. Posterior</span></span>
<span id="cb53-504"><a href="#cb53-504" aria-hidden="true" tabindex="-1"></a>  temp_posterior <span class="ot">&lt;-</span> temp_likelihood <span class="sc">/</span> <span class="fu">sum</span>(temp_likelihood)</span>
<span id="cb53-505"><a href="#cb53-505" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-506"><a href="#cb53-506" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 5. Add to results</span></span>
<span id="cb53-507"><a href="#cb53-507" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb53-508"><a href="#cb53-508" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">%&gt;%</span></span>
<span id="cb53-509"><a href="#cb53-509" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_rows</span>(</span>
<span id="cb53-510"><a href="#cb53-510" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb53-511"><a href="#cb53-511" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample =</span> i,</span>
<span id="cb53-512"><a href="#cb53-512" aria-hidden="true" tabindex="-1"></a>        <span class="at">sequence =</span> <span class="fu">paste</span>(sub_sample, <span class="at">collapse =</span> <span class="st">","</span>),</span>
<span id="cb53-513"><a href="#cb53-513" aria-hidden="true" tabindex="-1"></a>        p_continuous,</span>
<span id="cb53-514"><a href="#cb53-514" aria-hidden="true" tabindex="-1"></a>        <span class="at">likelihood =</span> temp_likelihood,</span>
<span id="cb53-515"><a href="#cb53-515" aria-hidden="true" tabindex="-1"></a>        <span class="at">current =</span> temp_posterior,</span>
<span id="cb53-516"><a href="#cb53-516" aria-hidden="true" tabindex="-1"></a>        <span class="at">last =</span> last_posterior</span>
<span id="cb53-517"><a href="#cb53-517" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb53-518"><a href="#cb53-518" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-519"><a href="#cb53-519" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-520"><a href="#cb53-520" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Set the new last posterior</span></span>
<span id="cb53-521"><a href="#cb53-521" aria-hidden="true" tabindex="-1"></a>  last_posterior <span class="ot">&lt;-</span> temp_posterior</span>
<span id="cb53-522"><a href="#cb53-522" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-523"><a href="#cb53-523" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-524"><a href="#cb53-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-525"><a href="#cb53-525" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span></span>
<span id="cb53-526"><a href="#cb53-526" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-527"><a href="#cb53-527" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Send down the rows</span></span>
<span id="cb53-528"><a href="#cb53-528" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb53-529"><a href="#cb53-529" aria-hidden="true" tabindex="-1"></a>    <span class="at">cols =</span> <span class="fu">c</span>(last, current)</span>
<span id="cb53-530"><a href="#cb53-530" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb53-531"><a href="#cb53-531" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-532"><a href="#cb53-532" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb53-533"><a href="#cb53-533" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb53-534"><a href="#cb53-534" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(</span>
<span id="cb53-535"><a href="#cb53-535" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-536"><a href="#cb53-536" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p_continuous,</span>
<span id="cb53-537"><a href="#cb53-537" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> value,</span>
<span id="cb53-538"><a href="#cb53-538" aria-hidden="true" tabindex="-1"></a>      <span class="at">fill =</span> name</span>
<span id="cb53-539"><a href="#cb53-539" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb53-540"><a href="#cb53-540" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb53-541"><a href="#cb53-541" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> .<span class="dv">65</span>,</span>
<span id="cb53-542"><a href="#cb53-542" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span></span>
<span id="cb53-543"><a href="#cb53-543" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-544"><a href="#cb53-544" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(</span>
<span id="cb53-545"><a href="#cb53-545" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">paste0</span>(<span class="st">"Spin: "</span>, <span class="fu">factor</span>(sample), <span class="st">" </span><span class="sc">\n</span><span class="st">Sample: "</span>, sequence)</span>
<span id="cb53-546"><a href="#cb53-546" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-547"><a href="#cb53-547" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb53-548"><a href="#cb53-548" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb53-549"><a href="#cb53-549" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.background =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb53-550"><a href="#cb53-550" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.major.y =</span> <span class="fu">element_line</span>(<span class="at">colour =</span> <span class="st">"gray"</span>),</span>
<span id="cb53-551"><a href="#cb53-551" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb53-552"><a href="#cb53-552" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb53-553"><a href="#cb53-553" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-554"><a href="#cb53-554" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"p"</span>) <span class="sc">+</span></span>
<span id="cb53-555"><a href="#cb53-555" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Posterior Probability"</span>) <span class="sc">+</span></span>
<span id="cb53-556"><a href="#cb53-556" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb53-557"><a href="#cb53-557" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Posterior"</span></span>
<span id="cb53-558"><a href="#cb53-558" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-559"><a href="#cb53-559" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(</span>
<span id="cb53-560"><a href="#cb53-560" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"darkgray"</span>)</span>
<span id="cb53-561"><a href="#cb53-561" aria-hidden="true" tabindex="-1"></a>  ) </span>
<span id="cb53-562"><a href="#cb53-562" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-563"><a href="#cb53-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-564"><a href="#cb53-564" aria-hidden="true" tabindex="-1"></a>Again, these curves are actually approximated here. In practice, we would need to calculate the area underneath the curve to get exact answers about probabilities. _Note: We could parameterize the Beta distribution to get the normalizing constant for calculating the actual posterior probabilities that fits this distribution._</span>
<span id="cb53-565"><a href="#cb53-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-566"><a href="#cb53-566" aria-hidden="true" tabindex="-1"></a><span class="fu">## Homework</span></span>
<span id="cb53-567"><a href="#cb53-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-568"><a href="#cb53-568" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Suppose the globe tossing data had turned out to be 4 water and 11 land. Construct the posterior distribution.</span>
<span id="cb53-569"><a href="#cb53-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-570"><a href="#cb53-570" aria-hidden="true" tabindex="-1"></a>We'll cheat a little bit and use the approach of using a large, discrete list of possible values for $p$, and plot it as if it is continuous (we could also just use the Beta distribution). With that, all we need to do is change the values of $W$ and $N$ and use the same code as above.</span>
<span id="cb53-571"><a href="#cb53-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-574"><a href="#cb53-574" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-575"><a href="#cb53-575" aria-hidden="true" tabindex="-1"></a>W_new <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb53-576"><a href="#cb53-576" aria-hidden="true" tabindex="-1"></a>N_new <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb53-577"><a href="#cb53-577" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb53-578"><a href="#cb53-578" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>), <span class="co"># Approximate the range of p values</span></span>
<span id="cb53-579"><a href="#cb53-579" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> p<span class="sc">^</span>W_new<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">^</span>(N_new<span class="sc">-</span>W_new) <span class="co"># Compute the posterior</span></span>
<span id="cb53-580"><a href="#cb53-580" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb53-581"><a href="#cb53-581" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-582"><a href="#cb53-582" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb53-583"><a href="#cb53-583" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb53-584"><a href="#cb53-584" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb53-585"><a href="#cb53-585" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-586"><a href="#cb53-586" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p,</span>
<span id="cb53-587"><a href="#cb53-587" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior</span>
<span id="cb53-588"><a href="#cb53-588" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-589"><a href="#cb53-589" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-590"><a href="#cb53-590" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb53-591"><a href="#cb53-591" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb53-592"><a href="#cb53-592" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb53-593"><a href="#cb53-593" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-594"><a href="#cb53-594" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-595"><a href="#cb53-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-596"><a href="#cb53-596" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Using the posterior distribution from (1), compute the posterior predictive distribution for the next 5 tosses of the same globe. </span>
<span id="cb53-597"><a href="#cb53-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-598"><a href="#cb53-598" aria-hidden="true" tabindex="-1"></a>Okay here I'll finally acknowledge that the posterior can be written as a <span class="co">[</span><span class="ot">Beta</span><span class="co">](https://en.wikipedia.org/wiki/Beta_distribution)</span> distribution, which gives us the normalizing constant needed to make it a real probability distribution (i.e., the area sums to 1). It has the following _probability density function (PDF)_:</span>
<span id="cb53-599"><a href="#cb53-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-600"><a href="#cb53-600" aria-hidden="true" tabindex="-1"></a>$$f(x|\alpha, \beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$$</span>
<span id="cb53-601"><a href="#cb53-601" aria-hidden="true" tabindex="-1"></a>where $x \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, $\alpha, \beta &gt; 0$, and $\Gamma(n) = (n-1)!$. If we make the following reparameterizations from our set of variables:</span>
<span id="cb53-602"><a href="#cb53-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-603"><a href="#cb53-603" aria-hidden="true" tabindex="-1"></a>$$p=x$$</span>
<span id="cb53-604"><a href="#cb53-604" aria-hidden="true" tabindex="-1"></a>$$W = \alpha - 1$$</span>
<span id="cb53-605"><a href="#cb53-605" aria-hidden="true" tabindex="-1"></a>$$N-W = \beta - 1$$</span>
<span id="cb53-606"><a href="#cb53-606" aria-hidden="true" tabindex="-1"></a>we get:</span>
<span id="cb53-607"><a href="#cb53-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-608"><a href="#cb53-608" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-609"><a href="#cb53-609" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-610"><a href="#cb53-610" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-611"><a href="#cb53-611" aria-hidden="true" tabindex="-1"></a>f(p|W,N)</span>
<span id="cb53-612"><a href="#cb53-612" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\Gamma(W+1+N-W+1)}{\Gamma(W+1)\Gamma(N-W+1)}p^W(1-p)^{N-W} <span class="sc">\\</span></span>
<span id="cb53-613"><a href="#cb53-613" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{\Gamma(N+2)}{\Gamma(W+1)\Gamma(N-W+1)}p^W(1-p)^{N-W} <span class="sc">\\</span></span>
<span id="cb53-614"><a href="#cb53-614" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{(N+1)!}{W!(N-W)!}p^W(1-p)^{N-W} <span class="sc">\\</span></span>
<span id="cb53-615"><a href="#cb53-615" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-616"><a href="#cb53-616" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-617"><a href="#cb53-617" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-618"><a href="#cb53-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-619"><a href="#cb53-619" aria-hidden="true" tabindex="-1"></a>_Note that since $p$ is continuous, this function represents the probability density at any particular value of $p$. To get any positive probability, we must integrate this function over a range of $p$ values. Hence the $f$ notation._</span>
<span id="cb53-620"><a href="#cb53-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-621"><a href="#cb53-621" aria-hidden="true" tabindex="-1"></a>Let's quickly plug in $W=4$ and $N=15$ to confirm (at least visually) that this function produces the same posterior we made to answer the last question. We'll do this by evaluating the density of the derived Beta distribution at range of possible $p$ values. _Note we'll have to use the parameterizations for the Beta distribution that are built into `R`_.</span>
<span id="cb53-622"><a href="#cb53-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-625"><a href="#cb53-625" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-626"><a href="#cb53-626" aria-hidden="true" tabindex="-1"></a><span class="co"># Reparameterize</span></span>
<span id="cb53-627"><a href="#cb53-627" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> W_new <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb53-628"><a href="#cb53-628" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> N_new <span class="sc">-</span> W_new <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb53-629"><a href="#cb53-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-630"><a href="#cb53-630" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a data frame</span></span>
<span id="cb53-631"><a href="#cb53-631" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb53-632"><a href="#cb53-632" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">01</span>), <span class="co"># Approximate the range of p values (same as before)</span></span>
<span id="cb53-633"><a href="#cb53-633" aria-hidden="true" tabindex="-1"></a>  <span class="at">posterior =</span> <span class="fu">dbeta</span>(p, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta) <span class="co"># Compute the actual posterior density</span></span>
<span id="cb53-634"><a href="#cb53-634" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb53-635"><a href="#cb53-635" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-636"><a href="#cb53-636" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb53-637"><a href="#cb53-637" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb53-638"><a href="#cb53-638" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb53-639"><a href="#cb53-639" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-640"><a href="#cb53-640" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> p,</span>
<span id="cb53-641"><a href="#cb53-641" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior</span>
<span id="cb53-642"><a href="#cb53-642" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-643"><a href="#cb53-643" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-644"><a href="#cb53-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-645"><a href="#cb53-645" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-646"><a href="#cb53-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-647"><a href="#cb53-647" aria-hidden="true" tabindex="-1"></a>From inspection, it appears that they are essentially the same curves. _Note that this time I kept the y-axis labels because this is the density for the actual probability distribution_.</span>
<span id="cb53-648"><a href="#cb53-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-649"><a href="#cb53-649" aria-hidden="true" tabindex="-1"></a>So back to the question: how do we find the posterior predictive distribution for the next 5 globe spins? Well, if the globe is spun 5 more times, then we can get water on 0, 1, 2, 3, 4, or all 5 spins. Our quest is to figure out the likelihood of each of those possible outcomes based on what we currently know about $p$ (i.e., the posterior distribution). To do this, we'll use our posterior distribution to run a simulation of the experiment using the following steps:</span>
<span id="cb53-650"><a href="#cb53-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-651"><a href="#cb53-651" aria-hidden="true" tabindex="-1"></a>i. Select a random value of $p$ from the posterior</span>
<span id="cb53-652"><a href="#cb53-652" aria-hidden="true" tabindex="-1"></a>ii. Draw a random $binomial$ realization where $N=5$</span>
<span id="cb53-653"><a href="#cb53-653" aria-hidden="true" tabindex="-1"></a>iii. Repeat steps i-ii 10000 times</span>
<span id="cb53-654"><a href="#cb53-654" aria-hidden="true" tabindex="-1"></a>iv. Graph the results</span>
<span id="cb53-655"><a href="#cb53-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-658"><a href="#cb53-658" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-659"><a href="#cb53-659" aria-hidden="true" tabindex="-1"></a><span class="co"># Set some parameters</span></span>
<span id="cb53-660"><a href="#cb53-660" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb53-661"><a href="#cb53-661" aria-hidden="true" tabindex="-1"></a>n_experiment <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="co"># Number of new spins we're going to conduct</span></span>
<span id="cb53-662"><a href="#cb53-662" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="dv">10000</span> <span class="co"># Number of simulations</span></span>
<span id="cb53-663"><a href="#cb53-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-664"><a href="#cb53-664" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Draw random values of p from the posterior</span></span>
<span id="cb53-665"><a href="#cb53-665" aria-hidden="true" tabindex="-1"></a>p_rand <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="at">n =</span> s, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta) <span class="co"># Same parameters as before</span></span>
<span id="cb53-666"><a href="#cb53-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-667"><a href="#cb53-667" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. For each p, run a binomial experiment (represents samples of W)</span></span>
<span id="cb53-668"><a href="#cb53-668" aria-hidden="true" tabindex="-1"></a>w_rand <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="at">n =</span> s, <span class="at">size =</span> n_experiment, <span class="at">prob =</span> p_rand)</span>
<span id="cb53-669"><a href="#cb53-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-670"><a href="#cb53-670" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a data frame</span></span>
<span id="cb53-671"><a href="#cb53-671" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb53-672"><a href="#cb53-672" aria-hidden="true" tabindex="-1"></a>  <span class="at">w =</span> w_rand</span>
<span id="cb53-673"><a href="#cb53-673" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb53-674"><a href="#cb53-674" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-675"><a href="#cb53-675" aria-hidden="true" tabindex="-1"></a>  <span class="co"># For each w</span></span>
<span id="cb53-676"><a href="#cb53-676" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(w) <span class="sc">%&gt;%</span></span>
<span id="cb53-677"><a href="#cb53-677" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-678"><a href="#cb53-678" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the total</span></span>
<span id="cb53-679"><a href="#cb53-679" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb53-680"><a href="#cb53-680" aria-hidden="true" tabindex="-1"></a>    <span class="at">count =</span> <span class="fu">n</span>()</span>
<span id="cb53-681"><a href="#cb53-681" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb53-682"><a href="#cb53-682" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-683"><a href="#cb53-683" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add proportion</span></span>
<span id="cb53-684"><a href="#cb53-684" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb53-685"><a href="#cb53-685" aria-hidden="true" tabindex="-1"></a>    <span class="at">proportion =</span> count <span class="sc">/</span> <span class="fu">sum</span>(count)</span>
<span id="cb53-686"><a href="#cb53-686" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb53-687"><a href="#cb53-687" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-688"><a href="#cb53-688" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make a plot</span></span>
<span id="cb53-689"><a href="#cb53-689" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb53-690"><a href="#cb53-690" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-691"><a href="#cb53-691" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">factor</span>(w)</span>
<span id="cb53-692"><a href="#cb53-692" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-693"><a href="#cb53-693" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-694"><a href="#cb53-694" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(</span>
<span id="cb53-695"><a href="#cb53-695" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-696"><a href="#cb53-696" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> proportion</span>
<span id="cb53-697"><a href="#cb53-697" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-698"><a href="#cb53-698" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-699"><a href="#cb53-699" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb53-700"><a href="#cb53-700" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-701"><a href="#cb53-701" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> proportion,</span>
<span id="cb53-702"><a href="#cb53-702" aria-hidden="true" tabindex="-1"></a>      <span class="at">label =</span> <span class="fu">paste0</span>(<span class="fu">round</span>(proportion<span class="sc">*</span><span class="dv">100</span>,<span class="dv">1</span>), <span class="st">"%"</span>)</span>
<span id="cb53-703"><a href="#cb53-703" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb53-704"><a href="#cb53-704" aria-hidden="true" tabindex="-1"></a>    <span class="at">vjust =</span> <span class="sc">-</span>.<span class="dv">1</span></span>
<span id="cb53-705"><a href="#cb53-705" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-706"><a href="#cb53-706" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb53-707"><a href="#cb53-707" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> scales<span class="sc">::</span>percent</span>
<span id="cb53-708"><a href="#cb53-708" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-709"><a href="#cb53-709" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"W"</span>) <span class="sc">+</span></span>
<span id="cb53-710"><a href="#cb53-710" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability"</span>) <span class="sc">+</span></span>
<span id="cb53-711"><a href="#cb53-711" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb53-712"><a href="#cb53-712" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">paste0</span>(<span class="st">"Posterior Predictive Distribution for "</span>, n_experiment, <span class="st">" more spins."</span>)</span>
<span id="cb53-713"><a href="#cb53-713" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-714"><a href="#cb53-714" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-715"><a href="#cb53-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-716"><a href="#cb53-716" aria-hidden="true" tabindex="-1"></a>Another way to think about what we're doing here is:</span>
<span id="cb53-717"><a href="#cb53-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-718"><a href="#cb53-718" aria-hidden="true" tabindex="-1"></a>i. Find the collection of _density_ values for all $p$ in the posterior distribution</span>
<span id="cb53-719"><a href="#cb53-719" aria-hidden="true" tabindex="-1"></a>ii. Find the probability distribution of the possible outcomes from a Binomial distribution where $N=5$ for all possible values of $p$ (i.e., independent of our posterior)</span>
<span id="cb53-720"><a href="#cb53-720" aria-hidden="true" tabindex="-1"></a>iii. Take the average probability value for each possible outcome in (ii) over all values of $p$, _weighted_ by the posterior density in (i)</span>
<span id="cb53-721"><a href="#cb53-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-724"><a href="#cb53-724" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-725"><a href="#cb53-725" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a set of p representive of its domain</span></span>
<span id="cb53-726"><a href="#cb53-726" aria-hidden="true" tabindex="-1"></a>p_alt <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">001</span>) <span class="co"># Supposed to represent continuous p</span></span>
<span id="cb53-727"><a href="#cb53-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-728"><a href="#cb53-728" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Posterior density values for each p</span></span>
<span id="cb53-729"><a href="#cb53-729" aria-hidden="true" tabindex="-1"></a>posterior_alt <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(p_alt, <span class="at">shape1 =</span> alpha, <span class="at">shape2 =</span> beta)</span>
<span id="cb53-730"><a href="#cb53-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-731"><a href="#cb53-731" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Probability distribution for each outcome for each p</span></span>
<span id="cb53-732"><a href="#cb53-732" aria-hidden="true" tabindex="-1"></a>possible_outcomes <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span>n_experiment</span>
<span id="cb53-733"><a href="#cb53-733" aria-hidden="true" tabindex="-1"></a>likelihood_alt <span class="ot">&lt;-</span> </span>
<span id="cb53-734"><a href="#cb53-734" aria-hidden="true" tabindex="-1"></a>  possible_outcomes <span class="sc">%&gt;%</span> </span>
<span id="cb53-735"><a href="#cb53-735" aria-hidden="true" tabindex="-1"></a>  <span class="fu">map_df</span>(</span>
<span id="cb53-736"><a href="#cb53-736" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span></span>
<span id="cb53-737"><a href="#cb53-737" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb53-738"><a href="#cb53-738" aria-hidden="true" tabindex="-1"></a>        <span class="at">binomial_probability =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> .x, <span class="at">size =</span> n_experiment, <span class="at">prob =</span> p_alt),</span>
<span id="cb53-739"><a href="#cb53-739" aria-hidden="true" tabindex="-1"></a>        <span class="at">p =</span> p_alt,</span>
<span id="cb53-740"><a href="#cb53-740" aria-hidden="true" tabindex="-1"></a>        <span class="at">outcome =</span> .x</span>
<span id="cb53-741"><a href="#cb53-741" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb53-742"><a href="#cb53-742" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-743"><a href="#cb53-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-744"><a href="#cb53-744" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Get the posterior predictive distribution</span></span>
<span id="cb53-745"><a href="#cb53-745" aria-hidden="true" tabindex="-1"></a>posterior_predictive_distribution <span class="ot">&lt;-</span></span>
<span id="cb53-746"><a href="#cb53-746" aria-hidden="true" tabindex="-1"></a>  likelihood_alt <span class="sc">%&gt;%</span></span>
<span id="cb53-747"><a href="#cb53-747" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-748"><a href="#cb53-748" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Join to attach the posterior density weight to each value of p</span></span>
<span id="cb53-749"><a href="#cb53-749" aria-hidden="true" tabindex="-1"></a>  <span class="fu">inner_join</span>(</span>
<span id="cb53-750"><a href="#cb53-750" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> </span>
<span id="cb53-751"><a href="#cb53-751" aria-hidden="true" tabindex="-1"></a>      <span class="fu">tibble</span>(</span>
<span id="cb53-752"><a href="#cb53-752" aria-hidden="true" tabindex="-1"></a>        <span class="at">p =</span> p_alt,</span>
<span id="cb53-753"><a href="#cb53-753" aria-hidden="true" tabindex="-1"></a>        <span class="at">posterior_density =</span> posterior_alt</span>
<span id="cb53-754"><a href="#cb53-754" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb53-755"><a href="#cb53-755" aria-hidden="true" tabindex="-1"></a>    <span class="at">by =</span> <span class="st">"p"</span></span>
<span id="cb53-756"><a href="#cb53-756" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb53-757"><a href="#cb53-757" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-758"><a href="#cb53-758" aria-hidden="true" tabindex="-1"></a>  <span class="co"># For each possible outcome</span></span>
<span id="cb53-759"><a href="#cb53-759" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(outcome) <span class="sc">%&gt;%</span></span>
<span id="cb53-760"><a href="#cb53-760" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-761"><a href="#cb53-761" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the weighted-average probability</span></span>
<span id="cb53-762"><a href="#cb53-762" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb53-763"><a href="#cb53-763" aria-hidden="true" tabindex="-1"></a>    <span class="at">posterior_probability =</span> <span class="fu">sum</span>(binomial_probability <span class="sc">*</span> posterior_density) <span class="sc">/</span> <span class="fu">sum</span>(posterior_density)</span>
<span id="cb53-764"><a href="#cb53-764" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-765"><a href="#cb53-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-766"><a href="#cb53-766" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Make a plot</span></span>
<span id="cb53-767"><a href="#cb53-767" aria-hidden="true" tabindex="-1"></a>posterior_predictive_distribution <span class="sc">%&gt;%</span></span>
<span id="cb53-768"><a href="#cb53-768" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb53-769"><a href="#cb53-769" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-770"><a href="#cb53-770" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> <span class="fu">factor</span>(outcome)</span>
<span id="cb53-771"><a href="#cb53-771" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-772"><a href="#cb53-772" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-773"><a href="#cb53-773" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(</span>
<span id="cb53-774"><a href="#cb53-774" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-775"><a href="#cb53-775" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior_probability</span>
<span id="cb53-776"><a href="#cb53-776" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-777"><a href="#cb53-777" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-778"><a href="#cb53-778" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(</span>
<span id="cb53-779"><a href="#cb53-779" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-780"><a href="#cb53-780" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> posterior_probability,</span>
<span id="cb53-781"><a href="#cb53-781" aria-hidden="true" tabindex="-1"></a>      <span class="at">label =</span> <span class="fu">paste0</span>(<span class="fu">round</span>(posterior_probability<span class="sc">*</span><span class="dv">100</span>,<span class="dv">1</span>), <span class="st">"%"</span>)</span>
<span id="cb53-782"><a href="#cb53-782" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb53-783"><a href="#cb53-783" aria-hidden="true" tabindex="-1"></a>    <span class="at">vjust =</span> <span class="sc">-</span>.<span class="dv">1</span></span>
<span id="cb53-784"><a href="#cb53-784" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-785"><a href="#cb53-785" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(</span>
<span id="cb53-786"><a href="#cb53-786" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> scales<span class="sc">::</span>percent</span>
<span id="cb53-787"><a href="#cb53-787" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-788"><a href="#cb53-788" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"W"</span>) <span class="sc">+</span></span>
<span id="cb53-789"><a href="#cb53-789" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probability"</span>) <span class="sc">+</span></span>
<span id="cb53-790"><a href="#cb53-790" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb53-791"><a href="#cb53-791" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">paste0</span>(<span class="st">"Posterior Predictive Distribution for "</span>, n_experiment, <span class="st">" more spins."</span>)</span>
<span id="cb53-792"><a href="#cb53-792" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-793"><a href="#cb53-793" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-794"><a href="#cb53-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-795"><a href="#cb53-795" aria-hidden="true" tabindex="-1"></a>The distributions from the two approaches are merely identical (slight differences due to simulation variability and inexact integration).</span>
<span id="cb53-796"><a href="#cb53-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-797"><a href="#cb53-797" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Use the posterior predictive distribution from (2) to calculate the probability of 3 or more water samples in the next 5 tosses.</span>
<span id="cb53-798"><a href="#cb53-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-799"><a href="#cb53-799" aria-hidden="true" tabindex="-1"></a>Using the posterior predictive distribution above, we can look at the percent of simulations that resulted in 3 or more water samples:</span>
<span id="cb53-800"><a href="#cb53-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-803"><a href="#cb53-803" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-804"><a href="#cb53-804" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(w_rand <span class="sc">&gt;=</span> <span class="dv">3</span>)</span>
<span id="cb53-805"><a href="#cb53-805" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-806"><a href="#cb53-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-807"><a href="#cb53-807" aria-hidden="true" tabindex="-1"></a>So there is a <span class="in">`r round(mean(w_rand&gt;=3), 3)`</span> probability of 3 or more water samples in the next 5 tosses. However, this point estimate is not totally sufficient because we haven't reported any uncertainty associated with it. Since we know that $W|p \sim Binomial(n,p)$, the $P(W&gt;=3|p,N)$ is already determined. In this case, we can just calculate it for each random value of $p$ sampled from the posterior:</span>
<span id="cb53-808"><a href="#cb53-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-811"><a href="#cb53-811" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-812"><a href="#cb53-812" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the binomial probability</span></span>
<span id="cb53-813"><a href="#cb53-813" aria-hidden="true" tabindex="-1"></a>prob_binom <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="at">q =</span> <span class="dv">2</span>, <span class="at">size =</span> n_experiment, <span class="at">prob =</span> p_rand)</span>
<span id="cb53-814"><a href="#cb53-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-815"><a href="#cb53-815" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a plot</span></span>
<span id="cb53-816"><a href="#cb53-816" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb53-817"><a href="#cb53-817" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(</span>
<span id="cb53-818"><a href="#cb53-818" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb53-819"><a href="#cb53-819" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> prob_binom</span>
<span id="cb53-820"><a href="#cb53-820" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb53-821"><a href="#cb53-821" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-822"><a href="#cb53-822" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb53-823"><a href="#cb53-823" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb53-824"><a href="#cb53-824" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb53-825"><a href="#cb53-825" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb53-826"><a href="#cb53-826" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"P(W&gt;=3|N=5)"</span>) </span>
<span id="cb53-827"><a href="#cb53-827" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-828"><a href="#cb53-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-829"><a href="#cb53-829" aria-hidden="true" tabindex="-1"></a>This one has been stumping me a bit, and I'm not totally confident this is the correct result. Another way I was thinking about it was similar the alternative in (2), namely that we are finding the $P(W&gt;=3|N=5)$ for each value of $p$, and then weighting that by the posterior density of $p$. However, it seems like we should be sampling from the predictive distribution in (2) somehow, but if we do that it seems like the precision of our estimates would then just be determined by the number of simulations we run, not the data, which also doesn't make sense.</span>
<span id="cb53-830"><a href="#cb53-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-831"><a href="#cb53-831" aria-hidden="true" tabindex="-1"></a><span class="fu">## Notes</span></span>
<span id="cb53-832"><a href="#cb53-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-833"><a href="#cb53-833" aria-hidden="true" tabindex="-1"></a>**Goal: Estimate the percent of the globe that is covered in water**</span>
<span id="cb53-834"><a href="#cb53-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-835"><a href="#cb53-835" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Think of spinning the globe and stopping on a point and repeating many times</span>
<span id="cb53-836"><a href="#cb53-836" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>How do we use that collection of points to come up with an estimate? That's the goal of today's lecture</span>
<span id="cb53-837"><a href="#cb53-837" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>First thought is just indicate each time whether land or water appear as the point; however, how does the shape of the globe impact the likelihood that I will come up with land or water on a "random" toss? Has to do with sampling strategy</span>
<span id="cb53-838"><a href="#cb53-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-839"><a href="#cb53-839" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Define a generative model</span>
<span id="cb53-840"><a href="#cb53-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-841"><a href="#cb53-841" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Think conceptually about scientifically how the sample was produced (how do variables influence one another)</span>
<span id="cb53-842"><a href="#cb53-842" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Variables: Things we *want* to observe/estimate or things we actually do observe</span>
<span id="cb53-843"><a href="#cb53-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-844"><a href="#cb53-844" aria-hidden="true" tabindex="-1"></a>$$\bf{p} = \text{proportion of water}\hskip.5inW=\text{water observations}$$ </span>
<span id="cb53-845"><a href="#cb53-845" aria-hidden="true" tabindex="-1"></a>$$N = \text{number of tosses}\hskip.5inL=\text{land observations}$$</span>
<span id="cb53-846"><a href="#cb53-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-847"><a href="#cb53-847" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Define a specific estimand</span>
<span id="cb53-848"><a href="#cb53-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-849"><a href="#cb53-849" aria-hidden="true" tabindex="-1"></a>Were interested in the true proportion of water **p**</span>
<span id="cb53-850"><a href="#cb53-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-851"><a href="#cb53-851" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Design a statistical way to produce estimate</span>
<span id="cb53-852"><a href="#cb53-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-853"><a href="#cb53-853" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>How are these related to each other?</span>
<span id="cb53-854"><a href="#cb53-854" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>N influences W and L (the more tosses leads to change on other variables)</span>
<span id="cb53-855"><a href="#cb53-855" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>p also influences W and L (i.e., the true proportion dictates the number of water observations and land observations)</span>
<span id="cb53-856"><a href="#cb53-856" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>The DAG shows relationships, but not what the relationships *are*. We can say $W,L=f(p,N)$; what is $f$?</span>
<span id="cb53-857"><a href="#cb53-857" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Assume a model (e.g., $p$ = .25, then count likely the sample was under that model, do that for all possible models)</span>
<span id="cb53-858"><a href="#cb53-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-859"><a href="#cb53-859" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Test (3) using (1)</span>
<span id="cb53-860"><a href="#cb53-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-863"><a href="#cb53-863" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-864"><a href="#cb53-864" aria-hidden="true" tabindex="-1"></a>sim_globe <span class="ot">&lt;-</span></span>
<span id="cb53-865"><a href="#cb53-865" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(<span class="at">p =</span> .<span class="dv">7</span>, <span class="at">N =</span> <span class="dv">9</span>) {</span>
<span id="cb53-866"><a href="#cb53-866" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample</span>(</span>
<span id="cb53-867"><a href="#cb53-867" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="st">"W"</span>,<span class="st">"L"</span>), <span class="co"># Possible observations</span></span>
<span id="cb53-868"><a href="#cb53-868" aria-hidden="true" tabindex="-1"></a>      <span class="at">size =</span> N, <span class="co"># Number of tosses</span></span>
<span id="cb53-869"><a href="#cb53-869" aria-hidden="true" tabindex="-1"></a>      <span class="at">prob =</span> <span class="fu">c</span>(p, <span class="dv">1</span><span class="sc">-</span>p), <span class="co"># The probability of each possible observation</span></span>
<span id="cb53-870"><a href="#cb53-870" aria-hidden="true" tabindex="-1"></a>      <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb53-871"><a href="#cb53-871" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-872"><a href="#cb53-872" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_globe</span>()</span>
<span id="cb53-873"><a href="#cb53-873" aria-hidden="true" tabindex="-1"></a><span class="fu">replicate</span>(<span class="fu">sim_globe</span>(<span class="at">p =</span>.<span class="dv">5</span>, <span class="at">N=</span><span class="dv">9</span>), <span class="at">n=</span><span class="dv">10</span>)</span>
<span id="cb53-874"><a href="#cb53-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-875"><a href="#cb53-875" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-876"><a href="#cb53-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-877"><a href="#cb53-877" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Test the intent of the code first</span>
<span id="cb53-878"><a href="#cb53-878" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If our procedure doesn't work when *we know* the answer, it certainly won't when we *don't* know the answer</span>
<span id="cb53-879"><a href="#cb53-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-880"><a href="#cb53-880" aria-hidden="true" tabindex="-1"></a>Infinite sample:</span>
<span id="cb53-881"><a href="#cb53-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-882"><a href="#cb53-882" aria-hidden="true" tabindex="-1"></a>$$p^W(1-p)^L$$ Posterior probability:</span>
<span id="cb53-883"><a href="#cb53-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-884"><a href="#cb53-884" aria-hidden="true" tabindex="-1"></a>$$p = \frac{(W+L+1)!}{W!L!}p^W(1-p)^L$$ </span>
<span id="cb53-885"><a href="#cb53-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-886"><a href="#cb53-886" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This is a *Beta* distribution, and the likelihood was a *Binomial*.</span>
<span id="cb53-887"><a href="#cb53-887" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The minimum sample size for Bayesian analysis is 1.</span>
<span id="cb53-888"><a href="#cb53-888" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The shape of the posterior distribution embodies the sample size</span>
<span id="cb53-889"><a href="#cb53-889" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>No point estimate, we work with the entire posterior distribution</span>
<span id="cb53-890"><a href="#cb53-890" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The distribution *is* the estimate; always use the entire distribution, never a single point</span>
<span id="cb53-891"><a href="#cb53-891" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The fact that an arbitrary interval contains an arbitrary value is not meaningful</span>
<span id="cb53-892"><a href="#cb53-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-893"><a href="#cb53-893" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Analyze sample, summarize</span>
<span id="cb53-894"><a href="#cb53-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-895"><a href="#cb53-895" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Implications depend on entire posterior</span>
<span id="cb53-896"><a href="#cb53-896" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Average over the uncertainty of the posterior</span>
<span id="cb53-897"><a href="#cb53-897" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>What can we do with the posterior distribution?</span>
<span id="cb53-898"><a href="#cb53-898" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>We can take samples from it, and then do calculations with the samples</span>
<span id="cb53-899"><a href="#cb53-899" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Posterior Prediction</span>
<span id="cb53-900"><a href="#cb53-900" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Given what we've learned, what would happen if we took more samples?</span>
<span id="cb53-901"><a href="#cb53-901" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Sampling distribution (predictive distribution) of draws represents the likelihood of each outcome in a new experiment for a particular value</span>
<span id="cb53-902"><a href="#cb53-902" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>The _posterior predictive_ distribution then represents the entire distribution of the statistic of interest, and contains all the uncertainty around that estimate (analogous to the sampling distribution of a statistic (e.g., mean) in the frequentist paradigm, except this is completely model-driven by the posterior instead of based on asymptotics in the frequentist approach)</span>
<span id="cb53-903"><a href="#cb53-903" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Sampling turns calculus into a data summary problem; this is important when models get complex and numerically intractable to compute by hand</span>
<span id="cb53-904"><a href="#cb53-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-905"><a href="#cb53-905" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This generative, Bayesian framework is the optimal approach for causal estimation _if your model is correct_.</span>
<span id="cb53-906"><a href="#cb53-906" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It honestly carries out the assumptions we put into it, using logical implications</span>
<span id="cb53-907"><a href="#cb53-907" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Quantitative framework/asset that activates our qualitative knowledge as scientists, subject matter experts, etc. Let's the subjective and objective work together. Subjectivity is expertise.</span>
<span id="cb53-908"><a href="#cb53-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-909"><a href="#cb53-909" aria-hidden="true" tabindex="-1"></a>**Misclassification**</span>
<span id="cb53-910"><a href="#cb53-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-911"><a href="#cb53-911" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Use circles around variable in DAG to represent unobserved vs. observed variables</span>
<span id="cb53-912"><a href="#cb53-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-913"><a href="#cb53-913" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Imagine the true number of water samples (W) are unobserved (e.g., measurement error, data error, etc.)</span>
<span id="cb53-914"><a href="#cb53-914" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We observe a _contaminated_ W (called W*) that is the _misclassified_ sample</span>
<span id="cb53-915"><a href="#cb53-915" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>W* is caused by the _measurement process_ M. We can get get back to the correct posterior distribution for p if we use M through W*.</span>
<span id="cb53-916"><a href="#cb53-916" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The posterior is honest about the uncertaintly induced by the misclassification process</span>
<span id="cb53-917"><a href="#cb53-917" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>When there is measurement error, model it instead of ignoring it (same for missing data, compliance, inclusion)</span>
<span id="cb53-918"><a href="#cb53-918" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>_Key point: Samples do not need to be representative of population to provide good estimates, since we can correct them through our causal diagram (modeling the source, sampling process, etc.)_</span>
<span id="cb53-919"><a href="#cb53-919" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This concept may also arise if, for example, the globe was not spun equally likely for every point to be selected.</span>
<span id="cb53-920"><a href="#cb53-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-921"><a href="#cb53-921" aria-hidden="true" tabindex="-1"></a><span class="fu"># 3. Geocentric Models {#lecture3}</span></span>
<span id="cb53-922"><a href="#cb53-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-923"><a href="#cb53-923" aria-hidden="true" tabindex="-1"></a>Week #    Lecture #   Chapter(s)    Week End    Notes Taken</span>
<span id="cb53-924"><a href="#cb53-924" aria-hidden="true" tabindex="-1"></a>------    ---------   ----------    --------    -----------</span>
<span id="cb53-925"><a href="#cb53-925" aria-hidden="true" tabindex="-1"></a>2         3           4             1/13/2023   1/10/2023</span>
<span id="cb53-926"><a href="#cb53-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-927"><a href="#cb53-927" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb53-928"><a href="#cb53-928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-929"><a href="#cb53-929" aria-hidden="true" tabindex="-1"></a>We don't actually need data to construct a model. Our prior distributions, which account for our baseline knowledge about what reasonable values for unknown parameters may be, can produce estimates on their own. A bare minimum strategy is to choose these such that before seeing data, the output of our model produces scientifically reasonable results--there is no reason to allow our model to produce results that we know cannot happen. Then, our data can be introduced to help guide the parameters to an area of focus. In this sense (thinking of the example of points bumping around in parameter space), the data we collect is really just a tool for our model--the model is the central focus, the data just helps the model go to where it needs to go. Also, the idea that there are no correct priors and that priors are just (normalized) posteriors from previous data, make the idea of Bayesian updating very intuitive. It will be interesting to see in coming lectures how we can extend this linear model framework to more "real life" problems with observational data that have potentially tens or hundreds or thousands of potential drivers, and strategies for accounting for the most important ones. Obviously these basic examples are great to build a foundation, but it seems like a huge (sometimes impossible) hurdle to have the time and resources to be able to fully vet out expert-driven causal diagrams and generative models that fully account for all the things, especially in fast-paced environments when everyone is just so busy and there are so many projects to attend to. I'd imagine this is one of the reasons why frequentist analysis persists so much (at least in medical research), because it's the way it's been done and therefore you can get more things done faster, even though in an ideal state a Bayesian approach _is_ the right way to go. Definitely something I've thought about time and time again--how can we balance the rigor and detail needed to construct the appropriate models to achieve better inference while still being efficient with peoples' time? Part of it probably has to do with proving to stakeholders that the inference gained from the "quicker" way is less informative (or just plain wrong) compared to the more involved approach.</span>
<span id="cb53-930"><a href="#cb53-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-931"><a href="#cb53-931" aria-hidden="true" tabindex="-1"></a><span class="fu">## Notes</span></span>
<span id="cb53-932"><a href="#cb53-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-933"><a href="#cb53-933" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Statistical models can attain arbitrarily accurate predictions without having any explanation or accurate structure (i.e., the model is just plain wrong, but happens to produce accurate predictions at the right time)</span>
<span id="cb53-934"><a href="#cb53-934" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Example of this is a previous explanation of orbit pattern of Mars: assuming Earth at the center (geocentric), Mars orbits around Earth but also it's own local orbit (epi-cycles). Using this model, they got very accurate predictions, but this mechanism is completely wrong.</span>
<span id="cb53-935"><a href="#cb53-935" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Orbits are actually elliptical and around the sun, not Earth</span>
<span id="cb53-936"><a href="#cb53-936" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Even though the first one predicts accurately, because the structure/mechanism is wrong, it doesn't extend or generalize to other things. However, the correct mechanism is able to explain orbit patterns of all planets in the solar system.</span>
<span id="cb53-937"><a href="#cb53-937" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Linear regression is a large class of statistical golems</span>
<span id="cb53-938"><a href="#cb53-938" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>**Geogentric**: describes associations, makes good predictions; mechanistically always wrong (but useful), very good approximation; meaning doesn't depend on the model, depends on an external causal model. Nothing wrong with it unless you actually believe it is the true mechanism.</span>
<span id="cb53-939"><a href="#cb53-939" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>**Gaussian**: Abstracts away from detail of general error model; mechanistically silent. General argument about symmetry of error. </span>
<span id="cb53-940"><a href="#cb53-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-941"><a href="#cb53-941" aria-hidden="true" tabindex="-1"></a>**Gaussian**</span>
<span id="cb53-942"><a href="#cb53-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-943"><a href="#cb53-943" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Example: Flip coin, each person take a step to left or right depending on heads/tails, measure distance from center; makes a normal distribution. Why?</span>
<span id="cb53-944"><a href="#cb53-944" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>There are more ways for a sequence of coin tosses to get you close to the middle than there are to get you to the left or right</span>
<span id="cb53-945"><a href="#cb53-945" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Many natural processes attract to this behavior because it is adding together small differences</span>
<span id="cb53-946"><a href="#cb53-946" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Two arguments:</span>
<span id="cb53-947"><a href="#cb53-947" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Generative: summed fluctuations tend towards normal. Ex. growth--added fluctuations over time, same age weight tends to be gaussian</span>
<span id="cb53-948"><a href="#cb53-948" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Inferential: estimating mean/variance. Best to use since least informative (maximum entropy)</span>
<span id="cb53-949"><a href="#cb53-949" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Variable does not need to be normally distributed for normal model to be useful. Machine for estimating mean/variance. Contains the least assumptions. (central limit theorem)</span>
<span id="cb53-950"><a href="#cb53-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-951"><a href="#cb53-951" aria-hidden="true" tabindex="-1"></a>**Skills/Goals for Lecture**</span>
<span id="cb53-952"><a href="#cb53-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-953"><a href="#cb53-953" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Learn a standardized language for representing models (generative and statistical)</span>
<span id="cb53-954"><a href="#cb53-954" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calculate posteriors with multiple unknown parameters</span>
<span id="cb53-955"><a href="#cb53-955" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>How to construct and understand linear models; how to construct posterior predictions from them</span>
<span id="cb53-956"><a href="#cb53-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-957"><a href="#cb53-957" aria-hidden="true" tabindex="-1"></a>**Reminder of the owl**</span>
<span id="cb53-958"><a href="#cb53-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-959"><a href="#cb53-959" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>State a clear question; descriptive, causal, anything; but needs to be clear</span>
<span id="cb53-960"><a href="#cb53-960" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Sketch causal assumptions using DAGs; good way for non-theorists to realize they have a lot of subject knowledge and can get it on paper</span>
<span id="cb53-961"><a href="#cb53-961" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Define a generative model; generates synthetic observations</span>
<span id="cb53-962"><a href="#cb53-962" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Use generative model to build estimator; causal/generative assumptions embedded</span>
<span id="cb53-963"><a href="#cb53-963" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Test, analyze</span>
<span id="cb53-964"><a href="#cb53-964" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Profit: we realize our model was useful, or terrible; either way we gain something</span>
<span id="cb53-965"><a href="#cb53-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-966"><a href="#cb53-966" aria-hidden="true" tabindex="-1"></a>**Describing models**</span>
<span id="cb53-967"><a href="#cb53-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-968"><a href="#cb53-968" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Lists variables</span>
<span id="cb53-969"><a href="#cb53-969" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Define each variable as a deterministic or distributional function of other variables</span>
<span id="cb53-970"><a href="#cb53-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-971"><a href="#cb53-971" aria-hidden="true" tabindex="-1"></a>**Exercise**</span>
<span id="cb53-972"><a href="#cb53-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-973"><a href="#cb53-973" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Goal: Describe the association between adult weight and height</span>
<span id="cb53-974"><a href="#cb53-974" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Height causes weight H--&gt;W&lt;--(U) (unobserved influences on body weight)</span>
<span id="cb53-975"><a href="#cb53-975" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Generative/scientific model: $W=f(H,U)$, $W=\beta H + U$</span>
<span id="cb53-978"><a href="#cb53-978" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-979"><a href="#cb53-979" aria-hidden="true" tabindex="-1"></a>sim_weight <span class="ot">&lt;-</span></span>
<span id="cb53-980"><a href="#cb53-980" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(H,b,sd) {</span>
<span id="cb53-981"><a href="#cb53-981" aria-hidden="true" tabindex="-1"></a>    U <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(H),<span class="dv">0</span>,sd)</span>
<span id="cb53-982"><a href="#cb53-982" aria-hidden="true" tabindex="-1"></a>    W<span class="ot">&lt;-</span>b<span class="sc">*</span>H <span class="sc">+</span> U</span>
<span id="cb53-983"><a href="#cb53-983" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(W)</span>
<span id="cb53-984"><a href="#cb53-984" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-985"><a href="#cb53-985" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate height</span></span>
<span id="cb53-986"><a href="#cb53-986" aria-hidden="true" tabindex="-1"></a>H <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">200</span>,<span class="dv">130</span>,<span class="dv">170</span>)</span>
<span id="cb53-987"><a href="#cb53-987" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">sim_weight</span>(H, <span class="at">b=</span>.<span class="dv">5</span>, <span class="at">sd=</span> <span class="dv">5</span>)</span>
<span id="cb53-988"><a href="#cb53-988" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(W<span class="sc">~</span>H,<span class="at">col=</span><span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb53-989"><a href="#cb53-989" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-990"><a href="#cb53-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-991"><a href="#cb53-991" aria-hidden="true" tabindex="-1"></a>$$W_i=\beta H_i + U_i$$</span>
<span id="cb53-992"><a href="#cb53-992" aria-hidden="true" tabindex="-1"></a>$$U_i \sim Normal(0,\sigma)$$</span>
<span id="cb53-993"><a href="#cb53-993" aria-hidden="true" tabindex="-1"></a>$$H_i \sim Uniform(130, 170)$$</span>
<span id="cb53-994"><a href="#cb53-994" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Statistical model (estimator)</span>
<span id="cb53-995"><a href="#cb53-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-996"><a href="#cb53-996" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We want to estimate how the average weight changes with height.</span>
<span id="cb53-997"><a href="#cb53-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-998"><a href="#cb53-998" aria-hidden="true" tabindex="-1"></a>$$E(W_i|H_i)=\alpha + \beta H_i$$</span>
<span id="cb53-999"><a href="#cb53-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1000"><a href="#cb53-1000" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Posterior distribution</span>
<span id="cb53-1001"><a href="#cb53-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1002"><a href="#cb53-1002" aria-hidden="true" tabindex="-1"></a>$$P(\alpha, \beta, \sigma|H_i,W_i) = \frac{P(W_i|H_i,\alpha,\beta,\sigma)P(\alpha,\beta,\sigma)}{Z}$$</span>
<span id="cb53-1003"><a href="#cb53-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1004"><a href="#cb53-1004" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Gives the posterior probability of a specific regression line</span>
<span id="cb53-1005"><a href="#cb53-1005" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Likelihood: Number of ways we could produce $W_i$, given a line </span>
<span id="cb53-1006"><a href="#cb53-1006" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Prior: The previous posterior distribution; normalized number of ways previous data could have been produced.</span>
<span id="cb53-1007"><a href="#cb53-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1008"><a href="#cb53-1008" aria-hidden="true" tabindex="-1"></a>$$W_i \sim Normal(\mu_i, \sigma)$$</span>
<span id="cb53-1009"><a href="#cb53-1009" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + \beta H_i$$</span>
<span id="cb53-1010"><a href="#cb53-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1011"><a href="#cb53-1011" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Generally more useful to look at the lines (parameter implications together), instead of individual parameters</span>
<span id="cb53-1012"><a href="#cb53-1012" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-1013"><a href="#cb53-1013" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Quadratic approximation</span>
<span id="cb53-1014"><a href="#cb53-1014" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Approximate the posterior distribution using a multivariate Gaussian distribution</span>
<span id="cb53-1015"><a href="#cb53-1015" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Use the <span class="in">`quap`</span> function in the <span class="in">`rethinking`</span> package</span>
<span id="cb53-1016"><a href="#cb53-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1017"><a href="#cb53-1017" aria-hidden="true" tabindex="-1"></a>**Prior Predictive Distribution**</span>
<span id="cb53-1018"><a href="#cb53-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1019"><a href="#cb53-1019" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Should express scientific knowledge, but _softly_</span>
<span id="cb53-1020"><a href="#cb53-1020" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We can make the model make predictions without using data</span>
<span id="cb53-1021"><a href="#cb53-1021" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Not make ranges that represent the data, but rather just those that make sense based on current knowledge</span>
<span id="cb53-1022"><a href="#cb53-1022" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Account for basic reasonable constraints: In general, patients with more weight have more height, and the weight is less than the height, so $\beta$ is probably between $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$.</span>
<span id="cb53-1023"><a href="#cb53-1023" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Use these to define some lines based on the assumptions</span>
<span id="cb53-1026"><a href="#cb53-1026" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-1027"><a href="#cb53-1027" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb53-1028"><a href="#cb53-1028" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb53-1029"><a href="#cb53-1029" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">runif</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb53-1030"><a href="#cb53-1030" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="cn">NULL</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">130</span>,<span class="dv">170</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">90</span>),<span class="at">xlab=</span><span class="st">"height(cm)"</span>,<span class="at">ylab=</span><span class="st">"Weight(kg)"</span>)</span>
<span id="cb53-1031"><a href="#cb53-1031" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>) <span class="fu">abline</span>(<span class="at">a=</span>a[j],<span class="at">b=</span>b[j],<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">col=</span><span class="dv">2</span>)</span>
<span id="cb53-1032"><a href="#cb53-1032" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1033"><a href="#cb53-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1034"><a href="#cb53-1034" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Some of these are probably not plausible (e.g., high height with low weight). Slopes look good but not intercept</span>
<span id="cb53-1035"><a href="#cb53-1035" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We can adjust as needed to create what makes sense</span>
<span id="cb53-1036"><a href="#cb53-1036" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There are no correct priors; only scientifically justifiable priors</span>
<span id="cb53-1037"><a href="#cb53-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1038"><a href="#cb53-1038" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Validate Model</span>
<span id="cb53-1039"><a href="#cb53-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1040"><a href="#cb53-1040" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Bare minimum to test statistical model</span>
<span id="cb53-1041"><a href="#cb53-1041" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Not because you wrote it, more so to make sure your model works</span>
<span id="cb53-1042"><a href="#cb53-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1043"><a href="#cb53-1043" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Analyze data</span>
<span id="cb53-1044"><a href="#cb53-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1045"><a href="#cb53-1045" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Plug in your data set into your process</span>
<span id="cb53-1046"><a href="#cb53-1046" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Parameters are not independent, can't interpret as such</span>
<span id="cb53-1047"><a href="#cb53-1047" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Push out posterior predictions</span>
<span id="cb53-1048"><a href="#cb53-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1049"><a href="#cb53-1049" aria-hidden="true" tabindex="-1"></a><span class="fu"># 4. Categories and Curves {#lecture4}</span></span>
<span id="cb53-1050"><a href="#cb53-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1051"><a href="#cb53-1051" aria-hidden="true" tabindex="-1"></a>Week #    Lecture #   Chapter(s)    Week End    Notes Taken</span>
<span id="cb53-1052"><a href="#cb53-1052" aria-hidden="true" tabindex="-1"></a>------    ---------   ----------    --------    -----------</span>
<span id="cb53-1053"><a href="#cb53-1053" aria-hidden="true" tabindex="-1"></a>2         4           4             1/13/2023   1/11/2023</span>
<span id="cb53-1054"><a href="#cb53-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1055"><a href="#cb53-1055" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb53-1056"><a href="#cb53-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1057"><a href="#cb53-1057" aria-hidden="true" tabindex="-1"></a>The idea of _total_ vs. _direct_ effects is about specifying the statistical model that will allow you to observe the complete effect (i.e., including differences that could be explained by something else in the model) compared to parsing out differences explained by the variable after adjusting for effects explained through other variables. In the lecture example, the total causal effect of sex on weight was determined by using a (Bayesian) intercept-only model, which showed considerable difference is mean weights between male/female. However, when assessing the direct causal effect, a parameter was added to fit separate slopes for male/female in order to block out the effect of sex on weight that is observed through other causes (in this case, height), such that the resulting estimator looked at mean differences in weight _at each height_--the posterior distribution for this difference yielded little to no direct effect, indicating that most of the difference in weight between male/females is due to height differences. Another interesting aspect of this lecture was how to think about which way an arrow should go when drawing the causal diagram. You should think of the interventions we are willing to consider, and which make logical sense. For example, we drew $H \rightarrow W$ because, given a height, it makes sense to employ interventions (such as weight loss program, exercise, etc.) that could presumably impact the resulting weight, but it doesn't make a lot of sense to think of trying to change someone's height given their weight. Also, declaring something as a _cause_ of something, generally you first want to think about whether an intervention can be employed, but if not can still make sense if it is a proxy for something else (e.g., age encapsulates time, among many other things that presumably do cause height). We can use flexible curves to fit things (e.g., splines), but we want to make sure we vet out any erroneous areas where estimates don't make sense, and add necessary restrictions to alleviate. So far, these lectures have given great optimism and excitement for how to approach modeling. I want to be confident in the models I produce, and I think the generative framework is the right approach to be able to believe in the results you are producing. I see so much published research from observational data that declare something statistically significant for a given research hypothesis and say "we adjusted for all these confounders". Even if I feel fine about the math/statistical procedure, I'm always skeptical about the conclusions that are drawn from it, and quite frankly, don't feel like it means much at all for really making a decision--there are just too many limitations about all sorts of things. The generative approach gives the tools and rigor to be much more confident in the results, and if we can be more demanding of that rigor, time and energy, it should yield more benefit in the long run. I'd rather spend more time getting to a confident conclusion than just pumping out results.</span>
<span id="cb53-1058"><a href="#cb53-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1059"><a href="#cb53-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">### A check for understanding</span></span>
<span id="cb53-1060"><a href="#cb53-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1061"><a href="#cb53-1061" aria-hidden="true" tabindex="-1"></a>During (and after) the lecture, it took me a while to gain intuition about what was happening in the generative simulation for the model:</span>
<span id="cb53-1062"><a href="#cb53-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1065"><a href="#cb53-1065" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb53-1066"><a href="#cb53-1066" aria-hidden="true" tabindex="-1"></a><span class="in">flowchart LR</span></span>
<span id="cb53-1067"><a href="#cb53-1067" aria-hidden="true" tabindex="-1"></a><span class="in">  A(Sex) --&gt; C(Weight)</span></span>
<span id="cb53-1068"><a href="#cb53-1068" aria-hidden="true" tabindex="-1"></a><span class="in">  A --&gt; B(Height)</span></span>
<span id="cb53-1069"><a href="#cb53-1069" aria-hidden="true" tabindex="-1"></a><span class="in">  B --&gt; C</span></span>
<span id="cb53-1070"><a href="#cb53-1070" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1071"><a href="#cb53-1071" aria-hidden="true" tabindex="-1"></a>The code was written in the following way:</span>
<span id="cb53-1072"><a href="#cb53-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1075"><a href="#cb53-1075" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-1076"><a href="#cb53-1076" aria-hidden="true" tabindex="-1"></a><span class="co"># S = 1 female, S = 2 male</span></span>
<span id="cb53-1077"><a href="#cb53-1077" aria-hidden="true" tabindex="-1"></a>sim_HW <span class="ot">&lt;-</span> <span class="cf">function</span>(S,b,a) {</span>
<span id="cb53-1078"><a href="#cb53-1078" aria-hidden="true" tabindex="-1"></a>  N <span class="ot">&lt;-</span> <span class="fu">length</span>(S)</span>
<span id="cb53-1079"><a href="#cb53-1079" aria-hidden="true" tabindex="-1"></a>  H <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(S<span class="sc">==</span><span class="dv">1</span>,<span class="dv">150</span>,<span class="dv">160</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb53-1080"><a href="#cb53-1080" aria-hidden="true" tabindex="-1"></a>  W <span class="ot">&lt;-</span> a[S] <span class="sc">+</span> b[S]<span class="sc">*</span>H <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="dv">5</span>)</span>
<span id="cb53-1081"><a href="#cb53-1081" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(S,H,W)</span>
<span id="cb53-1082"><a href="#cb53-1082" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-1083"><a href="#cb53-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1084"><a href="#cb53-1084" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb53-1085"><a href="#cb53-1085" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb53-1086"><a href="#cb53-1086" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">100</span>,<span class="dv">1</span>,.<span class="dv">5</span>) <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb53-1087"><a href="#cb53-1087" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">sim_HW</span>(S, <span class="at">b=</span><span class="fu">c</span>(.<span class="dv">5</span>,.<span class="dv">6</span>), <span class="at">a=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb53-1088"><a href="#cb53-1088" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dat)</span>
<span id="cb53-1089"><a href="#cb53-1089" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1090"><a href="#cb53-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1091"><a href="#cb53-1091" aria-hidden="true" tabindex="-1"></a>First, the indexing used here <span class="in">`b[S]`</span> was odd because <span class="in">`b`</span> is a vector of length 2, and <span class="in">`S`</span> is a vector of length <span class="in">`r length(S)`</span>. But all it is doing is making a vector of length <span class="in">`r length(S)`</span> by looking up the index of <span class="in">`b`</span> at each spot (since <span class="in">`S`</span> is either 1 or 2). I didn't know you could index like that in <span class="in">`R`</span> but I guess you learn something everyday. Anyway, that was not the real thing that confused me.</span>
<span id="cb53-1092"><a href="#cb53-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1093"><a href="#cb53-1093" aria-hidden="true" tabindex="-1"></a>In the lecture, he states that the <span class="in">`a`</span> term represents the _direct_ effect of sex on weight, and the `b` term represents the _indirect_ effect (i.e., proportionality/slope for each sex). It's clear that there are separate lines created for each sex, and you can see the form of an intercept and slope for each one. In my mind, I'm thinking this has to be similar to an interaction in the model, but it wasn't intuitive to me how this really played out and/or there was something different going on here. After some thought on a notepad, it is exactly what I was thinking--just a linear model with an interaction term between sex and height, though it is reparameterized a little to create the _symmetry_ of effects as discussed in the lecture. Anyway, here is how it translates:</span>
<span id="cb53-1094"><a href="#cb53-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1095"><a href="#cb53-1095" aria-hidden="true" tabindex="-1"></a>Currently, we have that the sex indicators are as follows:</span>
<span id="cb53-1096"><a href="#cb53-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1097"><a href="#cb53-1097" aria-hidden="true" tabindex="-1"></a>$$S = 1 (female), 2(male)$$</span>
<span id="cb53-1098"><a href="#cb53-1098" aria-hidden="true" tabindex="-1"></a>Then, the effect of height on weight for each sex is as follows:</span>
<span id="cb53-1099"><a href="#cb53-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1100"><a href="#cb53-1100" aria-hidden="true" tabindex="-1"></a>$$b=(b_{S_1},b_{S_2}) = (0.5, 0.6)$$</span>
<span id="cb53-1101"><a href="#cb53-1101" aria-hidden="true" tabindex="-1"></a>Finally, the intercept within each line is:</span>
<span id="cb53-1102"><a href="#cb53-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1103"><a href="#cb53-1103" aria-hidden="true" tabindex="-1"></a>$$a=(a_{S_1},a_{S_2})=(0,0)$$</span>
<span id="cb53-1104"><a href="#cb53-1104" aria-hidden="true" tabindex="-1"></a>This leads to:</span>
<span id="cb53-1105"><a href="#cb53-1105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1106"><a href="#cb53-1106" aria-hidden="true" tabindex="-1"></a>$$W_{S_1} = a_{S_1} + b_{S_1}H + \epsilon_i = .5H+\epsilon_i$$</span>
<span id="cb53-1107"><a href="#cb53-1107" aria-hidden="true" tabindex="-1"></a>$$W_{S_2} = a_{S_2} + b_{S_1}H + \epsilon_i = .6H + \epsilon_i$$</span>
<span id="cb53-1108"><a href="#cb53-1108" aria-hidden="true" tabindex="-1"></a>We could think of this as a single model equation with four (4) regression coefficients looking like the following:</span>
<span id="cb53-1109"><a href="#cb53-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1110"><a href="#cb53-1110" aria-hidden="true" tabindex="-1"></a>$$W = \beta_1 S_1 + \beta_2 S_2 + \beta_3 H \times S_1 + \beta_4 H \times S_2 + \epsilon_i$$</span>
<span id="cb53-1111"><a href="#cb53-1111" aria-hidden="true" tabindex="-1"></a>where</span>
<span id="cb53-1112"><a href="#cb53-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1113"><a href="#cb53-1113" aria-hidden="true" tabindex="-1"></a>$$S_1 = 1 \text{ if female; 0 otherwise}$$</span>
<span id="cb53-1114"><a href="#cb53-1114" aria-hidden="true" tabindex="-1"></a>$$S_2 = 1 \text{ if male; 0 otherwise}$$</span>
<span id="cb53-1115"><a href="#cb53-1115" aria-hidden="true" tabindex="-1"></a>There is no intercept term in the model. Instead, there are _symmetric_ parameterizations for males and females, instead of making the effects relative to one another (which, as mentioned in the lecture, makes it more intuitive to make priors for). The design matrix for this model would then look something like:</span>
<span id="cb53-1116"><a href="#cb53-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1119"><a href="#cb53-1119" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-1120"><a href="#cb53-1120" aria-hidden="true" tabindex="-1"></a><span class="fu">tribble</span>(</span>
<span id="cb53-1121"><a href="#cb53-1121" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>S1, <span class="sc">~</span>S2, <span class="sc">~</span>H_S1, <span class="sc">~</span>H_S2, <span class="sc">~</span>W,</span>
<span id="cb53-1122"><a href="#cb53-1122" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">150</span>, <span class="dv">0</span>, <span class="dv">80</span>,</span>
<span id="cb53-1123"><a href="#cb53-1123" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">160</span>, <span class="dv">90</span>,</span>
<span id="cb53-1124"><a href="#cb53-1124" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">140</span>, <span class="dv">70</span>,</span>
<span id="cb53-1125"><a href="#cb53-1125" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">165</span>, <span class="dv">0</span>, <span class="dv">75</span></span>
<span id="cb53-1126"><a href="#cb53-1126" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-1127"><a href="#cb53-1127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1128"><a href="#cb53-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1129"><a href="#cb53-1129" aria-hidden="true" tabindex="-1"></a>Basically, every time <span class="in">`S1`</span> is <span class="in">`1`</span> (female), then <span class="in">`S2`</span> is <span class="in">`0`</span> (male), as well as the corresponding value for <span class="in">`H`</span>. </span>
<span id="cb53-1130"><a href="#cb53-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1131"><a href="#cb53-1131" aria-hidden="true" tabindex="-1"></a>_I may have to rethink what I just wrote a bit as the the $S_1$ and $S_2$ columns are actually completely redundant, so not sure if this is right yet_</span>
<span id="cb53-1132"><a href="#cb53-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1133"><a href="#cb53-1133" aria-hidden="true" tabindex="-1"></a>So how would we parameterize this in a more classical regression model? If we just rewrite a few things. Let:</span>
<span id="cb53-1134"><a href="#cb53-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1135"><a href="#cb53-1135" aria-hidden="true" tabindex="-1"></a>$$S=(0(female), 1(male))$$</span>
<span id="cb53-1136"><a href="#cb53-1136" aria-hidden="true" tabindex="-1"></a>Then we assume the model is:</span>
<span id="cb53-1137"><a href="#cb53-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1138"><a href="#cb53-1138" aria-hidden="true" tabindex="-1"></a>$$W = \beta_0+\beta_1 S+\beta_2 H+\beta_3 S\times H + \epsilon_i$$</span>
<span id="cb53-1139"><a href="#cb53-1139" aria-hidden="true" tabindex="-1"></a>If we translate parameter values from the example,</span>
<span id="cb53-1140"><a href="#cb53-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1141"><a href="#cb53-1141" aria-hidden="true" tabindex="-1"></a>$$\beta_0 = 0 \hskip.1in \beta_1 = 0$$</span>
<span id="cb53-1142"><a href="#cb53-1142" aria-hidden="true" tabindex="-1"></a>$$\beta_2 = .5 \hskip.1in \beta_3 = .6-.5 = .1$$</span>
<span id="cb53-1143"><a href="#cb53-1143" aria-hidden="true" tabindex="-1"></a>We then get:</span>
<span id="cb53-1144"><a href="#cb53-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1145"><a href="#cb53-1145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-1146"><a href="#cb53-1146" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-1147"><a href="#cb53-1147" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-1148"><a href="#cb53-1148" aria-hidden="true" tabindex="-1"></a>W_{S=0(female)}</span>
<span id="cb53-1149"><a href="#cb53-1149" aria-hidden="true" tabindex="-1"></a>&amp;= \beta_0 + \beta_1(0) + \beta_2H+\beta_3 0 \times H + \epsilon_i <span class="sc">\\</span></span>
<span id="cb53-1150"><a href="#cb53-1150" aria-hidden="true" tabindex="-1"></a>&amp;= 0 + 0(0) + .5H + .1(0 \times H) + \epsilon_i <span class="sc">\\</span></span>
<span id="cb53-1151"><a href="#cb53-1151" aria-hidden="true" tabindex="-1"></a>&amp;= 0.5H + \epsilon_i</span>
<span id="cb53-1152"><a href="#cb53-1152" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-1153"><a href="#cb53-1153" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-1154"><a href="#cb53-1154" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-1155"><a href="#cb53-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1156"><a href="#cb53-1156" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-1157"><a href="#cb53-1157" aria-hidden="true" tabindex="-1"></a>\begin{equation} </span>
<span id="cb53-1158"><a href="#cb53-1158" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb53-1159"><a href="#cb53-1159" aria-hidden="true" tabindex="-1"></a>W_{S=1(male)}</span>
<span id="cb53-1160"><a href="#cb53-1160" aria-hidden="true" tabindex="-1"></a>&amp;= \beta_0 + \beta_1(1) + \beta_2H+\beta_3 1 \times H + \epsilon_i <span class="sc">\\</span></span>
<span id="cb53-1161"><a href="#cb53-1161" aria-hidden="true" tabindex="-1"></a>&amp;= 0 + 0(1) + .5H + .1(1 \times H) + \epsilon_i <span class="sc">\\</span></span>
<span id="cb53-1162"><a href="#cb53-1162" aria-hidden="true" tabindex="-1"></a>&amp;= 0.5H + 0.1H + \epsilon_i <span class="sc">\\</span></span>
<span id="cb53-1163"><a href="#cb53-1163" aria-hidden="true" tabindex="-1"></a>&amp;= 0.6H + \epsilon_i</span>
<span id="cb53-1164"><a href="#cb53-1164" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb53-1165"><a href="#cb53-1165" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb53-1166"><a href="#cb53-1166" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb53-1167"><a href="#cb53-1167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1168"><a href="#cb53-1168" aria-hidden="true" tabindex="-1"></a>This makes it much more clear why the _direct_ effect is zero, since the main effect of sex is zero in this model. We only see an effect from sex through the interaction with height, which is what is known as the _indirect_ effect.</span>
<span id="cb53-1169"><a href="#cb53-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1170"><a href="#cb53-1170" aria-hidden="true" tabindex="-1"></a><span class="fu">## Homework</span></span>
<span id="cb53-1171"><a href="#cb53-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1172"><a href="#cb53-1172" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>From the <span class="in">`Howell1`</span> dataset, consider only the people younger than 13 years old. Estimate the causal association between age and weight. Assume age influences weight through two paths. First, age influences height, and height influences weight. Second, age directly influences weight through age-related changes in muscle growth and body proportions. Draw the DAG that represents these causal relationships. And then write a generative simulation that takes age as an input and simulates height and weight, obeying the relationships in the DAG.</span>
<span id="cb53-1173"><a href="#cb53-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1174"><a href="#cb53-1174" aria-hidden="true" tabindex="-1"></a>First, we'll import the dataset directly from the package's <span class="co">[</span><span class="ot">Github repository</span><span class="co">](https://github.com/rmcelreath/rethinking)</span>. We will filter to those &lt; 13 years old, and convert height to inches, and weight to lbs:</span>
<span id="cb53-1175"><a href="#cb53-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1178"><a href="#cb53-1178" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-1179"><a href="#cb53-1179" aria-hidden="true" tabindex="-1"></a>howell1 <span class="ot">&lt;-</span></span>
<span id="cb53-1180"><a href="#cb53-1180" aria-hidden="true" tabindex="-1"></a>  <span class="fu">read_delim</span>(</span>
<span id="cb53-1181"><a href="#cb53-1181" aria-hidden="true" tabindex="-1"></a>    <span class="at">file =</span> <span class="st">"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv"</span>,</span>
<span id="cb53-1182"><a href="#cb53-1182" aria-hidden="true" tabindex="-1"></a>    <span class="at">delim =</span> <span class="st">";"</span></span>
<span id="cb53-1183"><a href="#cb53-1183" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb53-1184"><a href="#cb53-1184" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-1185"><a href="#cb53-1185" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Keep those younger than 13</span></span>
<span id="cb53-1186"><a href="#cb53-1186" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(age <span class="sc">&lt;</span> <span class="dv">13</span>) <span class="sc">%&gt;%</span></span>
<span id="cb53-1187"><a href="#cb53-1187" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-1188"><a href="#cb53-1188" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert the units (more intuitive for me)</span></span>
<span id="cb53-1189"><a href="#cb53-1189" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb53-1190"><a href="#cb53-1190" aria-hidden="true" tabindex="-1"></a>    <span class="at">height =</span> height <span class="sc">/</span> <span class="fl">2.54</span>,</span>
<span id="cb53-1191"><a href="#cb53-1191" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> weight <span class="sc">*</span> <span class="fl">2.205</span></span>
<span id="cb53-1192"><a href="#cb53-1192" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb53-1193"><a href="#cb53-1193" aria-hidden="true" tabindex="-1"></a>howell1</span>
<span id="cb53-1194"><a href="#cb53-1194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1195"><a href="#cb53-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1196"><a href="#cb53-1196" aria-hidden="true" tabindex="-1"></a>Next, we can write the causal diagram as described:</span>
<span id="cb53-1197"><a href="#cb53-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1200"><a href="#cb53-1200" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb53-1201"><a href="#cb53-1201" aria-hidden="true" tabindex="-1"></a><span class="in">flowchart LR</span></span>
<span id="cb53-1202"><a href="#cb53-1202" aria-hidden="true" tabindex="-1"></a><span class="in">  A(Age) --&gt; C(Weight)</span></span>
<span id="cb53-1203"><a href="#cb53-1203" aria-hidden="true" tabindex="-1"></a><span class="in">  A --&gt; B(Height)</span></span>
<span id="cb53-1204"><a href="#cb53-1204" aria-hidden="true" tabindex="-1"></a><span class="in">  B --&gt; C</span></span>
<span id="cb53-1205"><a href="#cb53-1205" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1206"><a href="#cb53-1206" aria-hidden="true" tabindex="-1"></a>If we let</span>
<span id="cb53-1207"><a href="#cb53-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1208"><a href="#cb53-1208" aria-hidden="true" tabindex="-1"></a>$$A=Age \hskip.1in H=Height \hskip.1in W=Weight$$</span>
<span id="cb53-1209"><a href="#cb53-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1210"><a href="#cb53-1210" aria-hidden="true" tabindex="-1"></a>Then, we assume that:</span>
<span id="cb53-1211"><a href="#cb53-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1212"><a href="#cb53-1212" aria-hidden="true" tabindex="-1"></a>$$H = f_H(A) \hskip.2in W = f_W(A,H)$$</span>
<span id="cb53-1213"><a href="#cb53-1213" aria-hidden="true" tabindex="-1"></a>Finally, we can write the generative simulation to produce synthetic data governed by the DAG:</span>
<span id="cb53-1214"><a href="#cb53-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1217"><a href="#cb53-1217" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-1218"><a href="#cb53-1218" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulating synthetic children</span></span>
<span id="cb53-1219"><a href="#cb53-1219" aria-hidden="true" tabindex="-1"></a>sim_children <span class="ot">&lt;-</span></span>
<span id="cb53-1220"><a href="#cb53-1220" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(N) {</span>
<span id="cb53-1221"><a href="#cb53-1221" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-1222"><a href="#cb53-1222" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Generate uniform ages</span></span>
<span id="cb53-1223"><a href="#cb53-1223" aria-hidden="true" tabindex="-1"></a>    A <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, <span class="dv">0</span>, <span class="dv">13</span>)</span>
<span id="cb53-1224"><a href="#cb53-1224" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-1225"><a href="#cb53-1225" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Generate heights as a linear combination of age</span></span>
<span id="cb53-1226"><a href="#cb53-1226" aria-hidden="true" tabindex="-1"></a>    H <span class="ot">&lt;-</span> <span class="dv">22</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>A <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb53-1227"><a href="#cb53-1227" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-1228"><a href="#cb53-1228" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Generate weights as a linear combination of age and height</span></span>
<span id="cb53-1229"><a href="#cb53-1229" aria-hidden="true" tabindex="-1"></a>    W <span class="ot">&lt;-</span> .<span class="dv">8</span><span class="sc">*</span>H <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> .<span class="dv">5</span>)</span>
<span id="cb53-1230"><a href="#cb53-1230" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb53-1231"><a href="#cb53-1231" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make a data frame</span></span>
<span id="cb53-1232"><a href="#cb53-1232" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(A, H, W)</span>
<span id="cb53-1233"><a href="#cb53-1233" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb53-1234"><a href="#cb53-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1235"><a href="#cb53-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1236"><a href="#cb53-1236" aria-hidden="true" tabindex="-1"></a>We first generate ages uniformly from 0 to 13, so</span>
<span id="cb53-1237"><a href="#cb53-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1238"><a href="#cb53-1238" aria-hidden="true" tabindex="-1"></a>$$A \sim Uniform(0,13)$$</span>
<span id="cb53-1239"><a href="#cb53-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1240"><a href="#cb53-1240" aria-hidden="true" tabindex="-1"></a>Then, we generate heights from a normal distribution with means that are linearly related to the age.</span>
<span id="cb53-1241"><a href="#cb53-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1242"><a href="#cb53-1242" aria-hidden="true" tabindex="-1"></a>$$H \sim Normal(\mu =22 + 2 \times A, \sigma = 3)$$</span>
<span id="cb53-1243"><a href="#cb53-1243" aria-hidden="true" tabindex="-1"></a>Notice the intercept term to ensure a positive height for children who are 0 years old. _Note: A distribution like the Gamma may be better here to ensure we don't get negative heights. For younger ages, I would assume that the distribution of heights has a little right-skew. In any case, we'll move forward with the Normal distribution here for simplicity sake._</span>
<span id="cb53-1244"><a href="#cb53-1244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1245"><a href="#cb53-1245" aria-hidden="true" tabindex="-1"></a>Then we generate the weights as a linear function of the observed age and heights. </span>
<span id="cb53-1246"><a href="#cb53-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1247"><a href="#cb53-1247" aria-hidden="true" tabindex="-1"></a>$$W \sim Normal(\mu=.8H, \sigma = .5)$$</span>
<span id="cb53-1248"><a href="#cb53-1248" aria-hidden="true" tabindex="-1"></a>We make the assumption that there is a linear relationship between weight with age and height, and that for any age, the increase in mean weight per inch increase in height is the same. In fact, the effect for age is 0 since it is observed through height.</span>
<span id="cb53-1249"><a href="#cb53-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1252"><a href="#cb53-1252" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb53-1253"><a href="#cb53-1253" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate some children</span></span>
<span id="cb53-1254"><a href="#cb53-1254" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb53-1255"><a href="#cb53-1255" aria-hidden="true" tabindex="-1"></a>simmed_children <span class="ot">&lt;-</span> <span class="fu">sim_children</span>(<span class="dv">200</span>)</span>
<span id="cb53-1256"><a href="#cb53-1256" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(simmed_children)</span>
<span id="cb53-1257"><a href="#cb53-1257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb53-1258"><a href="#cb53-1258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1259"><a href="#cb53-1259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1260"><a href="#cb53-1260" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Use a linear regression to estimate the **total** causal effect of each year of growth on weight.</span>
<span id="cb53-1261"><a href="#cb53-1261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1262"><a href="#cb53-1262" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Now suppose the causal association between age and weight might be different between boys and girls. Use a single linear regression, with a categorical variable for sex, to estimate the total causal effect of age on weight separately for boys and girls. How do boys and girls differ? Provide one or more posterior contrasts as a summary.</span>
<span id="cb53-1263"><a href="#cb53-1263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1264"><a href="#cb53-1264" aria-hidden="true" tabindex="-1"></a><span class="fu">## Notes</span></span>
<span id="cb53-1265"><a href="#cb53-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1266"><a href="#cb53-1266" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The linear regression can approximate anything, so we need to design it with the causal model in mind</span>
<span id="cb53-1267"><a href="#cb53-1267" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Generative models + multiple estimands, we'll have multiple estimands</span>
<span id="cb53-1268"><a href="#cb53-1268" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Need post-processing of posterior distribution to gain inference of joint distributino</span>
<span id="cb53-1269"><a href="#cb53-1269" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We require categories, splines, etc. to build causal estimators</span>
<span id="cb53-1270"><a href="#cb53-1270" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Need to _stratify_ by category to get at the estimands we want (separate lines)</span>
<span id="cb53-1271"><a href="#cb53-1271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1272"><a href="#cb53-1272" aria-hidden="true" tabindex="-1"></a>**Example**</span>
<span id="cb53-1273"><a href="#cb53-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1274"><a href="#cb53-1274" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Extend example above to include patient sex, age</span>
<span id="cb53-1275"><a href="#cb53-1275" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Need to determine how height, weight, sex are causally related (add to DAG), and statistically related</span>
<span id="cb53-1276"><a href="#cb53-1276" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>To determine which way the arrows go, think about the interventions you're willing to consider</span>
<span id="cb53-1277"><a href="#cb53-1277" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Don't have to draw them, but the implied unobserved causes of each variable are implied</span>
<span id="cb53-1278"><a href="#cb53-1278" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>These are ignorable _unless shared_ across variables</span>
<span id="cb53-1279"><a href="#cb53-1279" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Ex. temperature is a cause of sex and weight in some species</span>
<span id="cb53-1280"><a href="#cb53-1280" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-1281"><a href="#cb53-1281" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>What is the causal effect of S on W?</span>
<span id="cb53-1282"><a href="#cb53-1282" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Accounts for direct and indirect effect</span>
<span id="cb53-1283"><a href="#cb53-1283" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>We can also ask what is the direct causal effect of S on W?</span>
<span id="cb53-1284"><a href="#cb53-1284" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>These questions require different models</span>
<span id="cb53-1285"><a href="#cb53-1285" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb53-1286"><a href="#cb53-1286" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Generally want to assign the same prior for parameters for each category level (below)</span>
<span id="cb53-1287"><a href="#cb53-1287" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Using indexing is advantageous because you have symmetry such that all parameters can get the same prior, they are all interpreted the same within their levels</span>
<span id="cb53-1288"><a href="#cb53-1288" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Using indicators makes parameters relative to other levels, which causes you have to put priors on other parameters because it is an adjustment parameter (one is an average, one is an adjustment to an average)</span>
<span id="cb53-1289"><a href="#cb53-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1290"><a href="#cb53-1290" aria-hidden="true" tabindex="-1"></a>$$W_i \sim Normal(\mu_i, \sigma) \hskip.1in \mu_i=\alpha_{S<span class="co">[</span><span class="ot">i</span><span class="co">]</span>}$$</span>
<span id="cb53-1291"><a href="#cb53-1291" aria-hidden="true" tabindex="-1"></a>$$\alpha = <span class="co">[</span><span class="ot">\alpha_1, \alpha_2</span><span class="co">]</span> \hskip.1in \alpha_j \sim Normal(60,10)$$</span>
<span id="cb53-1292"><a href="#cb53-1292" aria-hidden="true" tabindex="-1"></a>**Total Causal Effect**</span>
<span id="cb53-1293"><a href="#cb53-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1294"><a href="#cb53-1294" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simulate one data set of all males, another of all females, look at the average difference in weight</span>
<span id="cb53-1295"><a href="#cb53-1295" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>This is the actual causal effect</span>
<span id="cb53-1296"><a href="#cb53-1296" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Then you can generate a random data set, run the modeling process, and then ensure that the model provides the expected estimate</span>
<span id="cb53-1297"><a href="#cb53-1297" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Look at the posterior distribution of the mean difference, and randomly draw samples from the individual posteriors and compute the differences to answer questions like "what is the probability that a randomly selected male will be heavier than a randomly selected female?"</span>
<span id="cb53-1298"><a href="#cb53-1298" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>This was basically just an intercept-only model for sex, and the effect due to height would be captured in that difference</span>
<span id="cb53-1299"><a href="#cb53-1299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1300"><a href="#cb53-1300" aria-hidden="true" tabindex="-1"></a>**Direct Effect**</span>
<span id="cb53-1301"><a href="#cb53-1301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1302"><a href="#cb53-1302" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>How do we partial out the indirect effect of Height (block it)?</span>
<span id="cb53-1303"><a href="#cb53-1303" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Stratify by height to block the association between S and W that is transmitted through H</span>
<span id="cb53-1304"><a href="#cb53-1304" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Difference in intercept, the indirect is slope differences</span>
<span id="cb53-1305"><a href="#cb53-1305" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Here, the model allows for separate slopes by sex, so we can tease out the impact of height</span>
<span id="cb53-1306"><a href="#cb53-1306" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Center the height to make the interpretation of the intercept be the average</span>
<span id="cb53-1307"><a href="#cb53-1307" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Makes priors more intuitive, and computation easier</span>
<span id="cb53-1308"><a href="#cb53-1308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1309"><a href="#cb53-1309" aria-hidden="true" tabindex="-1"></a>$$W_i \sim Normal(\mu_i, \sigma) \hskip.1in \mu_i=\alpha_{S<span class="co">[</span><span class="ot">i</span><span class="co">]</span>} + \beta_{S<span class="co">[</span><span class="ot">i</span><span class="co">]</span>}(H_i-\bar{H})$$</span>
<span id="cb53-1310"><a href="#cb53-1310" aria-hidden="true" tabindex="-1"></a>$$\alpha=<span class="co">[</span><span class="ot">\alpha_1,\alpha_2</span><span class="co">]</span> \hskip.1in \beta=<span class="co">[</span><span class="ot">\beta_1,\beta_2</span><span class="co">]</span>$$</span>
<span id="cb53-1311"><a href="#cb53-1311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1312"><a href="#cb53-1312" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>In this case, nearly all the total effect of sex on weight is explained through height (the direct effect (posterior of the difference between weights at each height) is nearly 0 at all heights)</span>
<span id="cb53-1313"><a href="#cb53-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1314"><a href="#cb53-1314" aria-hidden="true" tabindex="-1"></a>**Curve Fitting**</span>
<span id="cb53-1315"><a href="#cb53-1315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1316"><a href="#cb53-1316" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>We use linear models to do this; i.e., it's not mechanistic, but we use it wisely</span>
<span id="cb53-1317"><a href="#cb53-1317" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Strategies</span>
<span id="cb53-1318"><a href="#cb53-1318" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Polynomials: Don't do it; no local smoothing, only global; learn to much from data in regions that lie far away </span>
<span id="cb53-1319"><a href="#cb53-1319" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>It's not worth having a model that looks OK for most of the data that we know is completely erroneous (e.g., parabola at some point shows babies get heavier as their height decreases, which we know is wrong); even though this is a small portation of observations, it's still knowingly wrong, so why use it?</span>
<span id="cb53-1320"><a href="#cb53-1320" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Splines &amp; GAMs: Not as bad as polynomials; add total many locally trained terms</span>
<span id="cb53-1321"><a href="#cb53-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1322"><a href="#cb53-1322" aria-hidden="true" tabindex="-1"></a>**Splines**</span>
<span id="cb53-1323"><a href="#cb53-1323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1324"><a href="#cb53-1324" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Flexible curve that will find trends</span>
<span id="cb53-1325"><a href="#cb53-1325" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>B-splines are linear models containing additive terms with synthetic variables</span>
<span id="cb53-1326"><a href="#cb53-1326" aria-hidden="true" tabindex="-1"></a><span class="ss">  + </span>Think of it as a collection of individual curves (basis functions), but the weight of each basis function is non-zero at only particular areas of x, and spline is the sum of the curves at a particular point</span>
<span id="cb53-1327"><a href="#cb53-1327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1328"><a href="#cb53-1328" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + w_1B_{i,1} + w_2B_{i,2} + ...$$</span>
<span id="cb53-1329"><a href="#cb53-1329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1330"><a href="#cb53-1330" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Ideal model for age/height would be to account for what we know about human biology: infant, toddler, adolescent, adult. In the first 3, we expect only upward growth, so we should constrain.</span>
<span id="cb53-1331"><a href="#cb53-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1332"><a href="#cb53-1332" aria-hidden="true" tabindex="-1"></a>**Full Luxury Bayes**</span>
<span id="cb53-1333"><a href="#cb53-1333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-1334"><a href="#cb53-1334" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Equivalent approach is to use one model for entire causal sample</span>
<span id="cb53-1335"><a href="#cb53-1335" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Then run simulations from overall system to get answers to specific queries</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2025 Zajichek Stats</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>