{
  "hash": "3a0cb44352f2f749371e9d462f5abf3e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"A look at collider bias\"\nauthor: \"Alex Zajichek\"\ndate: \"7/15/2021\"\nimage: \"feature.png\"\ncategories:\n  - Causal Inference\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n---\n\n\n\nThere has been a lot of buzz around [\"causal inference\"](https://en.wikipedia.org/wiki/Causal_inference) and given how fundamental the name seems to statistics, I picked up [_The Book of Why: The New Science of Cause and Effect_](http://bayes.cs.ucla.edu/WHY/) as a starting point. It's been a great resource for introducing causal concepts and thinking about the importance of bringing subjectivity into the modeling process. This article looks into one of the concepts introduced: [_collider bias_](https://catalogofbias.org/biases/collider-bias/). All code snippets are written in [`R`](https://www.r-project.org/).\n\n# What is collider bias?\n\nIn causal inference, the relationships between a network of events are represented in [_causal diagrams_](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7064555/). In the causal diagram below, event __A__ causes event __B__ which causes event __C__. Here the term \"event\" refers to a random variable.\n\n\n\n```{mermaid}\nflowchart LR\n  A --> B\n  B --> C\n```\n\n\n\nThe direction in which arrows point into the events (forming a _junction_) have major implications as to how the model behaves. One junction in particular, which is the focus of this article, is called a [_collider_](https://catalogofbias.org/biases/collider-bias/). This is shown in the causal diagram below. \n\n\n\n```{mermaid}\nflowchart LR\n  A --> C\n  B --> C\n```\n\n\n\nA collider occurs when an event is independently caused by two other events. In the example, event __C__ is caused by events __A__ and __B__.\n\nNow, there is no causal relationship between __A__ and __B__ (since there are no arrows between the two). However, if the model were conditioned on __C__, a correlation between __A__ and __B__ would be induced that does not exist in the unconditional distribution. This is known as [_collider bias_](https://catalogofbias.org/biases/collider-bias/).\n\nA basic example that [the book](http://bayes.cs.ucla.edu/WHY/) gives is to repeatedly flip two fair coins simultaneously but only keep samples where at least one of the coins shows heads. Let's do 10,000 flips and tabulate the results:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load some packages\nrequire(tidyverse)\n\n# Set the seed\nset.seed(123)\n\n# Number of coin flips \nn <- 10000\n\n# Generate random binomials\ncoin1 <- rbinom(n = n, size = 1, p = 0.5)\ncoin2 <- rbinom(n = n, size = 1, p = 0.5)\n\n# Make a tibble\ntibble(\n  `Coin 1` = coin1,\n  `Coin 2` = coin2\n) %>%\n  \n  # Convert to factors\n  mutate_all(\n    ~\n      .x %>%\n      factor() %>%\n      fct_recode(\n        Heads = \"1\",\n        Tails = \"0\"\n      ) %>%\n      fct_relevel(\n        \"Heads\"\n      )\n  ) %>%\n  \n  ### Filter to at least one heads\n  filter(\n    `Coin 1` == \"Heads\" |\n      `Coin 2` == \"Heads\"\n  ) %>%\n  \n  # Count the rows\n  group_by_all() %>%\n  summarise(\n    N = n(),\n    .groups = \"drop\"\n  ) %>%\n  \n  # Send over columns\n  pivot_wider(\n    names_from = `Coin 2`,\n    values_from = N,\n    values_fill = 0\n  ) %>%\n  \n  # Make a kable\n  knitr::kable(\n    format = \"html\",\n    caption = str_c(\"Tabulation of \", n, \" simulataneously coin flips excluding cases when both were tails.\")\n  ) %>%\n  kableExtra::kable_styling(\n    full_width = FALSE\n  ) %>%\n  kableExtra::add_header_above(\n    c(\"\", \"Coin 2\" = 2)\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Tabulation of 10000 simulataneously coin flips excluding cases when both were tails.</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Coin 2</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Coin 1 </th>\n   <th style=\"text-align:right;\"> Heads </th>\n   <th style=\"text-align:right;\"> Tails </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Heads </td>\n   <td style=\"text-align:right;\"> 2403 </td>\n   <td style=\"text-align:right;\"> 2540 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Tails </td>\n   <td style=\"text-align:right;\"> 2499 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nNow the question: Is the probability of a heads for one coin the same regardless of what the other coin shows? From our data,\n\n$$P(\\text{Coin 1 = Heads | Coin 2 = Heads}) = \\frac{2403}{2403 + 2499} \\approx 0.49$$\n\n$$P(\\text{Coin 1 = Heads | Coin 2 = Tails}) = \\frac{2540}{2540 + 0} = 1$$\n\nThese results suggest that the coins are not independent. When coin 2 is heads, coin 1 is fair. When coin 2 is tails, coin 1 is certain to be heads. However, we flipped the coins independently so we know there is not a relationship between them. This is an example of collider bias. Here is the causal diagram for this model:\n\n\n\n```{mermaid}\nflowchart LR\n  A[Coin 1] --> C[Keep trial result]\n  B[Coin 2] --> C\n```\n\n\n\nThe decision to keep the result depends on the values of both coins. Once we condition on the trials that we kept, a correlation is induced.\n\n# Example: selecting patients for a trial\n\nLet's go through a more practical example. _Note this is completely made up_.\n\n## Key question\n\n**Do patients who live further from a trial center have more severe disease?**\n\n## The setup\n\nThere is a clinical trial that we would like to recruit patients for which will be held at a single location. The study population consists of patients who have a disease of interest and live within 90 miles of the trial center. Suppose the following are true:\n\n1. 65% of patients live _near_ (within 20 miles of) the trial center (denoted __N__)\n2. 25% of patients have _severe_ disease regardless how far they live from the trial center (denoted __S__)\n\nSo we have...\n\n$$P(N) = 0.65 \\hskip{.25in} P(S|N) = 0.25 \\hskip{.25in} P(S|\\bar{N}) = 0.25$$\nOur sampling strategy will be to select patients at random from the entire population until 1000 are enrolled.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set a seed\nset.seed(321)\n\n# Base sample size\nbase_size <- 100000\n\n# Enrollment size\nn <- 1000\n\n# Make a data frame\npatients <-\n  tibble(\n    S = rbinom(base_size, 1, .25), # Disease severity\n    N = rbinom(base_size, 1, .65), # Distance from center\n  ) %>%\n  \n  # Add enrollment flag based on\n  mutate(\n    E = \n      # Determine enrollment probability\n      case_when(\n        N == 1 ~ 0.85,\n        S == 1 ~ 0.50,\n        TRUE ~ 0.10\n      ) %>%\n      \n      # Sample based on probability\n      rbinom(\n        n = base_size,\n        size = 1\n      )\n  ) %>%\n  \n  # Filter to enrolled patients\n  filter(\n    E == 1\n  ) %>%\n  \n  # Sample the desired enrollment\n  slice_sample(\n    n = n\n  ) %>%\n  \n  # Convert to factors\n  mutate(\n    S = \n      S %>%\n      factor() %>%\n      fct_recode(\n        Severe = \"1\",\n        `Non-severe` = \"0\"\n      ) %>%\n      fct_relevel(\"Severe\"),\n    N = \n      N %>%\n      factor() %>%\n      fct_recode(\n        Near = \"1\",\n        Far = \"0\"\n      ) %>%\n      fct_relevel(\"Near\")\n  ) %>%\n  \n  # Remove the enrollment indicator\n  select(\n    -E\n  )\n```\n:::\n\n\n\n## The problem\n\nSuppose we reach the desired enrollment size and we're given a data set (called `patients`) to do some preliminary analysis on the sample. Here are the first 5 rows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(patients, n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 2\n  S          N    \n  <fct>      <fct>\n1 Non-severe Near \n2 Severe     Far  \n3 Severe     Near \n4 Non-severe Near \n5 Non-severe Near \n# ℹ 995 more rows\n```\n\n\n:::\n:::\n\n\n\nWe have all 1000 patients represented in the data with two variables collected so far: disease severity (__S__) and distance from the trial center (__N__). Let's tabulate these columns:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npatients %>%\n  \n  # Count the rows\n  group_by(N, S) %>%\n  summarise(\n    Count = n(),\n    .groups = \"drop\"\n  ) %>%\n  \n  # Send over the columns\n  pivot_wider(\n    names_from = N,\n    values_from = Count\n  ) %>%\n  \n  # Rename\n  rename(\n    `Disease severity` = S\n  ) %>%\n  \n  # Make a kable\n  knitr::kable(\n    format = \"html\",\n    caption = \"Tabulation of disease severity and distance from trial center for 1000 sampled patients\"\n  ) %>%\n  kableExtra::kable_styling(\n    full_width = FALSE\n  ) %>%\n  kableExtra::add_header_above(c(\"\", \"Distance from trial center\" = 2))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Tabulation of disease severity and distance from trial center for 1000 sampled patients</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Distance from trial center</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Disease severity </th>\n   <th style=\"text-align:right;\"> Near </th>\n   <th style=\"text-align:right;\"> Far </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Severe </td>\n   <td style=\"text-align:right;\"> 221 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Non-severe </td>\n   <td style=\"text-align:right;\"> 650 </td>\n   <td style=\"text-align:right;\"> 47 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nThere is something strange: Of the patients who live near the trial center, 25.4% have severe disease (which is expected), but of those living far from the trial center, 63.6% have severe disease. We know that only 25% of patients have severe disease regardless of where they live. Is this possible? Did this just happen by chance?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.test(sum(patients$S == \"Severe\" & patients$N == \"Far\"), sum(patients$N == \"Far\"), p = 0.25)$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.321956e-23\n```\n\n\n:::\n:::\n\n\n\nWell, the p-value isn't 0 (it will never be), so it _is_ possible. However, there is probably something else going on. What else could be causing this discrepancy?\n\n## An explanation\n\nIf we think about the patients randomly selected and offered enrollment versus those ultimately deciding to enroll, a reasonable assumption might be that those with less-severe disease, especially those who also live far away, may be more reluctant to join. This is exactly what happened.\n\nIt turns out that the following are also true about this population with respect to their likelihood to _join_ the trial (denoted __J__):\n\n1. 85% of patients living near the trial center will join if asked regardless of disease severity\n2. Of those living far from the trial center, 50% will join if they have severe disease and only 10% will join if they don't.\n\nIn probability notation:\n\n$$P(J|N) = 0.85 \\hskip{.25in} P(J|\\bar{N} \\cap S) = 0.50 \\hskip{.25in} P(J|\\bar{N} \\cap \\bar{S}) = 0.10$$\nEven though every patient had the same opportunity to enroll in the trial, our realized sample became much more heavily weighted toward those living near the trial center, and much less weighted toward those living far from the trial center without severe disease. Thus, it conditioned on the patients that enrolled. As a result, a correlation between disease severity and the distance from the trial center was induced that isn't there in the general population. The figure below displays the causal diagram for this relationship.\n\n\n\n```{mermaid}\nflowchart LR\n  A[Distance from center] --> C[Decision to join trial]\n  B[Disease severity] --> C\n```\n\n\n\n### Does the math show it?\n\nWe know that 25% of patients in the general population have severe disease regardless of where they live. How does this probability change for patients who live far from the trial center when we condition on only those enrolled?\n\n$$\n\\begin{equation} \n\\begin{split}\nP(S|\\bar{N} \\cap J) & = \\frac{P(S \\cap \\bar{N} \\cap J)}{P(\\bar{N} \\cap J)} \\\\\n& = \\frac{P(S \\cap \\bar{N} \\cap J)}{P(S \\cap \\bar{N} \\cap J) + P(\\bar{S} \\cap \\bar{N} \\cap J)} \\\\\n& = \\frac{P(J|\\bar{N} \\cap S)P(\\bar{N} \\cap S)}{P(J|\\bar{N} \\cap S)P(\\bar{N} \\cap S) + P(J|\\bar{N} \\cap \\bar{S})P(\\bar{N} \\cap \\bar{S})} \\\\\n& = \\frac{P(J|\\bar{N} \\cap S)P(S|\\bar{N})P(\\bar{N})}{P(J|\\bar{N} \\cap S)P(S|\\bar{N})P(\\bar{N}) + P(J|\\bar{N} \\cap \\bar{S})P(\\bar{S}|\\bar{N})P(\\bar{N})} \\\\\n& = \\frac{P(J|\\bar{N} \\cap S)P(S|\\bar{N})}{P(J|\\bar{N} \\cap S)P(S|\\bar{N})+ P(J|\\bar{N} \\cap \\bar{S})P(\\bar{S}|\\bar{N})} \\\\\n& = \\frac{0.50 \\times 0.25}{0.50 \\times 0.25 + 0.10 \\times (1 - 0.25)} \\\\\n& = 0.625\n\\end{split}\n\\end{equation}\n$$\nAh, much better. Recall that in our sample 63.6% of patients who lived far from the trial center had severe disease. This is much closer to the true probability that we'd expect after conditioning on the correct factors.\n\nIntuitively, this result makes sense. If patients who live far away and have less-severe disease are the most unlikely to join the trial, then a patient who is enrolled and lives far away is more likely to have severe disease.\n\n# Conclusion\n\nCollider bias is a very interesting and important concept to consider when conducting a statistical analysis. In the examples throughout this article, we had the luxury of knowing the true probabilities of various events so we could easily identify and reconcile problems in the estimates. In practice, these are generally unknown quantities which makes this problem much more subtle and unapparent when relying solely on the data. Thus illustrating the importance of incorporating prior knowledge and subject-matter expertise into the modeling process.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}