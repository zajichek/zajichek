---
title: Statistical Rethinking 2023 Class Notes
author: Alex Zajichek
date: '2023-01-06'
slug: statistical-rethinking-2023-class-notes
categories: []
tags: []
subtitle: 'Summaries, interpretations, and examples'
summary: ''
authors: []
lastmod: '2023-01-06T09:37:10-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="{{< blogdown/postref >}}index_files/htmlwidgets/htmlwidgets.js"></script>
<script src="{{< blogdown/postref >}}index_files/viz/viz.js"></script>
<link href="{{< blogdown/postref >}}index_files/DiagrammeR-styles/styles.css" rel="stylesheet" />
<script src="{{< blogdown/postref >}}index_files/grViz-binding/grViz.js"></script>


<p>This document is intended to be a repository for my (raw, unedited) notes, interpretations, examples, and summaries from the <a href="https://github.com/rmcelreath/stat_rethinking_2023">Statistical Rethinking 2023</a> course (which Richard McElreath has graciously made available for free (!) covering <a href="https://xcelab.net/rm/statistical-rethinking/">his book</a>). I’m not actually enrolled in the course, but just following the lectures and material as they are released on a weekly basis. I have a strong interest in learning and incorporating Bayesian analysis and causal principles into my work, and this seemed like a great opportunity to build a foundation for that.</p>
<div id="table-of-contents" class="section level1">
<h1>Table of Contents</h1>
<ol style="list-style-type: decimal">
<li><a href="#lecture1">Science Before Statistics</a></li>
<li><a href="#lecture2">Garden of Forking Data</a></li>
<li><a href="#lecture3">Basic Regression</a></li>
<li><a href="#lecture4">Not-so-basic Regression</a></li>
</ol>
</div>
<div id="lecture1" class="section level1">
<h1>1. Science Before Statistics</h1>
<table>
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1</td>
<td>1</td>
<td>1/6/2023</td>
<td>1/3/2023</td>
</tr>
</tbody>
</table>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>This course focus is on scientific modeling via causal inference, which is focused on identifying causes in <em>observational</em> data. Causal Inference requires us to consider the mechanism of a phenomenon, and think about not only which variables cause other variables, but in what order–subject matter expertise is of utmost importance, and we don’t really depend on the data at hand until the very end of our inference process. Causal modeling must become the foundation to do analysis by–we can’t just do simple statistics in one project and then think about causal modeling in another–samples are from populations and there are causes associated with why we observed the sample we did, even if we’re answering very basic questions. Also, <em>Bayesian</em> modeling as a means to performing causal inference is not due to philosophical reasons (e.g., frequentist vs. Bayesian), it’s more so because a Bayesian framework provides the most natural tools to employ the specified causal model (i.e., if the frequentist model made sense for answering the causal question, we’d use it). The generative aspect of Bayesian modeling is one aspect in particular that makes it very inviting to represent the causal model in a statistical framework, and apply distributions. Finally, coding is not just a means to employ the math, but rather needs to be treated as part of the product, therefore employing software engineering principles, having documentation, making things reproducible. These things need to be employed if you really want to advance knowledge with confidence.</p>
</div>
<div id="notes" class="section level2">
<h2>Notes</h2>
<p><strong>Overview</strong></p>
<ul>
<li>Most interested in Causal Inference, focusing on the <em>science</em> before the <em>statistics</em></li>
<li>We must be able to talk about causes to obtain scientific knowledge, why else would we do it?</li>
<li>Causes can’t be extracted from data; must come from knowledge, assumptions</li>
</ul>
<p><strong>What is Causal Inference?</strong></p>
<ul>
<li>It is more than associations; associations are bi-directional, and correlation is only a basic measure of association;</li>
<li>It is all about intervention, directionality, and the <em>prediction</em> of the consequence of changing one variable on another (asking <em>what-if?</em>)</li>
</ul>
<p><strong>Causal Imputation</strong></p>
<ul>
<li>This is about being able to construct <em>counterfactual</em> outcomes</li>
<li>Asking the question, <em>what if I had done something else?</em></li>
<li>We only observe a single outcome, but we want to know what would have happened had a certain intervention not taken place</li>
</ul>
<p><strong>Directed Acyclic Graph (DAG)</strong></p>
<ul>
<li>Nothing more than an abstraction about which variables cause which other variables</li>
<li>Shows the direction at which variables cause each other, but doesn’t specify <em>how</em> (i.e., effect shapes, etc.)</li>
<li>We can use this to know which things to control for, answer hypothetical interventions, under the assumption that the model is true</li>
<li>It provides a tool to answer very specific questions (queries); not necessarily all questions lead to the same statistical model, but the appropriate statistical model can be derived from the causal model depending on the question</li>
<li><em>Intuition Pumps</em>: Gets the researcher to think about mechanism; great way to problem solve with SME’s without looking at the data (which is how it should be)</li>
</ul>
<p><strong>Golems (statistical models)</strong></p>
<ul>
<li>Metaphor for what a statistical model is; it’s a very useful machine that will do what it’s asked very well, but has no wisdom or forethought</li>
<li>Does not know the intent of the task</li>
<li>Statistical models are just objective tools, but we need causal models to know how and when certain models are actually appropriate</li>
</ul>
<p><strong>Statistical Models</strong></p>
<ul>
<li>Having a flowchart of tests is not useful, except maybe in the <em>experimental</em> setting (remember we’re talking observational data)</li>
<li>Statistical models/tests don’t make a clear relationship between the research and the data; it’s just math</li>
</ul>
<p><strong>Hypotheses &amp; Models</strong></p>
<ul>
<li>We need <em>generative</em> causal models that are guided by the DAG’s</li>
<li>We need <em>estimands</em> that are statistical models justified by the generative models (how do we quantify what we’re after?)</li>
<li>Introduce real data at the end–this is the easy part</li>
</ul>
<p><strong>Justifying Controls</strong></p>
<ul>
<li>Cannot just control for everything in your dataset like is done so much in current research (e.g., colliders have undesired effect)</li>
<li>Need the causal model (DAG) to be able to deduce what should be controlled for based on the specific question that is asked</li>
<li><em>Adjustment Set:</em> The variables determined appropriate to control for for a particular query</li>
</ul>
<p><strong>Why Bayesian?</strong></p>
<ul>
<li>Bayesian happens to be the easiest approach for generative models; it’s not because we’re stuck in a philosophical debate</li>
<li>Easiest way to take the scientific structure of the assumed model and generate it, since it naturally has <em>direction</em> (i.e., priors)</li>
<li>In most cases, Bayes can be appropriate (sometimes not–cut cake with chainsaw)
<ul>
<li>Measurement error, missing data, latent variables, regularization</li>
</ul></li>
<li>It is <em>practical</em>, not <em>philosophical</em></li>
</ul>
<p><strong>Owls</strong></p>
<ul>
<li>Classic joke: Step 1 = Draw two circles, Step 2 = draw remaining owl
<ul>
<li>Programming and technical things tend to be taught this way, but we want to avoid this and document all the intermediate steps</li>
</ul></li>
<li>We need to have an explicit workflow with clear steps</li>
<li>We need to treat coding/scripting seriously, not just a means to something (apply software engineering principles, documentation, quality control)</li>
<li>Understand what you are doing, document your work and reduce error, have a respectable scientific workflow, be professional and organized to maintain <em>reproducible</em> scientific knowledge, otherwise it’s all bullshit</li>
<li>Workflow
<ol style="list-style-type: decimal">
<li>Theoretical Estimand (what are we trying to do?)</li>
<li>Scientific (Causal) Model (DAG + Generative)</li>
<li>Use 1 &amp; 2 to build appropriate statistical model</li>
<li>Simulate from 2 to validate that 3 yields 1</li>
<li>Analyze the actual data</li>
</ol></li>
</ul>
</div>
</div>
<div id="lecture2" class="section level1">
<h1>2. Garden of Forking Data</h1>
<table>
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>2, 3</td>
<td>1/6/2023</td>
<td>1/6/2023</td>
</tr>
</tbody>
</table>
<div id="summary-1" class="section level2">
<h2>Summary</h2>
<p>This scientific modeling framework provides an <em>objective</em> process to incorporate <em>subjective</em> (expert, scientfic) knowledge into the modeling process, enabling us to incorporate all of the uncertainty associated with those processes, predicated on the assumption of the causal model. Further, one of the key takeaways was that <em>samples do not need to be representative of the population for us to provide good estimates</em>. This is profound because generally we are taught the opposite, but because of the process, we can explicitly account for how we know/assume the data was generated, and use that information to create a good estimate of the quantity we are interested in. This is much more <em>practical</em> than the assumptions that are made in a typical frequentist analysis–which tend to be blindly made which ironically makes them more wrong than the “subjective” information in the generative approach. We can then use sampling of our posterior distribution(s) to answer questions about what might happen if we do another experiment, etc. (e.g., what if we take 10 more samples?). Instead of relying on asymptotics for the sampling distribution of a statistic (frequentist), we can just take samples from the posterior for any complex quantity of interest and get the uncertainty surrounding that. This is especially important once we are dealing with analytically intractable posteriors that don’t have closed form solutions. Instead of needing expert-level calculus knowledge for such problem, we just have to follow the same workflow as in this basic problem. After years of frequentist modeling, that is always full of limitations and disatisfaction in the results, this approach will lead to much more rewarding scientific discovery and confidence in the conclusions of research.</p>
<div id="my-check-for-understanding" class="section level3">
<h3>My check for understanding</h3>
<p>Let’s go through and reproduce some of the content/concepts from slides but using our own explanation, implementation and interpretation along the way.</p>
<div id="what-is-the-objective" class="section level4">
<h4>1. What is the objective?</h4>
<p>The main question asked in the demonstration was <em>what proportion of the globe is water?</em>. Thus, the quantity we are interested in is a single quantity: the <em>true</em> proportion of of the globe that is water.</p>
</div>
<div id="what-is-the-sampling-strategy" class="section level4">
<h4>2. What is the sampling strategy?</h4>
<p>We want to collect data to try to answer the question of interest. This will be done by spinning the globe and dropping a pin at a random location to indicate if it is either land or water. Some initial assumptions are</p>
<ul>
<li>All points on the globe are equally-likely to be selected</li>
<li>Any given point on the globe is either land or water (only two possibilities)</li>
<li>There is no measurement error associated with indicating if the selected point was land or water</li>
</ul>
</div>
<div id="what-is-the-generative-model" class="section level4">
<h4>3. What is the generative model?</h4>
<p>We want to consider the different variables at play here as it relates to any observed sample we get as a result of the sampling strategy. First and foremost, the primary <em>unknown</em> parameter is:</p>
<p><span class="math display">\[p=\text{proportion of water on the globe}\]</span></p>
<p>The other two at play (under this simplistic model) are:</p>
<p><span class="math display">\[N=\text{Number of globe spins} \hskip.5in W=\text{Number of spins resulting in water}\]</span>
<em>Note that the number of spins resulting in land is just <span class="math inline">\(N-W\)</span></em></p>
<p>With the variables defined, the next step is determine how these variables relate to each other. We’ll use the following DAG:</p>
<pre class="r"><code>DiagrammeR::grViz(&quot;
  digraph graph2 {
    graph [layout = dot, rankdir = LR]
    node [style = filled]
    a [label = &#39;p&#39;, fillcolor = yellow]
    b [label = &#39;N&#39;]
    c [label = &#39;W&#39;]
    a -&gt; c
    b -&gt; c
  }
&quot;, height = 200, width = 350)</code></pre>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-1"></span>
<div id="htmlwidget-1" style="width:350px;height:200px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"diagram":"\n  digraph graph2 {\n    graph [layout = dot, rankdir = LR]\n    node [style = filled]\n    a [label = \"p\", fillcolor = yellow]\n    b [label = \"N\"]\n    c [label = \"W\"]\n    a -> c\n    b -> c\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 1: Unobserved quantities are highlighted in yellow
</p>
</div>
<p>This assumes that the number of water spins observed in our sample is determined by:</p>
<ol style="list-style-type: decimal">
<li>The true proportion of water on the globe</li>
<li>The total number of spins of the globe made (samples)</li>
</ol>
</div>
<div id="what-is-the-statistical-modelestimation-procedure" class="section level4">
<h4>4. What is the statistical model/estimation procedure?</h4>
<p>Let’s suppose we execute the sampling procedure which yields the following response vector:</p>
<pre class="r"><code>observed_sample &lt;- c(1, 0, 1, 1, 1, 0, 1, 0, 1) # 1 = water; 0 = land
W &lt;- sum(observed_sample) # Number of water samples
N &lt;- length(observed_sample) # Number of spins
W; N</code></pre>
<pre><code>## [1] 6</code></pre>
<pre><code>## [1] 9</code></pre>
<p>We just need to <em>count</em> all of the ways that this sample could have arose across all of the different possibilities of <span class="math inline">\(p\)</span>, and then estimate <span class="math inline">\(p\)</span> as that of where the sample was most likely to have occurred.</p>
<div id="basic-incorrect-solution-with-finite-possibilities" class="section level5">
<h5>Basic (incorrect) solution with finite possibilities</h5>
<p>We know that there are infinitely many possibilities for <span class="math inline">\(p\)</span>. Let’s first go through this assuming the globe is that of a 4-sided die, such that each side is land or water, implying the only possibilities are <span class="math inline">\(p \in (0,.25,.50,.75,1)\)</span>. For each possible value of <span class="math inline">\(p\)</span>, what is number of ways we could have observed our sequence of data? (thinking of the generative process, starting with <span class="math inline">\(N\)</span> and <span class="math inline">\(p\)</span>).</p>
<p>First of all, we can set our <em>possible</em> set of parameter values, and the number of “sides” of the globe this implies (i.e., we’re saying that there are only 4 sides and each one is either Water or Land, so we have a limited number of <span class="math inline">\(p\)</span> values that could occur).</p>
<pre class="r"><code># Set possible values for p
p &lt;- c(0, .25, .5, .75, 1)

# Number of sides of globe
sides &lt;- length(p) - 1</code></pre>
<p>For each of the 5 possible values of <span class="math inline">\(p\)</span>, how many combinations are there that produce our observed sequence of data?</p>
<pre class="r"><code># Number of ways to observe sample for each p (this is the count of the possible sequences of indicators)
ways &lt;- (sides*p)^W * (sides*(1-p))^(N-W)
ways</code></pre>
<pre><code>## [1]   0  27 512 729   0</code></pre>
<p>Now, of those possibilities, which was the most likely to occur?</p>
<pre class="r"><code># Posterior probability
posterior_prob &lt;- ways / sum(ways)
cbind(p, ways, posterior_prob)</code></pre>
<pre><code>##         p ways posterior_prob
## [1,] 0.00    0     0.00000000
## [2,] 0.25   27     0.02129338
## [3,] 0.50  512     0.40378549
## [4,] 0.75  729     0.57492114
## [5,] 1.00    0     0.00000000</code></pre>
<p>It looks like <span class="math inline">\(p=0.75\)</span> was the most likely value of those that are possible.</p>
<p>What is key to note about the posterior probabilities is that they are relative to the total across all values of <span class="math inline">\(p\)</span>. We simply found all of the raw counts associated with each <span class="math inline">\(p\)</span> and then normalized them by the total to get the posterior probability. But this process was <em>exactly</em> the same thing as finding the <em>likelihood</em> of the data:</p>
<p><span class="math display">\[Likelihood = \prod_{i=1}^NP(X=1|p)\]</span></p>
<p>where <span class="math inline">\(X\)</span> is the binary indicator from a single globe spin.</p>
<p>If we just look at all the <em>possible</em> sequences of indicators that could have occurred:</p>
<pre class="r"><code># Total possible sequences of indicators (each one could be a 1 or a 0)
total_possible_sequences &lt;- sides^N
total_possible_sequences</code></pre>
<pre><code>## [1] 262144</code></pre>
<p>And then divide our original combination counts by that, we’ll get <em>exactly</em> the likelihood of the data:</p>
<pre class="r"><code># Divide the total number of combinations we could have saw our sample, by the total number of possibilities
likelihood &lt;- ways / total_possible_sequences
likelihood</code></pre>
<pre><code>## [1] 0.0000000000 0.0001029968 0.0019531250 0.0027809143 0.0000000000</code></pre>
<p>However, as stated above, this will <em>not</em> change the resulting posterior distribution because the number we divided by was just a normalizing constant:</p>
<pre class="r"><code>likelihood / sum(likelihood)</code></pre>
<pre><code>## [1] 0.00000000 0.02129338 0.40378549 0.57492114 0.00000000</code></pre>
<p>So, we could also think of this problem in a different light (although it’s the SAME) and get the same result:</p>
<ol style="list-style-type: decimal">
<li>We could think of each observed value as an (unfair) coin flip (according to the value of <span class="math inline">\(p\)</span>) and calculate the likelihood of the sequence of flips (which is actually what we already did, but this is more of the “traditional” way to think about it):</li>
</ol>
<pre class="r"><code># Likelihood of sequence of observed sample
likelihood2 &lt;- p^W * (1-p)^(N-W)
likelihood</code></pre>
<pre><code>## [1] 0.0000000000 0.0001029968 0.0019531250 0.0027809143 0.0000000000</code></pre>
<pre class="r"><code># Compute posterior
likelihood2 / sum(likelihood2) # Same as before</code></pre>
<pre><code>## [1] 0.00000000 0.02129338 0.40378549 0.57492114 0.00000000</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>We could also think of this as finding the likelihood of observing the <em>total</em> number of water spins since each flip is <em>independent</em>. This is also the same as before, except we’re accounting for all of the combinations to observe the total number of water flips, not just the particular sequence:</li>
</ol>
<pre class="r"><code># Make the normalizing constant
normalizing_constant &lt;- factorial(N) / (factorial(W)*factorial(N-W))

# Multiply the likelihood by the normalizing constant by the likelihood to get the true probability of the observed sample for each value of p
probability &lt;- normalizing_constant * likelihood
probability</code></pre>
<pre><code>## [1] 0.000000000 0.008651733 0.164062500 0.233596802 0.000000000</code></pre>
<pre class="r"><code># Compute the posterior
probability / sum(probability)</code></pre>
<pre><code>## [1] 0.00000000 0.02129338 0.40378549 0.57492114 0.00000000</code></pre>
<p>Note that the normalizing constant had no effect on the posterior, but it did calculate the correct probabilities of the observed sample. In fact, this was just a Binomial distribution:</p>
<pre class="r"><code># What is the probability of observing W water values in a sample of N globe spins for each p?
dbinom(x = W, size = N, prob = p)</code></pre>
<pre><code>## [1] 0.000000000 0.008651733 0.164062500 0.233596802 0.000000000</code></pre>
<p>That is, the probability distribution for the number of water samples is:</p>
<p><span class="math display">\[W|p \sim Binomial(N, p)\]</span>
<span class="math display">\[P(W|p) = \frac{N!}{W!(N-W)!}p^W(1-p)^{(N-W)}\]</span></p>
<p>So what is going on here? We are after the distribution of probability weights associated with each possible value of <span class="math inline">\(p\)</span> (which is what the posterior distribution is). In mathematical notation, we’re just applying Bayes’ formula:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
P(p|sample)
&amp; = \frac{P(p)P(sample|p)}{P(sample)} \\
&amp; = \frac{P(p)P(W|p)}{P(W)} \\
&amp; = \frac{P(p)P(W|p)}{P(W \cap p = 0) + P(W \cap p = .25) + ... + P(W \cap p = 1)} \\
&amp; = \frac{P(p)P(W|p)}{P(p=0)P(W|p=0) + ... + P(p=1)P(W|p=1)} \\
\end{split}
\end{equation}
\]</span>
Each value of <span class="math inline">\(p\)</span> is equally-likely to occur (<em>uniform prior</em>), so we can factor out that term:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
\text{(from previous)}
&amp; = \frac{P(W|p)}{P(W|p=0) + ... + P(W|p=1)} \\
(binomials) &amp;= \frac{choose(N,W)p^W(1-p)^{(N-W)}}{choose(N,W)0^W(1-0)^{(N-W)} + ... + choose(N,W)1^W(1-1)^{(N-W)}} \\
&amp; = \frac{p^W(1-p)^{(N-W)}}{0^W(1-0)^{(N-W)} + ... + 1^W(1-1)^{(N-W)}} \\
&amp; = \frac{p^W(1-p)^{(N-W)}}{\text{Normalizing constant}} \\
\end{split}
\end{equation}
\]</span>
As you can see, the combination term also factors out, and the basic structure we’re left with is the <em>likelihood</em> piece that was found in <em>all three (3)</em> variations above: <span class="math inline">\(p^W(1-p)^{(N-W)}\)</span>. So when computing the posterior probability, they are relative to only terms dependent on the parameter of interest, so doesn’t matter if we use the counts, base likelihood, or the probability distribution–they are all the SAME. The counting process and the “forking path” approach is simply a means to breakdown the process of what’s happening behind the scenes in the math, so instead of just saying “do this integral” or “compute this product of the likelihood”, you’re picking apart each step of that process to gain intuition about what is happening. I’d imagine this is exactly the point of the Owl reference in the prior lecture.</p>
</div>
<div id="updating-the-posterior" class="section level5">
<h5>Updating the posterior</h5>
<p>So when we talk “Bayesian updates” or updating the posterior distribution, what does this mean? Since the point of it is to be able to update a model with new information, my gut used to tell me that we were somehow adding our current knowledge about the parameter into the new <em>prior</em> distribution, and then updating the new posterior with an updated prior and only using new data in the likelihood. While in a way this might be the right way to think about it (i.e., if I have a posterior right now, isn’t that the most current knowledge about the parameter, so if I want to collect more data, wouldn’t I want to use knowledge up to this point as the prior instead of reverting back to the original prior and just adding more data to the collective sample?), in these examples we were doing something different: we’re just seeing how the posterior changes as more data is added to the sample (i.e., observed sequence of data points).</p>
<p>Let’s start with just focusing on the basic example (i.e., 4 sided-globe) for now. We just need to loop through the observed sample, and calculate the posterior probabilities for each value of <span class="math inline">\(p\)</span> as a new observation comes in:</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
## ✔ ggplot2 3.4.0      ✔ purrr   1.0.0 
## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
## ✔ tidyr   1.2.1      ✔ stringr 1.4.1 
## ✔ readr   2.1.3      ✔ forcats 0.5.2 
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code># Set the prior probability (uniform over the possibly choices)
prior &lt;- rep(1 / length(p), length(p))

# Set the current posterior as the prior (before any data collected)
last_posterior &lt;- prior

# Make result set
results &lt;- tibble()

# For each value in the observed sample 
for(i in 1:N) {
  
  # 1. Get the sub-sample
  sub_sample &lt;- observed_sample[1:i]
  
  # 2. Compute metrics (the number of water samples, and the total number of spins)
  W_temp &lt;- sum(sub_sample)
  N_temp &lt;- length(sub_sample)
  
  # 3. Compute the likelihood for each p
  temp_likelihood &lt;- p^W_temp * (1 - p)^(N_temp - W_temp)
  
  # 4. Posterior
  temp_posterior &lt;- temp_likelihood / sum(temp_likelihood)
  
  # 5. Add to results
  results &lt;-
    results %&gt;%
    bind_rows(
      tibble(
        sample = i,
        sequence = paste(sub_sample, collapse = &quot;,&quot;),
        p,
        likelihood = temp_likelihood,
        posterior = temp_posterior,
        last_posterior
      )
    )
  
  # Set the new last posterior
  last_posterior &lt;- temp_posterior

}
results</code></pre>
<pre><code>## # A tibble: 45 × 6
##    sample sequence     p likelihood posterior last_posterior
##     &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;
##  1      1 1         0         0           0              0.2
##  2      1 1         0.25      0.25        0.1            0.2
##  3      1 1         0.5       0.5         0.2            0.2
##  4      1 1         0.75      0.75        0.3            0.2
##  5      1 1         1         1           0.4            0.2
##  6      2 1,0       0         0           0              0  
##  7      2 1,0       0.25      0.188       0.3            0.1
##  8      2 1,0       0.5       0.25        0.4            0.2
##  9      2 1,0       0.75      0.188       0.3            0.3
## 10      2 1,0       1         0           0              0.4
## # … with 35 more rows</code></pre>
</div>
</div>
</div>
</div>
<div id="homework" class="section level2">
<h2>Homework</h2>
</div>
<div id="notes-1" class="section level2">
<h2>Notes</h2>
<p><strong>Goal: Estimate the percent of the globe that is covered in water</strong></p>
<ul>
<li>Think of spinning the globe and stopping on a point and repeating many times</li>
<li>How do we use that collection of points to come up with an estimate? That’s the goal of today’s lecture</li>
<li>First thought is just indicate each time whether land or water appear as the point; however, how does the shape of the globe impact the likelihood that I will come up with land or water on a “random” toss? Has to do with sampling strategy</li>
</ul>
<ol style="list-style-type: decimal">
<li>Define a generative model</li>
</ol>
<ul>
<li>Think conceptually about scientifically how the sample was produced (how do variables influence one another)</li>
<li>Variables: Things we <em>want</em> to observe/estimate or things we actually do observe</li>
</ul>
<p><span class="math display">\[\bf{p} = \text{proportion of water}\hskip.5inW=\text{water observations}\]</span>
<span class="math display">\[N = \text{number of tosses}\hskip.5inL=\text{land observations}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Define a specific estimand</li>
</ol>
<p>Were interested in the true proportion of water <strong>p</strong></p>
<ol start="3" style="list-style-type: decimal">
<li>Design a statistical way to produce estimate</li>
</ol>
<ul>
<li>How are these related to each other?
<ul>
<li>N influences W and L (the more tosses leads to change on other variables)</li>
<li>p also influences W and L (i.e., the true proportion dictates the number of water observations and land observations)</li>
<li>The DAG shows relationships, but not what the relationships <em>are</em>. We can say <span class="math inline">\(W,L=f(p,N)\)</span>; what is <span class="math inline">\(f\)</span>?</li>
</ul></li>
<li>Assume a model (e.g., <span class="math inline">\(p\)</span> = .25, then count likely the sample was under that model, do that for all possible models)</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Test (3) using (1)</li>
</ol>
<pre class="r"><code>sim_globe &lt;-
  function(p = .7, N = 9) {
    sample(
      c(&quot;W&quot;,&quot;L&quot;), # Possible observations
      size = N, # Number of tosses
      prob = c(p, 1-p), # The probability of each possible observation
      replace = TRUE)
  }
sim_globe()</code></pre>
<pre><code>## [1] &quot;L&quot; &quot;W&quot; &quot;W&quot; &quot;W&quot; &quot;W&quot; &quot;L&quot; &quot;W&quot; &quot;W&quot; &quot;L&quot;</code></pre>
<pre class="r"><code>replicate(sim_globe(p =.5, N=9), n=10)</code></pre>
<pre><code>##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##  [1,] &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  
##  [2,] &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  
##  [3,] &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  
##  [4,] &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  
##  [5,] &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  
##  [6,] &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  
##  [7,] &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  
##  [8,] &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;  &quot;L&quot;  
##  [9,] &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  &quot;L&quot;  &quot;W&quot;  &quot;W&quot;  &quot;W&quot;  &quot;L&quot;  &quot;L&quot;</code></pre>
<ul>
<li>Test the intent of the code first</li>
<li>If our procedure doesn’t work when <em>we know</em> the answer, it certainly won’t when we <em>don’t</em> know the answer</li>
</ul>
<p>Infinite sample:</p>
<p><span class="math display">\[p^W(1-p)^L\]</span> Posterior probability:</p>
<p><span class="math display">\[p = \frac{(W+L+1)!}{W!L!}p^W(1-p)^L\]</span></p>
<ul>
<li>This is a <em>Beta</em> distribution, and the likelihood was a <em>Binomial</em>.</li>
<li>The minimum sample size for Bayesian analysis is 1.</li>
<li>The shape of the posterior distribution embodies the sample size</li>
<li>No point estimate, we work with the entire posterior distribution</li>
<li>The distribution <em>is</em> the estimate; always use the entire distribution, never a single point</li>
<li>The fact that an arbitrary interval contains an arbitrary value is not meaningful</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Analyze sample, summarize</li>
</ol>
<ul>
<li>Implications depend on entire posterior</li>
<li>Average over the uncertainty of the posterior</li>
<li>What can we do with the posterior distribution?
<ul>
<li>We can take samples from it, and then do calculations with the samples</li>
</ul></li>
<li>Posterior Prediction
<ul>
<li>Given what we’ve learned, what would happen if we took more samples?</li>
<li>Sampling distribution (predictive distribution) of draws represents the likelihood of each outcome in a new experiment for a particular value</li>
<li>The <em>posterior predictive</em> distribution then represents the entire distribution of the statistic of interest, and contains all the uncertainty around that estimate (analogous to the sampling distribution of a statistic (e.g., mean) in the frequentist paradigm, except this is completely model-driven by the posterior instead of based on asymptotics in the frequentist approach)</li>
<li>Sampling turns calculus into a data summary problem; this is important when models get complex and numerically intractable to compute by hand</li>
</ul></li>
<li>This generative, Bayesian framework is the optimal approach for causal estimation <em>if your model is correct</em>.</li>
<li>It honestly carries out the assumptions we put into it, using logical implications</li>
<li>Quantitative framework/asset that activates our qualitative knowledge as scientists, subject matter experts, etc. Let’s the subjective and objective work together. Subjectivity is expertise.</li>
</ul>
<p><strong>Misclassification</strong></p>
<ul>
<li><p>Use circles around variable in DAG to represent unobserved vs. observed variables</p></li>
<li><p>Imagine the true number of water samples (W) are unobserved (e.g., measurement error, data error, etc.)</p></li>
<li><p>We observe a <em>contaminated</em> W (called W*) that is the <em>misclassified</em> sample</p></li>
<li><p>W* is caused by the <em>measurement process</em> M. We can get get back to the correct posterior distribution for p if we use M through W*.</p></li>
<li><p>The posterior is honest about the uncertaintly induced by the misclassification process</p></li>
<li><p>When there is measurement error, model it instead of ignoring it (same for missing data, compliance, inclusion)</p></li>
<li><p><em>Key point: Samples do not need to be representative of population to provide good estimates, since we can correct them through our causal diagram (modeling the source, sampling process, etc.)</em></p></li>
<li><p>This concept may also arise if, for example, the globe was not spun equally likely for every point to be selected.</p></li>
</ul>
</div>
</div>
<div id="lecture3" class="section level1">
<h1>3. Basic Regression</h1>
<table>
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td>3</td>
<td>4</td>
<td>1/13/2023</td>
<td></td>
</tr>
</tbody>
</table>
<div id="summary-2" class="section level2">
<h2>Summary</h2>
</div>
<div id="notes-2" class="section level2">
<h2>Notes</h2>
</div>
</div>
<div id="lecture4" class="section level1">
<h1>4. Not-so-basic Regression</h1>
<table>
<thead>
<tr class="header">
<th>Week #</th>
<th>Lecture #</th>
<th>Chapter(s)</th>
<th>Week End</th>
<th>Notes Taken</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2</td>
<td>4</td>
<td>4</td>
<td>1/13/2023</td>
<td></td>
</tr>
</tbody>
</table>
<div id="summary-3" class="section level2">
<h2>Summary</h2>
</div>
<div id="notes-3" class="section level2">
<h2>Notes</h2>
</div>
</div>
