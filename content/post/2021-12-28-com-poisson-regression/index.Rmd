---
title: Exploring COM Poisson Regression
subtitle: A method for underdispersed count data
author: Alex Zajichek
date: '2021-12-28'
slug: com-poisson-regression
categories: []
tags: []
summary: ''
authors: []
lastmod: '2021-12-28T06:53:32-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

$$\Large \it \text {In Progress}$$
A few years ago I encountered an interesting count distribution at work during a modeling project. The goal was to model the number of [suture anchors](https://www.shoulderdoc.co.uk/article/538) used in rotator-cuff tendon tears, and how that was influenced by tear characteristics and surgeon preference. My instinct would typically be to fit a [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution) model, but the target took on relatively small values and was also non-zero, so I had to do some digging for an alternative approach. I came across a method called Conway-Maxwell (COM) Poisson regression, which not only allowed for _overdispersion_ (i.e., the population variance is greater than its mean), but also _underdispersion_. It hit me that I had never come across methodology for the latter and it seemed to align with my problem, so I was intrigued (FD: I heard of COM-Poisson prior to that, albeit knew nothing about it, when one of my super smart graduate school buddies was doing research on it, so that's also why it stuck). 

Long story short, we didn't end up using the COM-Poisson model for the [anchor project](https://www.jshoulderelbow.org/article/S1058-2746(18)30555-X/fulltext) `r emo::ji("grin")`, and instead went in favor of [Zero-Truncated Poisson regression](https://stats.oarc.ucla.edu/r/dae/zero-truncated-poisson/). Nevertheless I thought it was an awesome method that warranted further exploration and later did a [talk](NonTraditionalCountRegression.pdf) on it. That was a few years ago--so this article is intended to be a reworking of that talk to relearn it for myself, but also to get the word out about this awesome method!

# A review of Poisson regression

I really like making up examples, so lets start with that:

Suppose hospital administrators are interested in emergency department (ED) utilization and have asked a few questions:

1. How many patients can we expect to see in a given day?
2. What is the likelihood that we see more than 40 patients in a single day?
3. Do we see more variation during the week versus weekend, or in the AM versus PM hours?

To expedite the process, we're given a pre-built dataset called `ed_volumes` containing the number of patients entering the ED each day over the past year.

```{r, echo = FALSE, message = FALSE}

# Load packages
require(tidyverse)

# Set a seed
set.seed(123)

### 1. Create simulated dataset

# Generating a random Poisson parameter
ed_true_mean <-
  runif(
    n = 1,
    min = 12.5,
    max = 25
  )

# Build the dataset
ed_volumes <-
  tibble(
    Date = rep(Sys.Date() - seq(1, 365, 1), 2),
    TimeOfDay = c(rep("AM", length(Date) / 2), rep("PM", length(Date) / 2)),
    Volume = 
      rpois(
        n = length(Date), 
        lambda = ifelse(weekdays(Date) %in% c("Saturday", "Sunday"), ed_true_mean - 5, ed_true_mean)
      )
  ) %>%
  arrange(
    desc(Date),
    TimeOfDay
  )

```

```{r}
# Load some packages
require(tidyverse)

# Check the dataset
print(ed_volumes, n = 5)

```

First, let's take a look at the distribution of total daily patient volume over the time period:

```{r}
ed_volumes %>%
  
  # For each date
  group_by(Date) %>%
  
  # Compute the total 
  summarise(
    Volume = sum(Volume),
    .groups = "drop"
  ) %>%
  
  # Make a plot
  ggplot() +
  geom_histogram(
    aes(
      x = Volume
    ),
    fill = "gray",
    color = "black",
    bins = 30
  ) +
  geom_vline(
    aes(
      xintercept = mean(Volume)
    ),
    color = "#b84f48"
  ) +
  geom_text(
    aes(
      x = mean(Volume) + 1,
      y = 41,
      label = str_c("Avg: ", round(mean(Volume), 1), " patients")
    ),
    color = "#b84f48",
    hjust = -.15
  ) +
  xlab("Daily Patient Volume") +
  ylab("Frequency") +
  theme(
    legend.position = "none",
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = "gray")
  )
```

There were `r round(mean(with(ed_volumes, tapply(Volume, Date, sum))), 1)` patients per day on average, ranging from `r min(range(with(ed_volumes, tapply(Volume, Date, sum))))` to `r max(range(with(ed_volumes, tapply(Volume, Date, sum))))`. Knowing that this is a count distribution, we think to use a Poisson model to provide our estimates for the first two questions. Let's remind ourselves the specifics of a Poisson random variable:

If the probability mass function (PMF) for a non-negative, integer-valued $Y$ is:

$$P(Y = y|\lambda) = \frac{e^{-\lambda}\lambda^y}{y!}$$
then $Y$ is distributed as a Poisson random variable, and has the following property:

$$E[Y] = \lambda$$
It turns out that the maximum likelihood estimator (MLE) for $\lambda$ is the [sample average](https://www.statlect.com/fundamentals-of-statistics/Poisson-distribution-maximum-likelihood). Remembering this, _we provide the estimate for the first question to be `r ceiling(mean(with(ed_volumes, tapply(Volume, Date, sum))))` patients. (rounding up)_

```{r}
lambda_hat <- mean(with(ed_volumes, tapply(Volume, Date, sum)))
lambda_hat
```

We also know that once we have an estimate for $\lambda$ that we can compute probabilities by plugging it into the PMF:

$$P(Y>40) = 1 - P(Y\leq40) = 1 - \sum_{y=0}^{40} \frac{e^{-\lambda}\lambda^y}{y!}$$
```{r}
y <- 0:40
p <- exp(-lambda_hat) * lambda_hat^y / factorial(y)
question2 <- 1 - sum(p)
question2

# Alternative approach
1- ppois(40, lambda_hat)
```

_We estimate that there is a `r round(question2*100,1)`% chance that we will see more than 40 patients in the ED in a single day_--done with the first two questions! 

`r emo::ji("scared")`

Unfortunately, we missed a crucial assumption about the Poisson distribution that we didn't account for:

$$E[Y] = Var[Y]$$
The estimates we provided assumed that the mean and variance of our underlying distribution were equal. The sample variance was `r round(var(with(ed_volumes, tapply(Volume, Date, sum))), 1)` which is considerably larger than the mean of `r round(mean(with(ed_volumes, tapply(Volume, Date, sum))), 1)`. Here is what an actual Poisson distribution looks like (blue curve) with $\lambda$ = `r round(mean(with(ed_volumes, tapply(Volume, Date, sum))), 1)` (our sample average) in comparison with the observed data (bars):

```{r}

ed_volumes %>%
  
  # Compute the total for each date
  group_by(Date) %>%
  summarise(
    Volume = sum(Volume),
    .groups = "drop"
  ) %>%
  
  # Count the occurrences of each daily volume
  group_by(Volume) %>%
  summarise(
    N = n(),
    .groups = "drop"
  ) %>%
  
  # Compute the observed and theoretical relative frequencies
  mutate(
    Observed = N / sum(N),
    Theoretical = dpois(Volume, lambda = lambda_hat)
  ) %>%
  
  # Remove raw count
  select(-N) %>% 
  
  # Make a plot
  ggplot(
    aes(
      x = Volume
    )
  ) +
  geom_col(
    aes(
      y = Observed
    ),
    fill = "gray",
    color = "black"
  ) +
  geom_area(
    aes(
      y = Theoretical
    ),
    alpha = .25,
    color = "black",
    fill = "blue"
  ) +
  geom_vline(
    aes(
      xintercept = lambda_hat
    ),
    color = "#b84f48"
  ) +
  xlab("Daily Patient Volume") +
  ylab("Relative Frequency (%)") +
  theme(
    legend.title = element_blank(),
    legend.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = "gray")
  ) +
  scale_y_continuous(labels = scales::percent)

```

The tails of the observed sample are heavier than a Poisson would be with the same mean. Therefore, the estimates we provided for questions one and two are probably not very accurate. Let's take a different approach: _answer question three first, and then work our way back to the other two._ 

As a reminder, we want to assess whether there is more variation in patient volume during the week versus weekend, or in the AM versus PM hours. To get this comparison, we need a way to simultaneously estimate the effect of each of these factors on the patient volume: enter Poisson regression. 

## Model formulation

Just like other [generalized linear models](https://en.wikipedia.org/wiki/Generalized_linear_model) (GLM), a Poisson regression model estimates the population average (the same average as described above!), _but conditioned on a set of covariates_. 

More formally, for a given set of covariates $x_1, x_2, .., x_p$, we assume the following functional form:

$$log(\lambda_i) = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2}+...+\beta_px_{ip} = X_i\beta$$
This _log-linear_ model then allows us to estimate the average number of events (i.e., the Poisson parameter $\lambda$) for a given arrangement of covariate values. We also get informative interpretation of the individual effects of each covariate. For our example, the model looks like this:

$$log(\lambda_i) = \beta_0 + \beta_{weekend}x_{i_{weekend}} + \beta_{PM}x_{i_{PM}}$$
where $\lambda_i$ is the expected patient volume, $x_{i_{weekend}} = 1$ if it is Saturday or Sunday, and $x_{i_{PM}} = 1$ if it is PM hours (and they are 0 otherwise). We can take the following steps to estimate the parameters:

1. Plug the regression formula into the Poisson PMF

$$
\begin{equation} 
\begin{split}
P(Y_i = y_i|\lambda_i) & = \frac{e^{-\lambda_i}\lambda_i^{y_i}}{y_i!} \\
& = \frac{e^{-e^{X_i\beta}}{(e^{X_i\beta})}^{y_i}}{y_i!} \\
\end{split}
\end{equation}
$$
where $Y_i$ is the patient volume.

2. Compute the likelihood function

$$L(\lambda_i) = \prod_{i=1}^N \frac{e^{-e^{X_i\beta}}{(e^{X_i\beta})}^{y_i}}{y_i!} \\$$
where $N$ is the total sample size.

3. Derive the MLE's

$$\hat{\beta} = max_{\beta} L(\lambda_i)\\$$
where $\hat{\beta}$ is the set of estimated parameters computed from maximizing the likelihood function. Once we have these, we can plug them into the regression formula, and away we go! Luckily, our software will compute these for us--all we need to do is supply the data.

```{r}
# Fit a generalized linear model
model <-
  glm(
    formula = Volume ~ Weekend + PM, # Specify the model form
    data = # Supply the data
      ed_volumes %>% 
      mutate(
        Weekend = weekdays(Date) %in% c("Saturday", "Sunday"),
        PM = TimeOfDay == "PM"
      ),
    family = "poisson" # Indicate the likelihood
  )

# Show the model summary
summary(model)

```




* COM Poisson distribution, generalizes Poisson
* Modeling different dispersions by groups
* Zero inflated COM Poisson
* Number of re-admissions in 30 day period

```{r}
# Load required packages
require(COMPoissonReg)
```

# Code Appendix
```{r, eval = FALSE}

# Load packages
require(tidyverse)

# Set a seed
set.seed(123)

### 1. Create simulated dataset

# Generating a random Poisson parameter
ed_true_mean <-
  runif(
    n = 1,
    min = 12.5,
    max = 25
  )

# Build the dataset
ed_volumes <-
  tibble(
    Date = rep(Sys.Date() - seq(1, 365, 1), 2),
    TimeOfDay = c(rep("AM", length(Date) / 2), rep("PM", length(Date) / 2)),
    Volume = 
      rpois(
        n = length(Date), 
        lambda = ifelse(weekdays(Date) %in% c("Saturday", "Sunday"), ed_true_mean - 5, ed_true_mean)
      )
  ) %>%
  arrange(
    desc(Date),
    TimeOfDay
  )

```


