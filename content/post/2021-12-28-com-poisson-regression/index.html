---
title: Exploring COM Poisson regression
subtitle: A method for underdispersed count data
author: Alex Zajichek
date: '2021-12-28'
slug: com-poisson-regression
categories: []
tags: ['statistics', 'rstats', 'healthcare']
summary: ''
authors: []
lastmod: '2021-12-28T06:53:32-06:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>
<script src="{{< blogdown/postref >}}index_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index_files/lightable/lightable.css" rel="stylesheet" />


<p>A few years ago I encountered an interesting count distribution during a modeling project. The goal was to model the number of <a href="https://www.shoulderdoc.co.uk/article/538">suture anchors</a> used in rotator-cuff tendon tears, and how that was influenced by tear characteristics and surgeon preference. My instinct was to fit a <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson</a> model, but the target took on relatively small values and was also non-zero, so I had to do some digging for an alternative approach. I came across a method called Conway-Maxwell (COM) Poisson regression, which not only allowed for <em>overdispersion</em> (i.e., the population variance is greater than its mean), but also <em>underdispersion</em>. It hit me that I had never come across methodology for the latter and it seemed to align with my problem, so I was intrigued (Full Disclosure: I heard of COM-Poisson prior to that, albeit knew nothing about it, when one of my super smart graduate school buddies was doing research on it, so that‚Äôs also why it stuck).</p>
<p>Long story short, we didn‚Äôt end up using the COM-Poisson model for the <a href="https://www.jshoulderelbow.org/article/S1058-2746(18)30555-X/fulltext">anchor project</a> üòÅ, and instead went in favor of <a href="https://stats.oarc.ucla.edu/r/dae/zero-truncated-poisson/">Zero-Truncated Poisson regression</a>. Nevertheless I thought it was an awesome method that warranted further exploration and later did a <a href="NonTraditionalCountRegression.pdf">talk</a> on it. That was a few years ago‚Äìso this article is intended to be a reworking of that talk to relearn it for myself, but also to get the word out about this awesome method! All code is written in R.</p>
<div id="table-of-contents" class="section level1">
<h1>Table Of Contents</h1>
<ul>
<li><a href="#reviewofpoisson">A Review of Poisson Regression</a>
<ul>
<li><a href="#poissondistribution">The Poisson Distribution</a></li>
<li><a href="#modelformulation">Model Formulation</a></li>
</ul></li>
<li><a href="#compoisson">Conway-Maxwell (COM) Poisson Regression</a>
<ul>
<li><a href="#compoissondistribution">The COM-Poisson Distribution</a></li>
<li><a href="#compoissonregressionmodel">The Regression Model</a></li>
<li><a href="#compoissonlrt">Testing for Violations of Equidispersion</a></li>
<li><a href="#stratifieddispersion">Stratified Dispersion</a></li>
<li><a href="#comfittedvalues">Generating Fitted Values</a></li>
<li><a href="#compowersim">Simulation: Power of Equidispersion Test</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#codeappendix">Code Appendix</a></li>
</ul>
</div>
<div id="reviewofpoisson" class="section level1">
<h1>A Review of Poisson Regression</h1>
<p>I really like making up examples, so lets start with that:</p>
<p>Suppose hospital administrators are interested in emergency department (ED) utilization and have asked a few questions:</p>
<ol style="list-style-type: decimal">
<li>How many patients can we expect to see in a given day?</li>
<li>What is the likelihood that we see more than 40 patients in a single day?</li>
<li>Do we see more variation during the week versus weekend, or in the AM versus PM hours?</li>
</ol>
<p>To expedite the process, we‚Äôre given a pre-built dataset called <code>ed_volumes</code> containing the number of patients entering the ED each (half) day over the past calendar year.</p>
<pre class="r"><code># Load some packages
require(tidyverse)

# Check the dataset
print(ed_volumes, n = 5)</code></pre>
<pre><code>## # A tibble: 730 √ó 3
##   Date       TimeOfDay Volume
##   &lt;date&gt;     &lt;chr&gt;      &lt;int&gt;
## 1 2021-12-31 AM            19
## 2 2021-12-31 PM            12
## 3 2021-12-30 AM            20
## 4 2021-12-30 PM            20
## 5 2021-12-29 AM             9
## # ‚Ä¶ with 725 more rows</code></pre>
<p>First, let‚Äôs take a look at the distribution of total daily patient volume over the time period:</p>
<pre class="r"><code>ed_volumes %&gt;%
  
  # For each date
  group_by(Date) %&gt;%
  
  # Compute the total 
  summarise(
    Volume = sum(Volume),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Make a plot
  ggplot() +
  geom_histogram(
    aes(
      x = Volume
    ),
    fill = &quot;gray&quot;,
    color = &quot;black&quot;,
    bins = 30
  ) +
  geom_vline(
    aes(
      xintercept = mean(Volume)
    ),
    color = &quot;#b84f48&quot;
  ) +
  geom_text(
    aes(
      x = mean(Volume) + 1,
      y = 41,
      label = str_c(&quot;Avg: &quot;, round(mean(Volume), 1), &quot; patients&quot;)
    ),
    color = &quot;#b84f48&quot;,
    hjust = -.15
  ) +
  xlab(&quot;Daily Patient Volume&quot;) +
  ylab(&quot;Frequency&quot;) +
  theme(
    legend.position = &quot;none&quot;,
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>There were 29.5 patients per day on average, ranging from 11 to 47. Knowing that this is a count distribution, we think to use a Poisson model to provide our estimates for the first two questions. Let‚Äôs remind ourselves of the specifics:</p>
<div id="poissondistribution" class="section level2">
<h2>The Poisson Distribution</h2>
<p>If the probability mass function (PMF) for a non-negative, integer-valued <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[P(Y = y|\lambda) = \frac{e^{-\lambda}\lambda^y}{y!}\]</span>
then <span class="math inline">\(Y\)</span> is distributed as a Poisson random variable, and has the following property:</p>
<p><span class="math display">\[E[Y] = \lambda\]</span>
It turns out that the maximum likelihood estimator (MLE) for <span class="math inline">\(\lambda\)</span> is the <a href="https://www.statlect.com/fundamentals-of-statistics/Poisson-distribution-maximum-likelihood">sample average</a>. Remembering this, <em>we provide the estimate for the first question to be 30 patients. (rounding up)</em></p>
<pre class="r"><code>lambda_hat &lt;- mean(with(ed_volumes, tapply(Volume, Date, sum)))
lambda_hat</code></pre>
<pre><code>## [1] 29.53699</code></pre>
<p>We also know that once we have an estimate for <span class="math inline">\(\lambda\)</span> that we can compute probabilities by plugging it into the PMF:</p>
<p><span class="math display">\[P(Y&gt;40) = 1 - P(Y\leq40) = 1 - \sum_{y=0}^{40} \frac{e^{-\lambda}\lambda^y}{y!}\]</span></p>
<pre class="r"><code>y &lt;- 0:40
p &lt;- exp(-lambda_hat) * lambda_hat^y / factorial(y)
question2 &lt;- 1 - sum(p)
question2</code></pre>
<pre><code>## [1] 0.02633629</code></pre>
<pre class="r"><code># Alternative approach
1- ppois(40, lambda_hat)</code></pre>
<pre><code>## [1] 0.02633629</code></pre>
<p><em>We estimate that there is a 2.6% chance that we will see more than 40 patients in the ED in a single day</em>‚Äìdone with the first two questions!</p>
<p>üò®</p>
<p>Unfortunately, we missed a crucial assumption about the Poisson distribution that we didn‚Äôt account for:</p>
<p><span class="math display">\[E[Y] = Var[Y]\]</span>
The estimates we provided assumed that the mean and variance of our underlying distribution were equal. The sample variance was 53.4 which is considerably larger than the mean of 29.5. Here is what an actual Poisson distribution looks like with <span class="math inline">\(\lambda\)</span> = 29.5 (our sample average) in comparison with the observed data:</p>
<pre class="r"><code>ed_volumes %&gt;%
  
  # Compute the total for each date
  group_by(Date) %&gt;%
  summarise(
    Volume = sum(Volume),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Count the occurrences of each daily volume
  group_by(Volume) %&gt;%
  summarise(
    N = n(),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Compute the observed and theoretical relative frequencies
  mutate(
    Observed = N / sum(N),
    Theoretical = dpois(Volume, lambda = lambda_hat)
  ) %&gt;%
  
  # Remove raw count
  select(-N) %&gt;% 
  
  # Make a plot
  ggplot(
    aes(
      x = Volume
    )
  ) +
  geom_col(
    aes(
      y = Observed,
      fill = &quot;Observed Data&quot;
    ),
    color = &quot;black&quot;
  ) +
  geom_area(
    aes(
      y = Theoretical,
      fill = &quot;Actual Poisson&quot;
    ),
    alpha = .25,
    color = &quot;black&quot;
  ) +
  geom_vline(
    aes(
      xintercept = lambda_hat
    ),
    color = &quot;#b84f48&quot;
  ) +
  xlab(&quot;Daily Patient Volume&quot;) +
  ylab(&quot;Relative Frequency (%)&quot;) +
  theme(
    legend.title = element_blank(),
    legend.text = element_text(size = 12),
    legend.position = &quot;top&quot;,
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(values = c(&quot;blue&quot;, &quot;gray&quot;))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The tails of the observed sample are heavier than a Poisson would be with the same mean. Therefore, the estimates we provided for questions 1 and 2 are probably not very accurate. Let‚Äôs take a different approach: <em>answer question 3 first, and then work our way back to the other two.</em></p>
<p>As a reminder, we want to assess whether there is more variation in patient volume during the week versus weekend, or in the AM versus PM hours. To get this comparison, we need a way to simultaneously estimate the effect of each of these factors on the patient volume: enter Poisson regression.</p>
</div>
<div id="modelformulation" class="section level2">
<h2>Model Formulation</h2>
<p>Just like other <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear models</a> (GLM), a Poisson regression model estimates the population average (the same average as described above!), <em>but conditioned on a set of covariates</em>.</p>
<p>More formally, for a given set of covariates <span class="math inline">\(x_1, x_2, .., x_p\)</span>, we assume the following functional form:</p>
<p><span class="math display">\[log(\lambda_i) = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2}+...+\beta_px_{ip} = X_i\beta\]</span>
This <em>log-linear</em> model allows us to estimate the mean number of events (i.e., the Poisson parameter <span class="math inline">\(\lambda\)</span>) for a given arrangement of covariate values. We also get informative interpretation of the individual effects of each covariate. For our example, the model looks like this:</p>
<p><span class="math display">\[log(\lambda_i) = \beta_0 + \beta_{weekend}x_{i_{weekend}} + \beta_{PM}x_{i_{PM}}\]</span>
where <span class="math inline">\(\lambda_i\)</span> is the expected (half-day) patient volume, <span class="math inline">\(x_{i_{weekend}} = 1\)</span> if it is Saturday or Sunday, and <span class="math inline">\(x_{i_{PM}} = 1\)</span> if it is PM hours (and they are 0 otherwise). We can take the following steps to estimate the <span class="math inline">\(\beta\)</span> parameters:</p>
<ol style="list-style-type: decimal">
<li>Plug the regression formula into the Poisson PMF</li>
</ol>
<p><span class="math display">\[
\begin{equation}
\begin{split}
P(Y_i = y_i|\lambda_i) &amp; = \frac{e^{-\lambda_i}\lambda_i^{y_i}}{y_i!} \\
&amp; = \frac{e^{-e^{X_i\beta}}{(e^{X_i\beta})}^{y_i}}{y_i!} \\
\end{split}
\end{equation}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Derive the likelihood function</li>
</ol>
<p><span class="math display">\[L(\lambda_i) = \prod_{i=1}^N \frac{e^{-e^{X_i\beta}}{(e^{X_i\beta})}^{y_i}}{y_i!} \\\]</span>
where <span class="math inline">\(N\)</span> is the total number of (half) days.</p>
<ol start="3" style="list-style-type: decimal">
<li>Compute the MLE‚Äôs</li>
</ol>
<p><span class="math display">\[\hat{\beta} = max_{\beta} L(\lambda_i)\\\]</span>
<span class="math inline">\(\hat{\beta}\)</span> is the set of estimated parameter values computed from maximizing the likelihood function. Once we have these, we can plug them into the regression formula, and away we go! Luckily, our software will compute these for us‚Äìall we need to do is supply the data.</p>
<pre class="r"><code># Fit a generalized linear model
model &lt;-
  glm(
    formula = Volume ~ Weekend + PM, # Specify the model form
    data = # Supply the data
      ed_volumes %&gt;% 
      mutate(
        Weekend = weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;),
        PM = TimeOfDay == &quot;PM&quot;
      ),
    family = &quot;poisson&quot; # Indicate the likelihood
  )

# Show the model summary
summary(model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Volume ~ Weekend + PM, family = &quot;poisson&quot;, data = ed_volumes %&gt;% 
##     mutate(Weekend = weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;), 
##         PM = TimeOfDay == &quot;PM&quot;))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.91321  -0.63033  -0.05093   0.66126   2.85749  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  2.78530    0.01455 191.483   &lt;2e-16 ***
## WeekendTRUE -0.41433    0.02371 -17.474   &lt;2e-16 ***
## PMTRUE       0.01762    0.01926   0.915     0.36    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1054.15  on 729  degrees of freedom
## Residual deviance:  723.55  on 727  degrees of freedom
## AIC: 4007.4
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The estimated model turns out to be:</p>
<p><span class="math display">\[log(\hat{\lambda_i}) = 2.7853 - 0.4143x_{i_{weekend}} + 0.0176x_{i_{PM}}\]</span>
where <span class="math inline">\(\hat{\lambda_i}\)</span> is the <em>estimated</em> average number of patients showing up to the ED on a given day of the week and time of day. Let‚Äôs take a look at the four possible estimated means:</p>
<pre class="r"><code># Make grid of possible values for each input
list(
  Weekend = c(TRUE, FALSE),
  PM = c(TRUE, FALSE)
) %&gt;%
  
  # Find cross-product
  cross_df() %&gt;%
  
  # Add some columns
  mutate(
    
    # Add predictions
    EstimatedVolume =
      predict(
        model, # Supply the model
        newdata = data.frame(Weekend, PM),
        type = &quot;response&quot; # Applies the inverse link to the linear predictor
      ),
    EstimatedVolume = round(EstimatedVolume, 2),
    
    # Clean up names
    Weekend = 
      case_when(
        Weekend ~ &quot;Sat, Sun&quot;,
        TRUE ~ &quot;Mon - Fri&quot;
      ) %&gt;%
      factor() %&gt;%
      fct_relevel(&quot;Mon - Fri&quot;),
    PM = 
      case_when(
        PM ~ &quot;PM&quot;,
        TRUE ~ &quot;AM&quot;
      ) %&gt;%
      factor() %&gt;%
      fct_relevel(
        &quot;AM&quot;
      )
  ) %&gt;%
  
  # Rearrange
  arrange(
    Weekend,
    PM
  ) %&gt;%
  
  # Send over the columns
  pivot_wider(
    names_from = PM,
    values_from = EstimatedVolume
  ) %&gt;%
  
  # Rename column
  rename(
    `Day of week` = Weekend
  ) %&gt;%
  
  # Make a kable
  knitr::kable(
    format = &quot;html&quot;,
    caption = &quot;Expected ED patient volume&quot;
  ) %&gt;%
  kableExtra::kable_styling(
    full_width = FALSE,
    bootstrap_options = c(&quot;striped&quot;, &quot;responsive&quot;)
  ) %&gt;%
  kableExtra::add_header_above(c(&quot;&quot;, &quot;Time of day&quot; = 2))</code></pre>
<table class="table table-striped table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-8">Table 1: </span>Expected ED patient volume
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Time of day
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Day of week
</th>
<th style="text-align:right;">
AM
</th>
<th style="text-align:right;">
PM
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Mon - Fri
</td>
<td style="text-align:right;">
16.20
</td>
<td style="text-align:right;">
16.49
</td>
</tr>
<tr>
<td style="text-align:left;">
Sat, Sun
</td>
<td style="text-align:right;">
10.71
</td>
<td style="text-align:right;">
10.90
</td>
</tr>
</tbody>
</table>
<p>Our model suggests that we see <span class="math inline">\(1 - e^{\beta_{weekend}} \approx\)</span> 33.9% <em>less</em> patient volume on the weekends compared to during the week, regardless if it is AM or PM hours‚Äìthis is reflected in our table estimates. We can also see that there is little difference in patient volume by the time of day, regardless of the day of the week.</p>
<p><strong><em>Answer to Question 3</em></strong></p>
<p>The evidence tells us that not only is the day of the week the <em>more important</em> factor, but the time of day does not appear to matter at all. This is clear when we stratify our observed sample distribution:</p>
<pre class="r"><code>ed_volumes %&gt;% 
  
  # Make the indicators
  mutate(
    Weekend = 
      case_when(
        weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;) ~ &quot;Sat, Sun&quot;,
        TRUE ~ &quot;Mon - Fri&quot;
      ) %&gt;%
      factor() %&gt;%
      fct_relevel(&quot;Mon - Fri&quot;),
    TimeOfDay = 
      TimeOfDay %&gt;%
      factor() %&gt;%
      fct_relevel(
        &quot;AM&quot;
      )
  ) %&gt;%
  
  # Make a plot
  ggplot() +
  geom_histogram(
    aes(
      x = Volume,
      fill = Weekend
    ),
    color = &quot;black&quot;,
    bins = 20,
    position = &quot;identity&quot;,
    alpha = .5
  ) + 
  facet_wrap(
    ~TimeOfDay,
    nrow = 2
  ) +
  xlab(&quot;Half-Day Patient Volume&quot;) +
  ylab(&quot;Frequency&quot;) +
  theme(
    legend.position = &quot;top&quot;,
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p><strong><em>Answers to Questions 1 &amp; 2</em></strong></p>
<p>So back to the first two questions. How can we use what we found for question 3 to inform us of these answers? Remember, we need to provide estimates regarding the <em>total</em> daily patient volume even though our model target was half-day patient volume. We have a couple options:</p>
<ol style="list-style-type: decimal">
<li>Since we have established that the time of day does not impact patient volume, we could fit a new model by first aggregating the target to reflect the total daily patient volume and then only add the weekday versus weekend factor as a covariate.</li>
</ol>
<pre class="r"><code># Fit a generalized linear model
model2 &lt;-
  glm(
    formula = Volume ~ Weekend, # Specify the model form
    data = 
      ed_volumes %&gt;% 
      
      # For each date
      group_by(Date) %&gt;%
      
      # Compute the total daily patient volume
      summarise(
        Volume = sum(Volume),
        .groups = &quot;drop&quot;
      ) %&gt;%
      
      # Make the indicator
      mutate(
        Weekend = weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;)
      ),
    family = &quot;poisson&quot; # Indicate the likelihood
  )

# Show the model summary
summary(model2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Volume ~ Weekend, family = &quot;poisson&quot;, data = ed_volumes %&gt;% 
##     group_by(Date) %&gt;% summarise(Volume = sum(Volume), .groups = &quot;drop&quot;) %&gt;% 
##     mutate(Weekend = weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;)))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.2441  -0.6594   0.0529   0.5682   2.6417  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  3.48729    0.01082  322.15   &lt;2e-16 ***
## WeekendTRUE -0.41433    0.02371  -17.47   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 681.97  on 364  degrees of freedom
## Residual deviance: 352.21  on 363  degrees of freedom
## AIC: 2252.7
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Notice the relative effect of the day of week factor remained consistent from the original model‚Äìthe intercept just changed to reflect the shifted distribution for the total patient volume. This approach works, but lets use the model we originally developed‚Ä¶</p>
<ol start="2" style="list-style-type: decimal">
<li>This option requires us to know a <a href="https://math.stackexchange.com/questions/221078/poisson-distribution-of-sum-of-two-random-independent-variables-x-y">property</a> of Poisson random variables. Specifically, if <em>X</em> and <em>Y</em> are two independent Poisson random variables and <span class="math inline">\(Z = X + Y\)</span>, then</li>
</ol>
<p><span class="math display">\[Z \sim Poisson(\lambda_X + \lambda_Y)\]</span>
where <span class="math inline">\(\lambda_X\)</span> and <span class="math inline">\(\lambda_Y\)</span> are the expected values (means) for <em>X</em> and <em>Y</em>, respectively. This is relevant to us because we need to aggregate our model estimates over the time of day in order to get estimates for the total daily volume. Specifically, if <span class="math inline">\(V\)</span> is the patient volume, then <span class="math inline">\(V_{Daily} = V_{AM} + V_{PM}\)</span> for a particular day of the week. We assume from our model specification above that <span class="math inline">\(V_{AM}\)</span> and <span class="math inline">\(V_{PM}\)</span> follow independent Poisson distributions. Thus, we get the following:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
\lambda_{Daily} &amp; = E[V_{Daily}] \\
&amp; = E[V_{AM} + V_{PM}] \\
&amp; = E[V_{AM}] + E[V_{PM}] \\
&amp; = \lambda_{AM} + \lambda_{PM} \\
&amp; = e^{\beta_0 + \beta_{weekend}x_{i_{weekend}}} + e^{\beta_0 + \beta_{weekend}x_{i_{weekend}} + \beta_{PM}} \\
&amp; = e^{\beta_0 + \beta_{weekend}x_{i_{weekend}}} (1 + e^{\beta_{PM}})\\
&amp; =
\begin{cases}
e^{\beta_0} (1 + e^{\beta_{PM}}) &amp; \text{if M-F} \\
e^{\beta_0 + \beta_{weekend}} (1 + e^{\beta_{PM}}) &amp; \text{if Sat, Sun} \\
\end{cases} \\
&amp; \approx
\begin{cases}
32.70 &amp; \text{if M-F} \\
21.61         &amp; \text{if Sat, Sun} \\
\end{cases}
\end{split}
\end{equation}
\]</span>
Simply put, to get estimates around the total daily volume, we summed the regression equation over the time of day variable. Note that this is exactly what we would have gotten by just taking the sample mean of total daily volume stratified by each day of week grouping:</p>
<pre class="r"><code>stratified_means &lt;-
  ed_volumes %&gt;% 
  
  # For each date
  group_by(Date) %&gt;%
  
  # Compute the total daily patient volume
  summarise(
    Volume = sum(Volume),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Make the indicator
  mutate(
    Weekend = 
      case_when(
        weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;) ~ &quot;Sat, Sun&quot;,
        TRUE ~ &quot;Mon - Fri&quot;
      ) %&gt;%
      factor() %&gt;%
      fct_relevel(&quot;Mon - Fri&quot;)
  ) %&gt;%
  
  # For each group
  group_by(Weekend) %&gt;%
  
  # Compute the mean
  summarise(
    Mean = mean(Volume),
    Variance = var(Volume),
    .groups = &quot;drop&quot;
  )

stratified_means %&gt;%
  
  # Make a kable
  knitr::kable(
    format = &quot;html&quot;,
    caption = &quot;Stratified Daily Sample Means and Variances&quot;
  ) %&gt;%
  kableExtra::kable_styling(
    full_width = FALSE,
    bootstrap_options = c(&quot;striped&quot;, &quot;responsive&quot;)
  ) </code></pre>
<table class="table table-striped table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-11">Table 2: </span>Stratified Daily Sample Means and Variances
</caption>
<thead>
<tr>
<th style="text-align:left;">
Weekend
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
Variance
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Mon - Fri
</td>
<td style="text-align:right;">
32.69732
</td>
<td style="text-align:right;">
31.93495
</td>
</tr>
<tr>
<td style="text-align:left;">
Sat, Sun
</td>
<td style="text-align:right;">
21.60577
</td>
<td style="text-align:right;">
19.40618
</td>
</tr>
</tbody>
</table>
<p>Notice also that the stratified sample <em>variances</em> align much more with our assumptions in using a Poisson distribution‚Äìthis was one of our <a href="#poissondistribution">problems earlier</a>, but it appears to be resolved! Now that we have weekday and weekend-specific Poisson distributions, we can confidently compute our final estimates for questions 1 and 2 the same way we did <a href="#poissondistribution">above</a>.</p>
<p>Table 2 already shows the answer to question 1: <em>we can expect to see 33 patients per day Monday-Friday, and 22 patients on Saturdays or Sundays.</em> To get the updated estimates for question 2, we just need to plug in the new means to the PDF and compute the cumulative probability:</p>
<pre class="r"><code>question2_updated &lt;-
  stratified_means %&gt;%
  
  # For each set, compute the cumulative probability
  cheese::stratiply(
    by = Weekend,
    f = ~1 - sum(exp(-.x$Mean) * .x$Mean^c(0:40) / factorial(c(0:40)))
  )
question2_updated</code></pre>
<pre><code>## $`Mon - Fri`
## [1] 0.08959949
## 
## $`Sat, Sun`
## [1] 0.0001298706</code></pre>
<p><em>We estimate that there is a 8.96% chance that we will see more than 40 patients on any given Monday-Friday, and a 0.01% chance that we will see that many patients on the weekend.</em></p>
<p>Okay we got a little carried away with that but hopefully you have an idea of how Poisson regression works.</p>
</div>
</div>
<div id="compoisson" class="section level1">
<h1>Conway-Maxwell (COM) Poisson Regression</h1>
<p>Now that we have a foundation for standard Poisson regression, we can dig into COM-Poisson! We will use the <a href="https://github.com/lotze/COMPoissonReg"><code>COMPoissonReg</code></a> package in R, which can be installed from CRAN with <code>install.packages("COMPoissonReg")</code>.</p>
<pre class="r"><code># Load the package
require(COMPoissonReg)</code></pre>
<pre><code>## Loading required package: COMPoissonReg</code></pre>
<pre><code>## Loading required package: Rcpp</code></pre>
<div id="compoissondistribution" class="section level2">
<h2>The COM-Poisson Distribution</h2>
<p>If the PMF for a non-negative, integer-valued <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[P(Y = y|\lambda, \nu) = \frac{\lambda^y}{y!^{\nu}Z(\lambda, \nu)}\]</span>
where <span class="math inline">\(\lambda, \nu &gt; 0\)</span>, and</p>
<p><span class="math display">\[Z(\lambda, \nu) = \sum_{k=0}^{\infty}\frac{\lambda^k}{k!^{\nu}}\]</span>
then <span class="math inline">\(Y\)</span> is distributed as a COM-Poisson random variable.</p>
<p>That‚Äôs kind of a mouthful, but we can see some similarities in its form to the <a href="#poissondistribution">Poisson PDF</a>. In fact, if you‚Äôre really math-savvy (which I‚Äôm not, I had to look this up), you‚Äôll notice that the function <span class="math inline">\(Z\)</span> is a <em><a href="https://en.wikipedia.org/wiki/Power_series">power series</a></em>. When we set <span class="math inline">\(\nu = 1\)</span>, then</p>
<p><span class="math display">\[Z(\lambda, \nu = 1) = \sum_{k=0}^{\infty}\frac{\lambda^k}{k!} = e^\lambda\]</span>
Plugging that result back into the full PMF, it turns out to be <em>exactly</em> the same as a Poisson distribution. This tells us that <strong><em>the Poisson distribution is a special case of the COM-Poisson</em></strong>. In the other words, the COM-Poisson is a generalization of the Poisson distribution, so we‚Äôll expect it do everything that the latter can‚Äìplus more.</p>
<div id="dispersion-parameter" class="section level3">
<h3>Dispersion Parameter</h3>
<p>An important feature of the COM-Poisson PDF is the parameter <span class="math inline">\(\nu\)</span>, which determines its <em>dispersion</em> (i.e., how variable it is relative to its mean). In the standard Poisson distribution, the mean and variance are always the same, by definition. The <span class="math inline">\(\nu\)</span> parameter allows us to relax that restriction in cases where it does not apply (or we don‚Äôt want to force it to). The following table describes the properties when it is above, below, and equal to 1:</p>
<table>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Implies</th>
<th>Described As</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\nu=1\)</span></td>
<td><span class="math inline">\(E[Y] = Var[Y]\)</span></td>
<td>Equidispersed</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\nu&lt;1\)</span></td>
<td><span class="math inline">\(E[Y] &lt; Var[Y]\)</span></td>
<td>Overdispersed</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\nu&gt;1\)</span></td>
<td><span class="math inline">\(E[Y] &gt; Var[Y]\)</span></td>
<td>Underdispersed</td>
</tr>
</tbody>
</table>
</div>
<div id="compoissonmeanapprox" class="section level3">
<h3>Mean and Variance</h3>
<p>Unfortunately, there is <a href="https://faculty.georgetown.edu/kfs7/MY%20PUBLICATIONS/COMPoissonModelForCountDataWithDiscussion.pdf">no closed form solution</a> for the mean and variance of a COM-Poisson random variable. However, there are a couple related properties that are worth relaying:</p>
<ul>
<li>The <span class="math inline">\(\lambda\)</span> parameter is the mean of the power-transformed counts</li>
</ul>
<p><span class="math display">\[E[Y^\nu] = \lambda\]</span></p>
<ul>
<li>The mean and variance can be approximated as:</li>
</ul>
<p><span class="math display">\[E[Y] \approx \lambda^{1/\nu} - \frac{\nu-1}{2\nu}\]</span>
<span class="math display">\[Var[Y] \approx \frac{\lambda^{1/\nu}}{\nu}\]</span>
when <span class="math inline">\(\nu \leq 1\)</span> (overdispersed) or <span class="math inline">\(\lambda &gt; 10^\nu\)</span> (larger counts).</p>
</div>
<div id="centralitysimulation" class="section level3">
<h3>Centrality Simulation</h3>
<p>The properties described above give us some useful information, but it is hard to make sense of how these parameters directly govern the data we might observe from a COM-Poisson distribution. To give us a bit more insight, lets randomly generate a bunch of data for different parameter combinations and see what we find. To do this, we‚Äôll use the <code>rcmp</code> function.</p>
<pre class="r"><code># Make a parameter grid
params &lt;-
  list(
    lambda = c(1, 3, 5, 10, 25, 50),
    nu = c(.5, 1, 1.25, 1.5)
  ) %&gt;%
  cross_df()

# Number of samples
n &lt;- 500

# Number of simulations
s &lt;- 100

# Set a seed
set.seed(123)

compoisson_sim1 &lt;-
  params %&gt;%
  
  # Split into a list
  split(1:nrow(.)) %&gt;%
  
  # For each element
  map_df(
    function(.x) {
      
      1:s %&gt;%
        
        # For each iteration
        map_df(
          function(.sim) {
            
            # Time the sampling
            temp_time &lt;- system.time(temp_value &lt;- rcmp(n = n, lambda = .x$lambda, nu = .x$nu))
            
            tibble(
              s = .sim,
              lambda = .x$lambda,
              nu = .x$nu,
              value = temp_value,
              time = temp_time[&quot;elapsed&quot;][[1]]
            )
            
          }
        )
    }
  )</code></pre>
<p>We took 100 random samples of size 500 from 24 parameter combinations. This process took about 94.1 seconds to run. Lets first take a quick look at the distributions from the first simulation for each parameter set.</p>
<pre class="r"><code>compoisson_sim1 %&gt;%
  
  # Filter to the first simulated value
  filter(
    s == 1
  ) %&gt;%
  
  # Convert to factors
  mutate(
    across(
      c(
        lambda,
        nu
      ),
      factor
    ),
    lambda = 
      lambda %&gt;%
      fct_relabel(
        function(x) paste0(&quot;lambda == &quot;, x)
      )
  ) %&gt;%
  
  # Make a plot
  ggplot() +
  geom_histogram(
    aes(
      x = value,
      fill = nu
    ),
    position = &quot;identity&quot;,
    alpha = 0.5
  ) +
  facet_wrap(
    ~lambda,
    scales = &quot;free&quot;,
    label = &quot;label_parsed&quot;
  ) +
  xlab(&quot;Observed Value&quot;) +
  ylab(&quot;Frequency&quot;) +
  theme(
    legend.position = &quot;top&quot;,
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  ) +
  labs(
    fill = expression(nu)
  )</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>It looks like the magnitude of counts increases with <span class="math inline">\(\lambda\)</span>, and decreases with <span class="math inline">\(\nu\)</span>. To get a more concrete view of this, lets compute the sample mean and variance for each iteration, and then average those over the simulations for each parameter combination. By doing this, we‚Äôll also get a sense of the sampling variability of these statistics when <span class="math inline">\(n=\)</span> 500.</p>
<pre class="r"><code>compoisson_sim1 %&gt;%
  
  # For each group
  group_by(lambda, nu, s) %&gt;%
  
  # Compute the statistics
  summarise(
    Mean = mean(value),
    Variance = var(value),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Send the statistics down the rows
  pivot_longer(
    cols = c(Mean, Variance)
  ) %&gt;%
  
  # For each group
  group_by(lambda, nu, name) %&gt;%
  
  # Compute the mean/standard error
  summarise(
    Mean = mean(value),
    SE = sd(value),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Join to get the average time for each iteration
  inner_join(
    y = 
      compoisson_sim1 %&gt;%
      
      # Remove the value, get unique rows
      select(-value) %&gt;%
      distinct() %&gt;%
      
      # For each group
      group_by(lambda, nu) %&gt;%
      
      # Compute the average time per iteration
      summarise(
        time = mean(time),
        .groups = &quot;drop&quot;
      ),
    by = 
      c(
        &quot;lambda&quot;,
        &quot;nu&quot;
      )
  ) %&gt;%
  
  # Convert to factors
  mutate(
    nu = 
      nu %&gt;%
      factor() %&gt;%
      fct_relabel(
        function(x) paste0(&quot;nu == &quot;, x)
      )
  ) %&gt;%
  
  # Make a plot
  ggplot(
    aes(
      x = lambda,
      y = Mean
    )
  ) +
  geom_line(
    aes(
      color = name
    ),
    size = 1.25
  ) +
  geom_point(
    aes(
      color = name
    ),
    size = 3
  ) +
  geom_ribbon(
    aes(
      ymin = Mean - 2*SE,
      ymax = Mean + 2*SE,
      fill = name
    ),
    alpha = .25
  ) +
  facet_wrap(
    ~nu,
    scales = &quot;free_y&quot;,
    label = &quot;label_parsed&quot;
  ) +
  ylab(&quot;Value&quot;) +
  theme(
    legend.position = &quot;top&quot;,
    legend.title = element_blank(),
    legend.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  ) +
  scale_x_continuous(
    breaks = unique(params$lambda)
  ) +
  labs(
    x = expression(lambda)
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>When <span class="math inline">\(\nu=0.5\)</span> (overdispersed), the counts become large quickly with an increasing <span class="math inline">\(\lambda\)</span>. As the data becomes more underdispersed (<span class="math inline">\(\nu &gt; 1\)</span>), the variance increases at a slower rate as <span class="math inline">\(\lambda\)</span> increases, relative to the mean.</p>
<p>So how does this translate to a regression model?</p>
</div>
</div>
<div id="compoissonregressionmodel" class="section level2">
<h2>The Regression Model</h2>
<p>It turns out that the model structure for COM-Poisson regression is very similar to the <a href="#modelformulation">standard Poisson model</a>. In fact, we can just copy and paste it from above:</p>
<p><span class="math display">\[log(\lambda_i) = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2}+...+\beta_px_{ip} = X_i\beta\]</span>
The basic structure models the <span class="math inline">\(\lambda\)</span> parameter (on the log scale) as a linear combination of covariates. In turn, the steps for estimating the parameters are also the same:</p>
<ol style="list-style-type: decimal">
<li>Plug the regression formula into the COM-Poisson PDF</li>
<li>Derive the likelihood function</li>
<li>Compute the maximum likelihood estimates (MLEs)</li>
</ol>
<p>The only difference is that the <span class="math inline">\(\lambda\)</span> parameter in this model no longer <a href="#poissondistribution">represents the mean</a>. So when we generate fitted values or interpret parameter estimates, there has to be a little more care taken as to what those represent.</p>
<p>Let‚Äôs take a quick look at how to fit a model with the <code>glm.cmp</code> function and orient ourselves with its output. We‚Äôll use the <code>ed_volumes</code> dataset from the <a href="#reviewofpoisson">previous section</a>.</p>
<pre class="r"><code>compoisson_model1 &lt;-
  
  # Function to fit a COM-Poisson model
  glm.cmp(
    formula.lambda = Volume ~ Weekend + PM, # lamda parameter linear predictor
    data = 
      ed_volumes %&gt;% 
      mutate(
        Weekend = weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;),
        PM = TimeOfDay == &quot;PM&quot;
      )
  )

compoisson_model1</code></pre>
<pre><code>## CMP coefficients
##               Estimate     SE  z.value   p.value
## X:(Intercept)   2.8472 0.1551  18.3534 3.101e-75
## X:WeekendTRUE  -0.4231 0.0324 -13.0517 6.211e-39
## X:PMTRUE        0.0180 0.0195   0.9235    0.3557
## S:(Intercept)   0.0217 0.0537   0.4050    0.6855
## --
## Transformed intercept-only parameters
##    Estimate     SE
## nu    1.022 0.0548
## --
## Chi-squared test for equidispersion
## X^2 = 0.1614, df = 1, p-value = 6.8787e-01
## --
## Elapsed Sec: 3.32   Sample size: 730   SEs via Hessian
## LogLik: -2000.6310   AIC: 4009.2620   BIC: 4027.6342   
## Optimization Method: L-BFGS-B   Converged status: 0
## Message: CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH</code></pre>
<p>We see some familiar results. Namely, the parameter estimates and p-values are pretty similar to the standard Poisson model <a href="#modelformulation">above</a>. However, there is additional output‚Äìthis is where the dispersion comes in. When we fit the model, the function also estimated the value of the <span class="math inline">\(\nu\)</span> parameter, which in this case was 1.022 (it was expected to be near 1, given that our data was generated from a standard Poisson distribution). The <code>X</code> components make up the regression equation for <span class="math inline">\(\lambda\)</span>, and the <code>S</code> components make up the regression equation for <span class="math inline">\(\nu\)</span>. We just need to evaluate those equations on an observation‚Äôs covariate values, and we‚Äôll have its estimated conditional COM-Poisson distribution.</p>
</div>
<div id="compoissonlrt" class="section level2">
<h2>Testing for Violations of Equidispersion</h2>
<p>We could just look at the estimated <span class="math inline">\(\nu\)</span> parameter and its standard error in the model output to draw a conclusion about the dispersion. Nevertheless, the package also provides a function called <code>equitest</code> to more formally carry out a <em>likelihood ratio test (LRT)</em> for the following hypotheses:</p>
<p><span class="math display">\[H_0: \nu = 1 \hskip.25in H_A: \nu \neq 1\]</span></p>
<p>It tests for evidence that the data is <em>not</em> equidispersed, but does not specify its direction. Therefore, if <span class="math inline">\(H_0\)</span> is rejected, it is up to us to garner from the model output whether there is over or under dispersion. Here is the output when performing this test on our model:</p>
<pre class="r"><code>equitest(compoisson_model1)</code></pre>
<pre><code>## $teststat
## [1] 0.1614062
## 
## $pvalue
## [1] 0.6878651</code></pre>
<p>As expected, the p-value of 0.6879 does not indicate that over or under dispersion was detected.</p>
</div>
<div id="stratifieddispersion" class="section level2">
<h2>Stratified Dispersion</h2>
<p>One of the coolest features of this modeling framework (in my opinion) is that not only can you fit a model for over or under dispersed data, but you can allow the dispersion parameter to vary by covariate values. You probably noticed the <code>formula.lambda</code> argument in the <code>glm.cmp</code> function call where we specified the model form for the <span class="math inline">\(\lambda\)</span> parameter. There is an additional argument called <code>formula.nu</code> where we can analogously specify a linear predictor for the <span class="math inline">\(\nu\)</span> parameter, which, like <span class="math inline">\(\lambda\)</span>, is on the <em>log</em> scale. This means that, for example, if we suspect that one group has <em>overdispersed</em> data, and another has <em>underdispersed</em> data, we can account for that within a single model. Very cool! Just for kicks, let‚Äôs see what this looks like when we allow the <span class="math inline">\(\nu\)</span> parameter to vary between AM and PM hours from our <code>ed_volumes</code> dataset:</p>
<pre class="r"><code>compoisson_model2 &lt;-
  glm.cmp(
    formula.lambda = Volume ~ Weekend, # Linear predictor for log-lambda
    formula.nu = Volume ~ PM, # Linear predictor for log-nu
    data = 
      ed_volumes %&gt;% 
      mutate(
        Weekend = weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;),
        PM = TimeOfDay == &quot;PM&quot;
      )
  )
compoisson_model2</code></pre>
<pre><code>## CMP coefficients
##               Estimate     SE  z.value   p.value
## X:(Intercept)   2.8561 0.1553  18.3941 1.466e-75
## X:WeekendTRUE  -0.4231 0.0324 -13.0519 6.197e-39
## S:(Intercept)   0.0249 0.0538   0.4640    0.6427
## S:PMTRUE       -0.0064 0.0069  -0.9312    0.3518
## --
## Chi-squared test for equidispersion
## X^2 = 1.0118, df = 1, p-value = 3.1446e-01
## --
## Elapsed Sec: 3.51   Sample size: 730   SEs via Hessian
## LogLik: -2000.6243   AIC: 4009.2487   BIC: 4027.6209   
## Optimization Method: L-BFGS-B   Converged status: 0
## Message: CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH</code></pre>
<p>We can see that there are now two parameters associated with the <code>S</code> component of the model. We can simply evaluate and exponentiate those terms to get the <span class="math inline">\(\nu\)</span> estimates for each group:</p>
<pre class="r"><code># Make a simple design matrix
nu_design &lt;- matrix(c(1,1,0,1), nrow = 2)

# Multiply by the S component of the model
nu_log_estimates &lt;- nu_design %*% as.matrix(compoisson_model2$gamma)

# Exponentiate
nu_estimates &lt;- exp(nu_log_estimates)

# Add the names
rownames(nu_estimates) &lt;- names(compoisson_model2$gamma)
nu_estimates</code></pre>
<pre><code>##                   [,1]
## S:(Intercept) 1.025254
## S:PMTRUE      1.018668</code></pre>
<p>Again, both groups‚Äô data were knowingly generated from a standard Poisson distribution here, so we expected the conditional estimates to be near 1 as well. Nevertheless, it illustrates the power and flexibility of this framework.</p>
</div>
<div id="comfittedvalues" class="section level2">
<h2>Generating Fitted Values</h2>
<p>As <a href="#compoissonmeanapprox">previously mentioned</a>, there is no closed form solution for the mean of a COM-Poisson random variable. So when we generate fitted values from the model‚Äôs linear predictor, it is hard to conceptualize what they represent (it is <em>NOT</em> the mean). Since our model <em>does</em> produce estimates for both <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\nu\)</span>, the <a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-4/issue-2/A-flexible-regression-model-for-count-data/10.1214/09-AOAS306.full">recommendation</a> is to plug these into the inverse cumulative density function (CDF) to obtain quantile-based fitted values. Specifically, we can use the <em>median</em>. The figure below displays the median and <span class="math inline">\(25^{th}\)</span>/<span class="math inline">\(75^{th}\)</span> percentiles from the parameter grid used in the <a href="#centralitysimulation">simulation above</a>.</p>
<pre class="r"><code>params %&gt;%
  
  # Add the quantiles
  inner_join(
    y = 
      tibble(
        Quantile = c(0.25, 0.50, 0.75)
      ),
    by = character()
  ) %&gt;%
  
  # Get the value
  mutate(
    Value = qcmp(Quantile, lambda, nu),
    Linegroup = factor(Quantile == 0.50) %&gt;% fct_rev(),
    nu = 
      nu %&gt;%
      factor() %&gt;%
      fct_relabel(
        function(x) paste0(&quot;nu == &quot;, x)
      )
  ) %&gt;%
  
  # Make a plot
  ggplot(
    aes(
      x = lambda,
      y = Value,
      group = Quantile
    )
  ) +
  geom_line(
    aes(
      linetype = Linegroup,
      color = Linegroup
    ),
    size = 1.25
  ) +
  geom_point(
    size = 2
  ) +
  facet_wrap(
    ~nu,
    scales = &quot;free_y&quot;,
    label = &quot;label_parsed&quot;
  ) +
  ylab(&quot;Median &amp; 25th/75th Percentiles&quot;) +
  theme(
    legend.position = &quot;none&quot;,
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  ) +
  scale_x_continuous(
    breaks = unique(params$lambda)
  ) +
  labs(
    x = expression(lambda)
  ) +
  scale_color_manual(
    values = c(&quot;black&quot;, &quot;red&quot;)
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>The median values seem to have a relatively similar behavior to the simulated means.</p>
<p>So, to obtain <em>predicted</em> values with our model object (we‚Äôll use the <a href="#compoissonregressionmodel">first model we made</a>), we have to:</p>
<ol style="list-style-type: decimal">
<li>Produce observation-level estimates of <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\nu\)</span> with the regression equation</li>
</ol>
<pre class="r"><code># Multiply the design matrices by the parameter estimates for each linear predictor, then exponentiate
lambda_hat &lt;- exp(compoisson_model1$X %*% as.matrix(compoisson_model1$beta))
nu_hat &lt;- exp(compoisson_model1$S %*% as.matrix(compoisson_model1$gamma))
head(data.frame(lambda_hat, nu_hat))</code></pre>
<pre><code>##   lambda_hat   nu_hat
## 1   17.23881 1.021967
## 2   17.55188 1.021967
## 3   17.23881 1.021967
## 4   17.55188 1.021967
## 5   17.23881 1.021967
## 6   17.55188 1.021967</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Plug the estimates into the inverse CDF at the 50th percentile</li>
</ol>
<pre class="r"><code>y_hat &lt;- qcmp(rep(0.5, length(lambda_hat)), lambda = lambda_hat, nu = nu_hat)
table(y_hat)</code></pre>
<pre><code>## y_hat
##  11  16 
## 208 522</code></pre>
<p>There does exist a <code>predict.cmp</code> function that uses the <a href="#compoissonmeanapprox">mean approximation</a> by default, so this could be used for fitted values as well if those conditions are satisfied.</p>
</div>
<div id="compowersim" class="section level2">
<h2>Simulation: Power of Equidispersion Test</h2>
<p>So how well does the likelihood ratio test <a href="#compoissonlrt">described above</a> detect over or under dispersion in the data-generating process? We can use simulation! To keep it simple, we will base it off of intercept-only regression models (i.e., no covariates), in effect assessing power at varying values of <span class="math inline">\(\lambda\)</span>. Presumably, power may depend on the complexity of the model, so coverage might vary as terms are added. Here are the parameter values we will consider:</p>
<p><span class="math display">\[
\begin{equation}
\begin{split}
\lambda &amp; = (1, 3, 5, 10, 25) \\
\nu &amp; = (0.5, 0.75, 1, 1.25, 1.5, 2) \\
N &amp; = (25, 50, 100, 500) \\
\end{split}
\end{equation}
\]</span></p>
<p>With those, we will take the following steps to carry out the simulation <em>for each combination of <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\nu\)</span>, and <span class="math inline">\(N\)</span></em>:</p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\(N\)</span> random COM-Poisson realizations</li>
<li>Fit an intercept-only COM-Poisson regression model</li>
<li>Conduct the likelihood ratio test for equidispersion</li>
<li>Calculate the p-value from (3)</li>
<li>Repeat steps 1-4 for 100 iterations</li>
<li>Compute the proportion of iterations in (5) where the p-value was less than 0.05</li>
</ol>
<p>The following code chunk carries out these steps:</p>
<pre class="r"><code># NOTE: THIS CHUNK TAKES A WHILE TO RUN

# Number of iterations
sims &lt;- 100

power_results &lt;-
  
  # Parameter set
  list(
    lambda = c(1, 3, 5, 10, 25),
    nu = c(0.5, 0.75, 1, 1.25, 1.5, 2),
    N  = c(25, 50, 100, 500)
  ) %&gt;%
  
  # Get the cross product
  cross_df() %&gt;%
  
  # Split into a list
  split(1:nrow(.)) %&gt;%
  
  # For each parameter combination
  map_df(
    function(x) {
      
      # Generate all CMP realizations
      tibble(
        S = rep(1:sims, x$N),
        Y = rcmp(n = x$N * sims, lambda = x$lambda, nu = x$nu)
      ) %&gt;%
        
        # For each iteration
        group_by(S) %&gt;%
        
        # Compute the p-value
        summarise(
          PValue = 
            tryCatch(
              equitest(glm.cmp(Y ~ 1))$pvalue,
              error = function(e) NA_real_
            ),
          .groups = &quot;drop&quot;
        ) %&gt;%
        
        # Add the parameter values
        mutate(
          lambda = x$lambda,
          nu = x$nu,
          N = x$N
        )
      
    }
  )</code></pre>
<p>This code took quite a while to run (~4 hours). I‚Äôve noticed the fitting procedure takes a bit longer than we‚Äôd be used to with a simple <code>glm</code> call (which is probably expected given the complexity of the estimation), and varies depending on the combination of parameter values. It‚Äôs also worth noting that it failed to converge on 0.9% of simulations, which tended to only occur when there was overdispersion (<span class="math inline">\(\nu=0.5\)</span>) with large counts (<span class="math inline">\(\lambda &gt; 5\)</span>). Nevertheless, the figure below gives us the results of the simulation showing the estimated power for each parameter combination:</p>
<pre class="r"><code>power_results %&gt;%
  
  # For each group
  group_by(lambda, nu, N) %&gt;%
  
  # Compute the power, and a measure of simulation error
  summarise(
    Power = mean(PValue &lt;= 0.05, na.rm = TRUE),
    SE = sd(PValue &lt;= 0.05, na.rm = TRUE) / sqrt(n()),
    .groups = &quot;drop&quot;
  ) %&gt;%
  
  # Make a factor
  mutate(
    N = factor(N),
    nu = 
      nu %&gt;%
      factor() %&gt;%
      fct_relabel(
        function(x) paste0(&quot;nu == &quot;, x)
      )
  ) %&gt;%
  
  # Make a plot
  ggplot(
    aes(
      x = lambda,
      y = Power
    )
  ) +
  geom_line(
    aes(
      color = N
    ),
    size = 1
  ) +
  geom_point(
    aes(
      color = N
    ),
    size = 3
  ) +
  geom_ribbon(
    aes(
      ymin = Power - 2*SE,
      ymax = Power + 2*SE,
      fill = N
    ),
    alpha = .35
  ) +
  facet_wrap(
    ~nu,
    label = &quot;label_parsed&quot;
  ) +
  ylab(&quot;Power&quot;) +
  theme(
    legend.position = &quot;top&quot;,
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    panel.background = element_blank(),
    panel.grid.major.y = element_line(color = &quot;gray&quot;)
  ) +
  scale_x_continuous(
    breaks = unique(power_results$lambda)
  ) +
  labs(
    x = expression(lambda)
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p><strong>Findings</strong>:</p>
<ul>
<li>The power increases with sample size and deviation from <span class="math inline">\(\nu=1\)</span></li>
<li>The test has a much harder time detecting over/under dispersion when the counts are really small (i.e., <span class="math inline">\(\lambda = 1\)</span>)</li>
<li>When there is overdispersion (<span class="math inline">\(\nu&lt;1\)</span>), the power looks higher at lower values of <span class="math inline">\(\lambda\)</span>, but the opposite occurs as the data becomes more underdispersed</li>
</ul>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>The COM-Poisson regression framework is another tool in the toolbox to consider when modeling count data. Given that it is a generalization of the standard Poisson model that handles both over and under dispersed data, a good strategy may be to use it as a starting point to explore the variability in a dataset, and then shape the model from there. The likelihood ratio test allows us to test for violations of equidispersion, at which point we can use estimation to identify the direction that the dispersion exists. Since there are popular methods to handle overdispersed data (e.g., negative binomial models), the real void this method fills is its handling of underdispersed data‚Äìthe challenge there may simply be finding the use case.</p>
</div>
<div id="codeappendix" class="section level1">
<h1>Code Appendix</h1>
<p>This appendix only contains code snippets that were hidden from being displayed in the text.</p>
<pre class="r"><code># Load packages
require(tidyverse)

# Set a seed
set.seed(123)

### Create simulated dataset

# Generating a random Poisson parameter
ed_true_mean &lt;-
  runif(
    n = 1,
    min = 12.5,
    max = 25
  )

# Build the dataset
ed_volumes &lt;-
  tibble(
    Date = rep(as.Date(&quot;2021-12-31&quot;)  - seq(0, 364, 1), 2),
    TimeOfDay = c(rep(&quot;AM&quot;, length(Date) / 2), rep(&quot;PM&quot;, length(Date) / 2)),
    Volume = 
      rpois(
        n = length(Date), 
        lambda = ifelse(weekdays(Date) %in% c(&quot;Saturday&quot;, &quot;Sunday&quot;), ed_true_mean - 5, ed_true_mean)
      )
  ) %&gt;%
  arrange(
    desc(Date),
    TimeOfDay
  )</code></pre>
</div>
